[{"path":"index.html","id":"section","chapter":"","heading":"","text":"","code":""},{"path":"preamble.html","id":"preamble","chapter":"Preamble","heading":"Preamble","text":"","code":""},{"path":"preamble.html","id":"dedication","chapter":"Preamble","heading":"Dedication","text":"romantic, Kay —\nlove?\nNeed ask anyone tell us things?","code":""},{"path":"preamble.html","id":"acknowledgements","chapter":"Preamble","heading":"Acknowledgements","text":"work builds contributions many people R Open Source communities. particular, like acknowledge extensive material taken Introduction Data Science: Data Analysis Prediction Algorithms R Rafael . Irizarry, ModernDive: Statistical Inference via Data Science Chester Ismay Albert Y. Kim,\nSTAT 545: Data wrangling, exploration, analysis R Jenny Bryan, Intro Stat Randomization Simulation David M. Diez, Christopher D. Barr Mine Cetinkaya-Rundel, Think Bayes: Bayesian Statistics Made Simple Allen B. Downey, R Data Science Garrett Grolemund Hadley Wickham, Tidy Modeling R Max Kuhn Julia Silge, Broadening Statistical Horizons: Generalized Linear Models Multilevel Models Julie Legler Paul Roback. See (???) (???).Alboukadel Kassambara, Andrew Tran, Thomas Mock others kindly allowed re-use /modification work.Thanks contributions Harvard students, colleagues random people met internet: Albert Rivero, Nicholas Dow, Celine Vendler, Sophia Zheng, Maria Burzillo, Robert McKenzie, Deborah Gonzalez, Beau Meche, Evelyn Cai, Miro Bergam, Jessica Edwards, Emma Freeman, Cassidy Bargell, Yao Yu, Vivian Zhang, Ishan Bhatt, Mak Famulari, Tahmid Ahmed, Eliot Min, Hannah Valencia, Asmer Safi, Erin Guetzloe, Shea Jenkins, Thomas Weiss, Diego Martinez, Andy Wang, Tyler Simko, Jake Berg, Connor Rust, Liam Rust, Alla Baranovsky, Carine Hajjar, Diego Arias, Becca Gill, Stephanie Yao Tyler Simko.like gratefully acknowledge funding Derek Bok Center Teaching Learning Harvard University, via Digital Teaching Fellows Learning Lab Undergraduate Fellows programs.","code":""},{"path":"preamble.html","id":"license","chapter":"Preamble","heading":"License","text":"work licensed Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License.","code":""},{"path":"shopping-week.html","id":"shopping-week","chapter":"Shopping Week","heading":"Shopping Week","text":" usual touchstone whether someone asserts mere persuasion least subjective conviction, .e., firm belief, betting. Often someone pronounces propositions confident inflexible defiance seems entirely laid aside concern error. bet disconcerts . Sometimes reveals persuaded enough one ducat ten. happily bet one, 10 suddenly becomes aware previously noticed, namely quite possible erred. -— Immanuel Kant, Critique Pure ReasonThe world confronts us. Make decisions must.","code":""},{"path":"shopping-week.html","id":"warning","chapter":"Shopping Week","heading":"Warning","text":"isn’t book ’re looking .First, book students Gov 50: Data Gov 52: Models, courses offered Government Department Harvard University. Everything book designed make experience students better. material may useful students outside class, don’t really care .Second, book changes time. --date possible.Third, highly opinionated matters . unlikely share views.","code":""},{"path":"shopping-week.html","id":"install-r-and-rstudio","chapter":"Shopping Week","heading":"Install R and RStudio","text":"\nFigure 0.1: Analogy difference R RStudio.\nThroughout book, assume using R via RStudio. R like car’s engine RStudio like car’s dashboard.precisely, R programming language runs computations, RStudio integrated development environment (IDE) provides interface adding many convenient features tools. just way access speedometer, rearview mirrors, navigation system makes driving much easier, using RStudio’s interface makes using R much easier well.first need download install R RStudio (Desktop version) computer. Install R first install RStudio.must first: Download install R.must first: Download install R.must second: Download install RStudio Desktop (free version).must second: Download install RStudio Desktop (free version).","code":""},{"path":"shopping-week.html","id":"using-r-via-rstudio","chapter":"Shopping Week","heading":"Using R via RStudio","text":"\nFigure 0.2: Icons R versus RStudio computer.\nMuch don’t drive car interacting directly engine rather interacting elements car’s dashboard, won’t using R directly rather use RStudio’s interface. install R RStudio computer, ’ll two new programs (also called applications) can open. ’ll always work RStudio directly R application.Although experimental, allow two modes working R RStudio. First, computer. Second, using FAS OnDemand, available Canvas page. try highlight differences two approaches , use R RStudio, many. recommend students try course semester.FAS OnDemand provides similar experience RStudio Cloud, paid service. data science today done machine, data science future done cloud.Let’s begin getting familiar RStudio, whether machine FAS OnDemand. Begin opening RStudio. open RStudio, see three panes, panels, dividing screen: console pane, files pane, environment pane. see something like :workspace! can see three main windows right now. Let’s focus big one left:three tabs window, ’ll focusing Console Terminal. first start R, Console gives information version R. time written, 4.0.1 latest version R! Console can type run R code. example, type 1 + 1 hit return, Console returns 2.Next, let’s move top right:, main two tabs ’ll using Environment Git (yet available). Environment tab shows datasets variables currently loaded RStudio. case, loaded dataset 3407 rows 5 columns variable x equal 5. , Environment empty, let’s change !create first variable RStudio, go Console type:Now, hit return/enter see variable x equal 5 Environment! must always hit return/enter typing command, otherwise RStudio realize want R execute command. bottom right window:, Files tab allow see computer’s file system. create project later, tab automatically show contents project’s folder. plots tab show preview plots make RStudio. Packages shows packages installed RStudio far. Help explained later chapter.","code":"x <- 5"},{"path":"shopping-week.html","id":"initial-set-up","chapter":"Shopping Week","heading":"Initial Set Up","text":"Whether working FAS OnDemand computer, next step copy paste following R Console:rstudioapi commands set sensible defaults working RStudio. execute commands one time.Note R occasionally ask want install packages. Almost time want , otherwise R asking ! One tricky aspect process occasionally asked R:Unless good reason , always answer “” question.","code":"\nlibrary(rstudioapi)\nrstudioapi::writeRStudioPreference(name = \"load_workspace\", value = FALSE)\nrstudioapi::writeRStudioPreference(name = \"save_workspace\", value = \"never\")Do you want to install from sources the packages which \nneed compilation? (Yes/no/cancel)"},{"path":"shopping-week.html","id":"package-installation","chapter":"Shopping Week","heading":"Package installation","text":"Another point confusion many new R users idea R package. R packages, also known R libraries, extend functionality R providing additional functions, data, documentation. written worldwide community R users can downloaded free.example, among many packages use book remotes package.\nFigure 0.3: Analogy R versus R packages.\nR like new mobile phone: certain amount features use first time, doesn’t everything. R packages like apps can download onto phone Apple’s App Store Android’s Google Play.Let’s continue analogy considering Instagram app editing sharing pictures. Say purchased new phone like share photo just taken friends Instagram. need :Install app: Since phone new include Instagram app, need download app either App Store Google Play. ’re set time . might need future update app.Open app: ’ve installed Instagram, need open .Instagram open phone, can proceed share photo friends family. process similar using R package. need :\nFigure 0.4: Installing versus loading R package\nInstall package: like installing app phone. packages installed default install R RStudio. Thus want use package first time, need install first. ’ve installed package, likely won’t install unless want update newer version.“Load” package: “Loading” package like opening app phone. Packages “loaded” default start RStudio computer; need “load” package want use every time start RStudio.Let’s perform two steps remotes package.Type install.packages(\"remotes\") console pane RStudio press Return/Enter keyboard. Note must include quotation marks around name package.R packages generally live one two places: CRAN (rhymes “clan”) mature, popular packages Github experimental, less stable packages. install.packages() gets packages CRAN. end section, also install one package Github.","code":""},{"path":"shopping-week.html","id":"package-loading","chapter":"Shopping Week","heading":"Package loading","text":"Recall ’ve installed package, need “load .” words, need “open .” using library() command.example, load remotes package, run following code console pane. mean “run following code”? Either type copy--paste following code console pane hit Enter key.running earlier code, blinking cursor returns next > “prompt” sign, means successful remotes package now loaded ready use. , however, get red “error message” reads:haven’t successfully install . example “error message”. get error message, go back subsection R package installation make sure install remotes package proceeding.historical reasons “packages” also known “libraries,” relevant command loading library().","code":"\nlibrary(remotes)Error in library(remotes) : there is no package called ‘remotes’"},{"path":"shopping-week.html","id":"package-use","chapter":"Shopping Week","heading":"Package use","text":"One common mistake new R users make wanting use particular packages forget load first using library() command just saw. Remember: load package want use every time start RStudio. don’t load package attempting use one features, ’ll see error message similar :different error message one just saw package installed yet. R telling trying use function package yet loaded. R doesn’t know find function using. Almost new users forget starting .Now, installing package available CRAN: PPBDS.data. Copy paste following R Console:Depending computer/browser/locale, might fail, especially quotation marks paste turn curly. case, type commands .result many new packages installed. may take minutes. something gets messed , often useful remove.packages() problematic package install .","code":"Error: could not find function\nlibrary(remotes)\nremotes::install_github(\"davidkane9/PPBDS.data\")"},{"path":"shopping-week.html","id":"tutorials","chapter":"Shopping Week","heading":"Tutorials","text":"chapter textbook, corresponding tutorial available PPBDS.data package. order access tutorials, follow steps:Run library(PPBDS.data) R Console.can access tutorials via Tutorial pane top right tab RStudio. Click “Start tutorial” “Shopping Week” tutorial. don’t see tutorials, try clicking “Home” button – little house symbol thin red roof upper right.order expand window, can drag enlarge tutorial pane inside RStudio. order open popup window, click “Show New Window” icon next home icon.may notice Jobs tab create output tutorial starting . RStudio running code create tutorial. accidentally clicked “Start Tutorial” like stop job running, can click back arrow Jobs tab, press red stop sign icon.work saved sessions, can complete tutorial multiple sittings. order complete tutorial successfully, make sure enter name beginning answer questions. completed tutorial, follow instructions tutorial Submit page upload resulting tutorial_responses.rds file Canvas.Tutorials graded pass/fail. hard fail. long make honest attempt, pass easily.’ve finished tutorial! Now ? ways can close tutorial safely can quit RStudio session.clicked “Show new window” working tutorial pop-window, simply X pop-windowIf working tutorial inside Tutorial pane RStudio, simply press red stop sign icon","code":""},{"path":"visualization.html","id":"visualization","chapter":"1 Visualization","heading":"1 Visualization","text":"People love visualizations. chapter focuses ggplot2, one core packages tidyverse. access datasets, help pages, functions use chapter, load tidyverse running code:one line code loads packages associated tidyverse, packages use almost every data analysis. also tells functions tidyverse conflict functions base R packages might loaded. (future, hide messages ugly.)run code get error message “package called ‘tidyverse’”, ’ll need first install , run library() .Recall, need install package . need load every time use . also use two packages chapter: gapminder nycflights13.packages contain datasets use creating visualizations. may need install packages already done .need explicit function (dataset) comes , ’ll use special form: package::function(). example, ggplot2::ggplot() tells explicitly ’re using ggplot() function ggplot2 package.Now ’re set , let’s create first data visualization R using iris dataset! famous iris data set gives measurements centimeters variables sepal length width petal length width, respectively, 50 flowers 3 species iris (setosa, versicolor, virginica). can learn dataset running ?iris access help page.Wow! Just running lines code created nice visualization compare measured petal lengths 3 species iris! ’ll learn lines code mean write others like throughout chapter, now, let’s learn coding R.","code":"\nlibrary(tidyverse)## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.0 ──## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4\n## ✓ tibble  3.0.4     ✓ dplyr   1.0.2\n## ✓ tidyr   1.1.2     ✓ stringr 1.4.0\n## ✓ readr   1.4.0     ✓ forcats 0.5.0## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## x readr::col_factor() masks scales::col_factor()\n## x purrr::discard()    masks scales::discard()\n## x dplyr::filter()     masks stats::filter()\n## x dplyr::lag()        masks stats::lag()\ninstall.packages(\"tidyverse\")\nlibrary(gapminder)\nlibrary(nycflights13)\nggplot(data = iris, \n       mapping = aes(x = Petal.Length, fill = Species)) +\n  geom_histogram(binwidth = 0.1) +\n  labs(title = \"Petal Length Among Three Species of Iris\")"},{"path":"visualization.html","id":"getting-started","chapter":"1 Visualization","heading":"1.1 Getting Started","text":"","code":""},{"path":"visualization.html","id":"how-do-i-code-in-r","chapter":"1 Visualization","heading":"1.1.1 How do I code in R?","text":"Unlike statistical software programs like Excel, SPSS, Minitab provide point--click interfaces, R interpreted language. means type commands written R code. words, code/program R. Note ’ll use terms “coding” “programming” interchangeably book.new world coding, R, RStudio feel benefit detailed introduction, suggest check short book, Getting Used R, RStudio, R Markdown. (???) includes screencast recordings can follow along pause learn. book also contains introduction R Markdown, tool used reproducible research R.required seasoned coder/computer programmer use R, still set basic programming concepts new R users need understand.","code":""},{"path":"visualization.html","id":"tips","chapter":"1 Visualization","heading":"1.1.2 Tips","text":"Learning code/program quite similar learning foreign language. can daunting frustrating first. frustrations common normal feel disCouraged learn. However, just learning foreign language, put effort afraid make mistakes, anybody can learn improve.useful tips keep mind learn program:Remember computers actually smart: may think computer smartphone “smart,” really people spent lot time energy designing appear “smart.” reality, tell computer everything needs . Furthermore, instructions give computer can’t mistakes , can ambiguous way.Take “copy, paste, tweak” approach: Especially learn first programming language need understand particularly complicated code, often much easier take existing code know works modify suit ends. opposed trying type code scratch. call “copy, paste, tweak” approach. early , suggest trying write code memory, rather take existing examples provided , copy, paste, tweak suit goals. start feeling confident, can slowly move away approach write code scratch. Think “copy, paste, tweak” approach training wheels learning ride bike. getting comfortable, won’t need anymore.best way learn code : Rather learning code sake, find learning code goes much smoother goal mind working particular project, like analyzing data interested important .Practice key: Just method improve foreign language skills lots practice speaking, method improving coding skills lots practice. Write R code every day.","code":""},{"path":"visualization.html","id":"basic-programming","chapter":"1 Visualization","heading":"1.1.3 Basic programming","text":"now introduce basic programming concepts terminology. Instead asking memorize concepts terminology right now, ’ll guide ’ll “learn .” help learn, always use different font distinguish regular text computer_code. best way master topics , opinions, deliberate practice R lots repetition.Console pane: enter commands.Running code: act telling R perform act giving commands console.Objects: values saved R. ’ll show assign values objects display contents objects.Data types: integers, doubles/numerics, logicals, characters. Integers values like -1, 0, 2, 4092. Doubles numerics larger set values containing integers also fractions decimal values like -24.932 0.8. Logicals either TRUE FALSE characters text “cabbage”, “Hamilton”, “Wire greatest TV show ever”, “ramen delicious.” Note characters often denoted quotation marks around .Vectors: series values. created using c() function, c() stands “combine” “concatenate.” example, c(6, 11, 13, 31, 90, 92) creates six element series positive integer values.Factors: categorical data commonly represented R factors. Categorical data can also represented strings. go detail variable types Chapter 2.Data frames: rectangular spreadsheets. representations datasets R rows correspond observations columns correspond variables describe observations. Modern data frames called tibbles.Boolean algebra: TRUE/FALSE statements mathematical operators < (less ), <= (less equal), != (equal ). example, 4 + 2 >= 3 return TRUE, 3 + 5 <= 1 return FALSE. Testing inclusion %% operator. example, \"B\" %% c(\"\", \"B\") returns TRUE \"C\" %% c(\"\", \"B\") returns FALSE. test equality R using == (=, typically used assignment). example, 2 + 1 == 3 compares 2 + 1 3 correct R code, 2 + 1 = 3 return error.Logical operators: & representing “” well | representing “.” example, (2 + 1 == 3) & (2 + 1 == 4) returns FALSE since clauses TRUE (first clause TRUE). hand, (2 + 1 == 3) | (2 + 1 == 4) returns TRUE since least one two clauses TRUE.Functions, also called commands: perform tasks R. take inputs called arguments return outputs. can either manually specify function’s arguments use function’s default values. example, function seq() R generates sequence numbers. just run seq() return value 1. doesn’t seem useful! default arguments set seq(= 1, = 1). Thus, don’t pass different values change behavior, R just assumes want number 1. can change argument values updating values = sign. try seq(= 2, = 5) get result 2 3 4 5, expect.Help files: provide documentation various functions datasets. can bring help files adding ? name function data frame run console. presented page showing corresponding documentation.","code":""},{"path":"visualization.html","id":"errors-warnings-and-messages","chapter":"1 Visualization","heading":"1.1.4 Errors, warnings, and messages","text":"R reports errors, warnings, messages glaring red font, makes seem like scolding . However, seeing red text console always bad.R show red text console pane three different situations:Errors: red text legitimate error, prefaced “Error …” try explain went wrong. Generally ’s error, code run. example, see Error ggplot(...) : find function \"ggplot\", means ggplot() function accessible package contains function, ggplot2, loaded library(ggplot2). use ggplot() function without ggplot2 package loaded first.Warnings: red text warning, prefaced “Warning:” R try explain ’s warning. Generally code still work, caveats. create scatterplot based dataset two rows data missing entries, see warning: Warning: Removed 2 rows containing missing values (geom_point). R still produce scatterplot remaining non-missing values, warning two points aren’t .Messages: red text doesn’t start either “Error” “Warning”, ’s just friendly message. ’ll see messages load R packages read data saved spreadsheet files read_csv() function ’ll see Chapter 2. helpful diagnostic messages. don’t stop code working. Additionally, ’ll see messages install packages using install.packages().Remember, see red text console, don’t panic. doesn’t necessarily mean anything wrong. Rather:text starts “Error”, figure ’s causing . Think errors red traffic light: something wrong!text starts “Warning”, figure ’s something worry . instance, get warning missing values scatterplot know missing values, ’re fine. ’s surprising, look data see ’s missing. Think warnings yellow traffic light: everything working fine, watch /pay attention.Otherwise, text just message. Read , wave back R, thank talking . Think messages green traffic light: everything working fine keep going!","code":""},{"path":"visualization.html","id":"examining-trains","chapter":"1 Visualization","heading":"1.1.5 Examining trains","text":"Let’s put everything ’ve learned far practice start exploring real data! Data comes us variety formats, pictures text numbers. Throughout book, ’ll focus datasets saved “spreadsheet”-type format. probably common way data collected saved many fields. “spreadsheet”-type datasets called data frames R. ’ll focus working data saved data frames throughout book. , “tibble” modern term “data frame,” use interchangeably.’ll begin exploring trains data frame PPBDS.data package get idea structure. dataset includes data attitudes toward immigration-related policies, experiment randomly exposed commuters Spanish-speakers Boston train platform. Individuals treatment value “Treated” exposed two Spanish-speakers regular commute. “Control” individuals .Run following code console, either typing cutting--pasting . displays contents trains data frame console. Note depending size monitor, output may vary slightly.Let’s unpack output:tibble: 115 x 8: tibble specific kind data frame R. particular data frame 115 rows corresponding different observations. , observation person. tibble also 8 columns corresponding 8 variables describing observation.gender, liberal, party, age, income, att_start, treatment, att_end different variables dataset.see, dy default, top 10 rows, ten followed ... 105 rows, indicating us 105 rows data fit screen. R showing first 10 rows, since probably want see first. can see (fewer) rows print() command, .e.,","code":"See [\"Causal effect of intergroup contact on attitudes,\" by Ryan D. Enos, Proceedings of the National Academy of Sciences, Mar 2014, 111 (10)](https://scholar.harvard.edu/files/renos/files/enostrains.pdf) for background and details on the `trains` dataset.\nlibrary(PPBDS.data)\ntrains## # A tibble: 115 x 8\n##    gender liberal party        age income att_start treatment att_end\n##    <chr>  <lgl>   <chr>      <dbl>  <dbl>     <dbl> <fct>       <dbl>\n##  1 Female FALSE   Democrat      31 135000        11 Treated        11\n##  2 Female FALSE   Republican    34 105000         9 Treated        10\n##  3 Male   TRUE    Democrat      63 135000         3 Treated         5\n##  4 Male   FALSE   Democrat      45 300000        11 Treated        11\n##  5 Male   TRUE    Democrat      55 135000         8 Control         5\n##  6 Female FALSE   Democrat      37  87500        13 Treated        13\n##  7 Female FALSE   Republican    53  87500        13 Control        13\n##  8 Male   FALSE   Democrat      36 135000        10 Treated        11\n##  9 Female FALSE   Democrat      54 105000        12 Control        12\n## 10 Male   FALSE   Republican    42 135000         9 Treated        10\n## # … with 105 more rows\nprint(trains, n = 15)## # A tibble: 115 x 8\n##    gender liberal party        age income att_start treatment att_end\n##    <chr>  <lgl>   <chr>      <dbl>  <dbl>     <dbl> <fct>       <dbl>\n##  1 Female FALSE   Democrat      31 135000        11 Treated        11\n##  2 Female FALSE   Republican    34 105000         9 Treated        10\n##  3 Male   TRUE    Democrat      63 135000         3 Treated         5\n##  4 Male   FALSE   Democrat      45 300000        11 Treated        11\n##  5 Male   TRUE    Democrat      55 135000         8 Control         5\n##  6 Female FALSE   Democrat      37  87500        13 Treated        13\n##  7 Female FALSE   Republican    53  87500        13 Control        13\n##  8 Male   FALSE   Democrat      36 135000        10 Treated        11\n##  9 Female FALSE   Democrat      54 105000        12 Control        12\n## 10 Male   FALSE   Republican    42 135000         9 Treated        10\n## 11 Female FALSE   Democrat      33 105000        10 Control         9\n## 12 Male   FALSE   Democrat      50 250000        11 Treated         9\n## 13 Male   FALSE   Republican    24 105000        13 Treated        13\n## 14 Male   TRUE    Democrat      40  62500         6 Control         7\n## 15 Male   TRUE    Democrat      53 300000         8 Control         8\n## # … with 100 more rows"},{"path":"visualization.html","id":"exploring-data-frames","chapter":"1 Visualization","heading":"1.1.6 Exploring data frames","text":"many ways get feel data contained data frame trains. present two functions take “argument” (input) data frame question. also include third method exploring one particular column data frame:Using View() function, brings RStudio’s built-data viewer.Using glimpse() function, included dplyr package.Using $ “extraction operator,” used view single variable/column data frame.1. View():Run View(trains) console RStudio, either typing cutting--pasting console pane. Explore data frame resulting pop viewer. get habit viewing data frames encounter. Note uppercase V View(). R case-sensitive, ’ll get error message run view(trains) instead View(trains).running View(trains), can explore different variables listed columns. Observe many different types variables. variables including age, income, att_start, att_end quantitative variables. variables numerical nature. variables , including gender, liberal, party, treatment, categorical.Note look leftmost column View(trains) output, see column numbers. row numbers dataset. glance across row number, say row 5, can get idea row representing. allow identify object described given row taking note values columns specific row. often called observational unit. observational unit example individual participating experiment Boston commuter train platform.can identify observational unit determining “thing” measured described variables.2. glimpse():second way ’ll cover explore data frame using glimpse() provides us alternative perspective exploring data frame View() function:Observe glimpse() give first entries variable row variable name. addition, data type variable given immediately variable’s name inside < >. , dbl refers “double”, computer coding terminology quantitative/numerical variables. data type trains, int refers “integer” another data type also represents quantitative/numerical variables. “Doubles” take twice size store computer compared integers.contrast, chr refers “character”, computer terminology text data. forms, text data, gender party person, categorical variables. liberal variable another data type: lgl. types variables represent logical data (True/False). Finally, trains dataset also includes data type fct. fct refers “factor” describes variable nominal, case treatment variable.3. $ operatorLastly, $ operator allows us extract explore single variable within data frame. example, run following consoleWe used $ operator extract age variable return vector. ’ll occasionally exploring data frames using $ operator, instead favoring View() glimpse() functions.","code":"\nglimpse(trains)## Rows: 115\n## Columns: 8\n## $ gender    <chr> \"Female\", \"Female\", \"Male\", \"Male\", \"Male\", \"Female\", \"Fema…\n## $ liberal   <lgl> FALSE, FALSE, TRUE, FALSE, TRUE, FALSE, FALSE, FALSE, FALSE…\n## $ party     <chr> \"Democrat\", \"Republican\", \"Democrat\", \"Democrat\", \"Democrat…\n## $ age       <dbl> 31, 34, 63, 45, 55, 37, 53, 36, 54, 42, 33, 50, 24, 40, 53,…\n## $ income    <dbl> 135000, 105000, 135000, 300000, 135000, 87500, 87500, 13500…\n## $ att_start <dbl> 11, 9, 3, 11, 8, 13, 13, 10, 12, 9, 10, 11, 13, 6, 8, 13, 7…\n## $ treatment <fct> Treated, Treated, Treated, Treated, Control, Treated, Contr…\n## $ att_end   <dbl> 11, 10, 5, 11, 5, 13, 13, 11, 12, 10, 9, 9, 13, 7, 8, 13, 8…\ntrains$age##   [1] 31 34 63 45 55 37 53 36 54 42 33 50 24 40 53 50 33 33 32 57 41 36 43 25 41\n##  [26] 33 44 46 41 28 36 37 38 48 20 52 38 45 55 38 45 44 36 29 42 43 54 39 31 50\n##  [51] 60 67 54 44 50 20 57 25 60 44 35 54 52 47 60 47 22 56 50 21 29 45 46 42 23\n##  [76] 29 60 41 30 61 21 46 53 45 46 63 21 31 35 22 68 27 22 30 59 56 32 35 23 60\n## [101] 50 31 43 30 54 52 52 50 37 27 55 42 68 52 50"},{"path":"visualization.html","id":"basic-plots","chapter":"1 Visualization","heading":"1.2 Basic Plots","text":"begin development data science toolbox data visualization. visualizing data, gain valuable insights couldn’t initially obtain just looking raw data values. ’ll use ggplot2 package, provides easy way customize plots.basic, graphics/plots/charts (use terms interchangeably book) provide nice way explore patterns data, presence outliers, distributions individual variables, relationships groups variables. Graphics designed emphasize findings insights want audience understand. , however, require balancing act. one hand, want highlight many interesting findings possible. hand, don’t want include much information overwhelms audience.can break graphic following three essential components:data: dataset containing variables interest.geom: geometric object question. refers type object can observe plot. example: points, lines, bars.aes: aesthetic attributes geometric object. example, x/y position, color, shape, size. Aesthetic attributes mapped variables dataset.\nFigure 1.1: Artwork Allison Horst\nthree components specified ggplot() function included ggplot2 package. purposes book, ’ll always provide ggplot() function following arguments (.e., inputs) minimum:data frame variables exist: data argument.mapping variables aesthetic attributes: mapping argument specifies aesthetic attributes involved.’ve specified components, add layers plot using + sign. essential layer add plot layer specifies type geometric object want plot involve: points, lines, bars, others. layers can add plot include plot title, axes labels, visual themes plots, facets.February 2006, Swedish physician data advocate named Hans Rosling gave TED talk titled “best stats ’ve ever seen” presented global economic, health, development data website gapminder.org. example, data 142 countries 2007, let’s consider countries following table peak data.row table corresponds country 2007. row, 5 columns:Country: Name country.Continent: five continents country part . Note “Americas” includes countries North South America Antarctica excluded.Life Expectancy: Life expectancy years.Population: Number people living country.GDP per Capita: Gross domestic product (US dollars).Now consider following scatterplot, plots 142 data’s countries.Let’s view plot grammar graphics:data variable GDP per Capita gets mapped x-position aesthetic points.data variable Life Expectancy gets mapped y-position aesthetic points.data variable Population gets mapped size aesthetic points.data variable Continent gets mapped color aesthetic points.’ll see shortly data corresponds particular data frame data saved “data variables” correspond particular columns data frame. Furthermore, type geometric object considered plot points. said, example considering points, graphics limited just points. can also use lines, bars, geometric objects.Let’s take tour useful geoms.","code":"## # A tibble: 142 x 5\n##   Country     Continent `Life Expectancy` Population `GDP per Capita`\n##   <fct>       <fct>                 <dbl>      <int>            <dbl>\n## 1 Afghanistan Asia                   43.8   31889923             975.\n## 2 Albania     Europe                 76.4    3600523            5937.\n## 3 Algeria     Africa                 72.3   33333216            6223.\n## # … with 139 more rows"},{"path":"visualization.html","id":"geom_point","chapter":"1 Visualization","heading":"1.2.1 geom_point()","text":"Scatterplots, also called bivariate plots, allow visualize relationship two numerical variables. Specifically, visualize relationship following two numerical variables flights data frame included nycflights13 package:dep_delay: departure delay horizontal “x” axis andarr_delay: arrival delay vertical “y” axisfor Alaska Airlines flights leaving NYC 2013. requires paring data 336,776 flights left NYC 2013, 714 Alaska Airlines flights left NYC 2013. scatterplot involve manageable 714 points, overwhelmingly large number like 336,776. achieve , ’ll take flights data frame, filter rows 714 rows corresponding Alaska Airlines flights kept, save new data frame called alaska_flights using <- assignment operator:now, suggest don’t worry don’t fully understand code. ’ll see later code uses dplyr package tidyverse achieve goal: takes flights data frame filters return rows carrier equal \"\", Alaska Airlines’ carrier code. Testing equality specified == =. Convince code achieves supposed exploring resulting data frame running View(alaska_flights). ’ll see 714 rows, consisting 714 Alaska Airlines flights.Let’s now go code create desired scatterplot break piece--piece.Within ggplot() function, specify two plot’s components arguments (.e., inputs):data alaska_flights data frame via data = alaska_flights.aesthetic mapping setting mapping = aes(x = dep_delay, y = arr_delay). Specifically, variable dep_delay maps x position aesthetic, variable arr_delay maps y position.add layer ggplot() function call using + sign. added layer question specifies third component: geometric object. case, geometric object set points specifying geom_point(). running two lines code console, ’ll notice two outputs: warning message following graphic shown.Let’s first unpack graphic. Observe positive relationship exists dep_delay arr_delay: departure delays increase, arrival delays tend also increase. Observe also large mass points clustered near (0, 0), point indicating flights neither departed arrived late.Let’s turn attention warning message. R alerting us fact five rows ignored due missing. 5 rows, either value dep_delay arr_delay missing (recorded R NA), thus rows ignored plot.continue, let’s make observations code created scatterplot. Note + sign comes end lines, beginning. ’ll get error R put beginning line. adding layers plot, enCouraged start new line + (pressing Return/Enter button keyboard) code layer new line. add layers plots, ’ll see greatly improve legibility code.stress importance adding layer specifying geometric object, consider figure layers added. geometric object specified, blank plot useful!","code":"\nalaska_flights <- flights %>% \n  filter(carrier == \"AS\")\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + \n  geom_point()## Warning: Removed 5 rows containing missing values (geom_point).\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay))"},{"path":"visualization.html","id":"geom_jitter","chapter":"1 Visualization","heading":"1.2.2 geom_jitter()","text":"large mass points near (0, 0) scatterplot just plotted can cause confusion since hard tell true number points plotted. result phenomenon called overplotting. one may guess, corresponds points plotted top . overplotting occurs, difficult know number points plotted. two methods address issue overplotting. Either byAdjusting transparency points orAdding little random “jitter”, random “nudges”, points.Method 1: Changing transparencyThe first way addressing overplotting change transparency/opacity points setting alpha argument geom_point(). can change alpha argument value 0 1, 0 sets points 100% transparent 1 sets points 100% opaque. default, alpha set 1. words, don’t explicitly set alpha value, R use alpha = 1.Note following code identical code created scatterplot overplotting, alpha = 0.2 added geom_point() function:key feature note plot transparency points cumulative: areas high-degree overplotting darker, whereas areas lower degree less dark. Note furthermore aes() surrounding alpha = 0.2. mapping variable aesthetic attribute, rather merely changing default setting alpha. fact, ’ll receive error try change second line read geom_point(aes(alpha = 0.2)).Method 2: Jittering pointsThe second way addressing overplotting jittering points. means giving point small “nudge” random direction. can think “jittering” shaking points around bit plot. Let’s illustrate using simple example first. Say data frame 4 identical rows x y values: (0,0), (0,0), (0,0), (0,0). present regular scatterplot 4 points (left) jittered counterpart (right).left-hand regular scatterplot, observe 4 points superimposed top . know 4 values plotted, fact might apparent others. right-hand jittered scatterplot, now plainly evident plot involves four points since point given random “nudge.”Keep mind, however, jittering strictly visualization tool; even creating jittered scatterplot, original values saved data frame remain unchanged.create jittered scatterplot, instead using geom_point(), use geom_jitter(). Observe following code similar code created scatterplot overplotting, geom_point() replaced geom_jitter().order specify much jitter add, adjusted width height arguments geom_jitter(). corresponds hard ’d like shake plot horizontal x-axis units vertical y-axis units, respectively. case, axes minutes. much jitter add using width height arguments? one hand, important add just enough jitter break overlap points, hand, much completely alter original pattern points.can seen resulting plot, case jittering doesn’t really provide much new insight. particular case, can argued changing transparency points setting alpha proved effective. better use jittered scatterplot? better alter points’ transparency? single right answer applies situations. need make subjective choice choice. least confronted overplotting, however, suggest make types plots see one better emphasizes point trying make.","code":"\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + \n  geom_point(alpha = 0.2)\nggplot(data = alaska_flights, mapping = aes(x = dep_delay, y = arr_delay)) + \n  geom_jitter(width = 30, height = 30)"},{"path":"visualization.html","id":"geom_line","chapter":"1 Visualization","heading":"1.2.3 geom_line()","text":"Linegraphs show relationship two numerical variables variable x-axis, also called explanatory variable, sequential nature. words, inherent ordering variable.common examples linegraphs notion time x-axis: hours, days, weeks, years, etc. Since time sequential, connect consecutive observations variable y-axis line. Linegraphs notion time x-axis also called time series plots. Let’s illustrate linegraphs using another dataset nycflights13 package: weather data frame.Let’s explore weather data frame running View(weather) glimpse(weather). Furthermore let’s read associated help file running ?weather bring help file.Observe variable called temp hourly temperature recordings Fahrenheit weather stations near three major airports New York City: Newark (origin code EWR), John F. Kennedy International (JFK), LaGuardia (LGA). However, instead considering hourly temperatures days 2013 three airports, simplicity let’s consider hourly temperatures Newark airport first 15 days January.Recall section scatterplots, used filter() function choose subset rows flights corresponding Alaska Airlines flights. similarly use filter() , using & operator choose subset rows weather origin \"EWR\", month January, day 1 15. Recall performed similar task section scatterplots creating alaska_flights data frame Alaska Airlines flights, topic ’ll explore next chapter data wrangling.Let’s create time series plot hourly temperatures saved early_january_weather data frame using geom_line() create linegraph, instead using geom_point() like used previously create scatterplots:Much ggplot() code created scatterplot departure arrival delays Alaska Airlines flights, let’s break code piece--piece terms grammar graphics:Within ggplot() function call, specify two components grammar graphics arguments:data early_january_weather data frame setting data = early_january_weather.aesthetic mapping setting mapping = aes(x = time_hour, y = temp). Specifically, variable time_hour maps x position aesthetic, variable temp maps y position aesthetic.add layer ggplot() function call using + sign. layer question specifies third component grammar: geometric object question. case, geometric object line set specifying geom_line().","code":"\nearly_january_weather <- weather %>% \n  filter(origin == \"EWR\" & month == 1 & day <= 15)\nggplot(data = early_january_weather, \n       mapping = aes(x = time_hour, y = temp)) +\n  geom_line()"},{"path":"visualization.html","id":"geom_histogram","chapter":"1 Visualization","heading":"1.2.4 geom_histogram()","text":"Let’s consider temp variable weather data frame , unlike linegraphs, let’s say don’t care relationship time, rather care values temp distribute. words:smallest largest values?“center” “typical” value?values spread ?frequent infrequent values?One way visualize distribution single variable temp plot horizontal line:gives us general idea values temp distribute: observe temperatures vary around\n11°F (-11°C) 100°F (38°C). Furthermore, appear recorded temperatures 40°F 60°F outside range. However, high degree overplotting points, ’s hard get sense exactly many values say 50°F 55°F.commonly produced instead horizontal line plot known histogram. histogram plot visualizes distribution numerical value follows:first cut x-axis series bins, bin represents range values.bin, count number observations fall range corresponding bin.bin, draw bar whose height marks corresponding count.Let’s drill-example histogram.Let’s focus temperatures 30°F (-1°C) 60°F (15°C) now. Observe three bins equal width 30°F 60°F. Thus three bins width 10°F : one bin 30-40°F range, another bin 40-50°F range, another bin 50-60°F range. Since:bin 30-40°F range height around 5000. words, around 5000 hourly temperature recordings 30°F 40°F.bin 40-50°F range height around 4300. words, around 4300 hourly temperature recordings 40°F 50°F.bin 50-60°F range height around 3500. words, around 3500 hourly temperature recordings 50°F 60°F.nine bins spanning 10°F 100°F x-axis interpretation.Let’s now present ggplot() code plot first histogram! Unlike scatterplots linegraphs, now one variable mapped aes(): single numerical variable temp. y-aesthetic histogram, count observations bin, gets computed automatically. Furthermore, geometric object layer now geom_histogram(). running following code create histogram hourly temperatures three NYC airports, ’ll see histogram well warning messages. ’ll discuss warning messages first.first message telling us histogram constructed using bins = 30 30 equally spaced bins. known computer programming default value; unless override default number bins number specify, R choose 30 default. ’ll see next section change number bins another value default.second message telling us something similar warning message received ran code create scatterplot departure arrival delays Alaska Airlines flights: one row missing NA value temp, omitted histogram. R just giving us friendly heads case.Now let’s unpack resulting histogram. Observe values less 25°F well values 80°F rather rare. However, large number bins, ’s hard get sense range temperatures spanned bin; everything one giant amorphous blob. let’s add white vertical borders demarcating bins adding color = \"white\" argument geom_histogram() ignore warning setting number bins better value:now easier time associating ranges temperatures bins. can also vary color bars setting fill argument. example, can set bin colors “blue steel” setting fill = \"steelblue\":’re curious, run colors() see 657 possible choice colors R!Observe last histogram created 50-75°F range appear roughly 8 bins. Thus bin width 25 divided 8, 3.125°F, easily interpretable range work . Let’s improve adjusting number bins histogram one two ways:adjusting number bins via bins argument geom_histogram().adjusting width bins via binwidth argument geom_histogram().Using first method, power specify many bins like cut x-axis . mentioned previous section, default number bins 30. can override default, say 40 bins, follows:Using second method, instead specifying number bins, specify width bins using binwidth argument geom_histogram() layer. example, let’s set width bin 10°F.compare resulting histograms side--side.","code":"## Warning: Removed 1 rows containing missing values (geom_point).\nggplot(data = weather, mapping = aes(x = temp)) + geom_histogram()## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.## Warning: Removed 1 rows containing non-finite values (stat_bin).\nggplot(data = weather, mapping = aes(x = temp)) +\n  geom_histogram(color = \"white\")\nggplot(data = weather, mapping = aes(x = temp)) +\n  geom_histogram(color = \"white\", fill = \"steelblue\")\nggplot(data = weather, mapping = aes(x = temp)) +\n  geom_histogram(bins = 40, color = \"white\")\nggplot(data = weather, mapping = aes(x = temp)) +\n  geom_histogram(binwidth = 10, color = \"white\")"},{"path":"visualization.html","id":"geom_boxplot","chapter":"1 Visualization","heading":"1.2.5 geom_boxplot()","text":"faceted histograms one type visualization used compare distribution numerical variable split values another variable, another type visualization achieves goal side--side boxplot. boxplot constructed information provided five-number summary numerical variable.keep things simple now, let’s consider 2141 hourly temperature recordings month November, represented jittered point.2141 observations following five-number summary:Minimum: 21°FFirst quartile (25th percentile): 36°FMedian (second quartile, 50th percentile): 45°FThird quartile (75th percentile): 52°FMaximum: 71°FIn leftmost plot, let’s mark 5 values dashed horizontal lines top 2141 points. middle plot, let’s add boxplot. rightmost plot, let’s remove points dashed horizontal lines clarity’s sake.boxplot visually summarize \n2141 points cutting 2141 temperature recordings quartiles dashed lines, quartile contains\nroughly 2141 \\(\\div\\) 4 \\(\\approx\\)\n535 observations. Thus25% points fall bottom edge box, first quartile 36°F. words, 25% observations 36°F.25% points fall bottom edge box solid middle line, median 45°F. Thus, 25% observations 36°F 45°F 50% observations 45°F.25% points fall solid middle line top edge box, third quartile 52°F. follows 25% observations 45°F 52°F 75% observations 52°F.25% points fall top edge box. words, 25% observations 52°F.middle 50% points lie within interquartile range (IQR) first third quartile. Thus, IQR example 52 - 36 = 16°F. interquartile range measure numerical variable’s spread.Furthermore, rightmost plot, see whiskers boxplot. whiskers stick either end box way minimum maximum observed temperatures 21°F 71°F, respectively. However, whiskers don’t always extend smallest largest observed values . fact extend 1.5 \\(\\times\\) interquartile range either end box. case November temperatures, 1.5 \\(\\times\\) 16°F = 24°F either end box. observed values outside range get marked points called outliers, ’ll see next section.Let’s now create side--side boxplot hourly temperatures split 12 months previously faceted histograms. mapping month variable x-position aesthetic, temp variable y-position aesthetic, adding geom_boxplot() layer:Observe plot provide information temperature separated month. first warning message clues us . telling us “continuous”, numerical variable, x-position aesthetic. Boxplots, however, require categorical variable mapped x-position aesthetic. second warning message identical warning message plotting histogram hourly temperatures: one values recorded NA missing.can convert numerical variable month factor categorical variable using factor() function. applying factor(month), month goes numerical values 1, 2, …, 12 associated ordering. ordering, ggplot() now knows work variable produce needed plot.resulting plot shows 12 separate “box whiskers” plots similar rightmost plot figure November temperatures. Thus different boxplots shown “side--side.”“box” portions visualization represent 1st quartile, median (2nd quartile), 3rd quartile.height box (value 3rd quartile minus value 1st quartile) interquartile range (IQR). measure spread middle 50% values, longer boxes indicating variability.“whisker” portions plots extend bottoms tops boxes represent points less 25th percentile greater 75th percentiles, respectively. ’re set extend \\(1.5 \\times IQR\\) units away either end boxes. say “” ends whiskers correspond observed temperatures. length whiskers show data outside middle 50% values vary, longer whiskers indicating variability.dots representing values falling outside whiskers called outliers. can thought anomalous (“---ordinary”) values.important keep mind definition outlier somewhat arbitrary absolute. case, defined length whiskers, \n\\(1.5 \\times IQR\\) units long boxplot. Looking side--side plot can see, expected, summer months (6 8) higher median temperatures evidenced higher solid lines middle boxes. can easily compare temperatures across months drawing imaginary horizontal lines across plot. Furthermore, heights 12 boxes quantified interquartile ranges informative ; tell us variability, spread, temperatures recorded given month.","code":"\nggplot(data = weather, mapping = aes(x = month, y = temp)) +\n  geom_boxplot()## Warning: Continuous x aesthetic -- did you forget aes(group=...)?## Warning: Removed 1 rows containing non-finite values (stat_boxplot).\nggplot(data = weather, mapping = aes(x = factor(month), y = temp)) +\n  geom_boxplot()## Warning: Removed 1 rows containing non-finite values (stat_boxplot)."},{"path":"visualization.html","id":"geom_bar","chapter":"1 Visualization","heading":"1.2.6 geom_bar()","text":"histograms boxplots tools visualize distribution numerical variables. Another commonly desired task visualize distribution categorical variable. simpler task, simply counting different categories within categorical variable, also known levels categorical variable. Often best way visualize different counts, also known frequencies, barplots (also called barcharts).Run following code manually creates data frame representing collection fruit: 3 apples 2 oranges. Notice fruits lists fruit individually.Using fruits data frame 5 fruits listed individually 5 rows, map fruit variable x-position aesthetic add geom_bar() layer:Let’s now look flights data frame nycflights13 package visualize distribution categorical variable carrier. words, let’s visualize number domestic flights New York City airline company flew 2013. Since row flights data frame corresponds flight, flights data frame like fruits data frame flights pre-counted carrier. Thus use geom_bar() create barplot. Much like geom_histogram(), one variable aes() aesthetic mapping: variable carrier gets mapped x-position. difference though, histograms bars touch whereas bar graphs white space bars going left right.\nFigure 1.2: Number flights departing NYC 2013 airline using geom_bar().\nObserve United Airlines (UA), JetBlue Airways (B6), ExpressJet Airlines (EV) flights depart NYC 2013. don’t know airlines correspond carrier codes, run View(airlines) see directory airlines. example, B6 JetBlue Airways.","code":"\nfruits <- tibble(fruit = c(\"apple\", \"apple\", \"orange\", \n                           \"apple\", \"orange\"))\n\nfruits## # A tibble: 5 x 1\n##   fruit \n##   <chr> \n## 1 apple \n## 2 apple \n## 3 orange\n## 4 apple \n## 5 orange\nggplot(data = fruits, mapping = aes(x = fruit)) +\n  geom_bar()\nggplot(data = flights, mapping = aes(x = carrier)) +\n  geom_bar()"},{"path":"visualization.html","id":"no-pie-charts","chapter":"1 Visualization","heading":"1.2.6.1 No pie charts!","text":"One common plots used visualize distribution categorical data pie chart. may seem harmless enough, pie charts actually present problem humans unable judge angles well. (???) argues overestimate angles greater 90 degrees underestimate angles less 90 degrees. words, difficult us determine relative size one piece pie compared another.pie charts present information way comparisons must made comparing angles, barplots effective present information way comparisons categories can made single horizontal lines.","code":""},{"path":"visualization.html","id":"two-categorical-variables","chapter":"1 Visualization","heading":"1.2.6.2 Two categorical variables","text":"Barplots common way visualize frequency different categories, levels, single categorical variable. Another use barplots visualize joint distribution two categorical variables time. Let’s examine joint distribution outgoing domestic flights NYC carrier well origin. words, number flights carrier origin combination.example, number WestJet flights JFK, number WestJet flights LGA, number WestJet flights EWR, number American Airlines flights JFK, . Recall ggplot() code created barplot carrier frequency:can now map additional variable origin adding fill = origin inside aes() aesthetic mapping.\nFigure 1.3: Stacked barplot flight amount carrier origin.\nexample stacked barplot. simple make, certain aspects ideal. example, difficult compare heights different colors bars, corresponding comparing number flights origin airport carriers.continue, let’s address common points confusion among new R users. First, fill aesthetic corresponds color used fill bars, color aesthetic corresponds color outline bars. identical added color histogram geom_histogram section: set outline bars white setting color = \"white\" colors bars blue steel setting fill = \"steelblue\". Observe mapping origin color fill yields grey bars different colored outlines.\nFigure 1.4: Stacked barplot color aesthetic used instead fill.\nSecond, note fill another aesthetic mapping much like x-position; thus careful include within parentheses aes() mapping. following code, fill aesthetic specified outside aes() mapping yield error. fairly common error new ggplot users make:alternative stacked barplots side--side barplots, also known dodged barplots. code create side--side barplot identical code create stacked barplot, position = \"dodge\" argument added geom_bar(). words, overriding default barplot type, stacked barplot, specifying side--side barplot instead.\nFigure 1.5: Side--side barplot comparing number flights carrier origin.\nNote width bars , F9, FL, HA YV different others. can make one tweak position argument get size terms width bars using robust position_dodge() function.\nFigure 1.6: Side--side barplot comparing number flights carrier origin (formatting tweak).\n","code":"\nggplot(data = flights, mapping = aes(x = carrier)) + \n  geom_bar()\nggplot(data = flights, mapping = aes(x = carrier, fill = origin)) +\n  geom_bar()\nggplot(data = flights, mapping = aes(x = carrier, color = origin)) +\n  geom_bar()\nggplot(data = flights, mapping = aes(x = carrier), fill = origin) +\n  geom_bar()\nggplot(data = flights, mapping = aes(x = carrier, fill = origin)) +\n  geom_bar(position = \"dodge\")\nggplot(data = flights, mapping = aes(x = carrier, fill = origin)) +\n  geom_bar(position = position_dodge(preserve = \"single\"))"},{"path":"visualization.html","id":"geom_smooth","chapter":"1 Visualization","heading":"1.2.7 geom_smooth()","text":"Now let’s go back geom_point() section add smooth line using geom_smooth() function.’s scatterplot created geom_point() section:Let’s try adding regression line scatterplot using geom_smooth() function combination argument method = lm, lm stands linear model. can add geom_smooth(method = lm) another layer plot.Another method fit line scatter plot called loess method, computes smooth local regression default value small number observations. can read loess using R code ?loess console.’s graph looks like using Loess method local regression fitting:want remove gray area, confidence interval, can set se = FALSE within geom_smooth() function.","code":"## Warning: Removed 5 rows containing missing values (geom_point).## `geom_smooth()` using formula 'y ~ x'## Warning: Removed 5 rows containing non-finite values (stat_smooth).## Warning: Removed 5 rows containing missing values (geom_point).## `geom_smooth()` using formula 'y ~ x'## Warning: Removed 5 rows containing non-finite values (stat_smooth).## Warning: Removed 5 rows containing missing values (geom_point).## `geom_smooth()` using formula 'y ~ x'## Warning: Removed 5 rows containing non-finite values (stat_smooth).## Warning: Removed 5 rows containing missing values (geom_point)."},{"path":"visualization.html","id":"geom_density","chapter":"1 Visualization","heading":"1.2.8 geom_density()","text":"Recall histogram plotted geom_histogram() section.\ncan change geom_histogram() geom_density() make density plot, smoothed version histogram. useful alternative histogram displays continuous data smooth distribution.","code":"\nggplot(data = weather, mapping = aes(x = temp)) + \n  geom_histogram()## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.## Warning: Removed 1 rows containing non-finite values (stat_bin).\nggplot(data = weather, mapping = aes(x = temp)) + \n  geom_density()## Warning: Removed 1 rows containing non-finite values (stat_density)."},{"path":"visualization.html","id":"advanced-plots","chapter":"1 Visualization","heading":"1.3 Advanced Plots","text":"\nFigure 1.7: Data Visualization ggplot2 Cheat Sheet\nprevious section seen three components every plot must include: data, data mappings, geom. may found graphics look bit boring. Luckily, Grammar Graphics allows us add layers order customize plots. go additional layers , Data Visualization ggplot2 Cheat Sheet great resource refer ggplot visualizations get complicated.keep simple, change Gapminder plot beginning chapter layer layer. begin creating subset data plotting subset.moment consists three necessary elements:subset gapminder datasetGDP per capita x-axis, life expectancy y-axis (mappings)geom_point(), creates scatterplot","code":"\ngapminder_07 <- gapminder %>% \n                    filter(year == 2007, continent != \"Oceania\")\nggplot(data = gapminder_07, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point()"},{"path":"visualization.html","id":"faceting","chapter":"1 Visualization","heading":"1.3.1 Faceting","text":"Let’s start introducing new concept called faceting. Faceting used ’d like split particular visualization values another variable. create multiple copies type plot matching x y axes, whose content differ.look plot , quite difficult compare continents despite colors. much easier “split” scatterplot 5 continents dataset. words, create plots gdpPercap lifeExp continent separately. adding facet_wrap(~ continent) layer. Note ~ “tilde” can generally found key next “1” key US keyboards. tilde required ’ll receive error Error .quoted(facets) : object 'month' found don’t include .way better! However, R chooses default 2 plots per row, Asia Europe two continents. can specify number rows columns grid using nrow ncol arguments inside facet_wrap(). Let’s get continents row setting nrow = 1:Note , expected, can see positive correlation economic development life expectancy continents. Now also clearer Asia average level Americas, countries Asia extremes.","code":"\nggplot(data = gapminder_07, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent)\nggplot(data = gapminder_07, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1)"},{"path":"visualization.html","id":"stats","chapter":"1 Visualization","heading":"1.3.2 Stats","text":"next layer stats, statistical transformations. ggplot provides us many different ones, suitable certain types geoms. Take example stat_boxplot(), applicable scatterplots adds boxplots plot:Now recognize differences continents, also within continents better. However, interpretation box plots intuitive, least first glance. easier understand alternative line best fit, can add stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE):two stats, many different purposes. type “stat” console, get suggestions different options ggplot offers.","code":"\nggplot(data = gapminder_07, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_boxplot()\nggplot(data = gapminder_07, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE)"},{"path":"visualization.html","id":"coordinate-systems","chapter":"1 Visualization","heading":"1.3.3 Coordinate Systems","text":"Next, can specify type coordinate system. cases use Cartesian coordinate systems, set coord_cartesian(). R draws every plot default method, don’t need determine specifically. Depending data working , exotic variants like coord_polar() coord_map() may helpful.coordinate system used often coord_flip(). actually just Cartesian coordinate system, name suggests, simply swaps axes:can seen, lifeExp now x-axis gdpPercap y-axis. Compared previous plot now easier observe distribution life expectancy respective continents. example, can see many countries Africa 55 years, Americas Asia 75 years, Europe 80 years. However, think makes sense consider lifeExp dependent variable, don’t use coord_flip() subsequent plots.","code":"\nggplot(data = gapminder_07, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE) + \n  coord_flip()"},{"path":"visualization.html","id":"positions-axis-limits-and-scales","chapter":"1 Visualization","heading":"1.3.4 Positions, Axis Limits and Scales","text":"can also use ggplot change position plot content. Positions rather “cosmetic” elements, make plots easier understand. , many different options , often work certain geoms. example, work barplots, can use position_dodge() position_stack() specify whether want arrange bars plot side side top . scatterplots like , position_jitter() can used:Notice several things code. First, positions placed geom refer (case geom_point()). Second, positions always start position = followed position type (case position_jitter()). width height optional can freely defined. might wonder difference position_jitter() geom_jitter() . answer : Nothing. R often several functions can lead result. However, practical start geom_point() first, still choice changing position shaking dots - geom_jitter() plot constructed like beginning.Besides position can also manipulate limits axes using xlim() ylim(). example, assume interested countries GDP per capita 0 30000. can tell R follows want see range. Note , data first argument mapping second ggplot(), don’t actually name arguments. can just provide , long correct order.can see GDP per capita y-axis now shown 0 30000.Finally can change scaling axes. example, might useful display axes scale_x_log10() scale_y_log10() logarithmic scale. Let’s try GDP per capita. Also, note can (lazily!) provide explicit x y argument names aes() long provide values right order: x comes y.Notice scale GDP per capita changed (now, don’t worry overlapping labels).","code":"\nggplot(data = gapminder_07, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point(position = position_jitter(width = 10, height = 15)) +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE)\nggplot(gapminder_07, \n       aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE) + \n  xlim(0, 30000)## Warning: Removed 19 rows containing non-finite values (stat_smooth).## Warning: Removed 19 rows containing missing values (geom_point).\nggplot(gapminder_07, \n       aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE) + \n  scale_x_log10()"},{"path":"visualization.html","id":"labels-and-text","chapter":"1 Visualization","heading":"1.3.5 Labels and Text","text":"last plot made looks quite good, perfect yet. noticed default R simply uses names variables axes legends. Also, plot title yet. can easily change using labs():title labs() argument long, can insert newline character — “\\n” — middle, cause title take two lines rather one. simplest way deal titles axis labels long.us, many arguments labs() use. arguments probably self-explanatory, makes sense look last one. determines title legend, always named aesthetic legend refers. Since legend created color argument density plot, can refer color =.can also change labels within plots. Wouldn’t great knew country point refers ? can help geom_text():Great! Notice need determine aesthetic called label. defines character variable used basis labels.","code":"\nggplot(gapminder_07, \n       aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE) + \n  scale_x_log10() +\n  labs(title = \"Life Expectancy and GDP per Capita (2007)\",\n       subtitle = \"Selected Nations by Continent\",\n       x = \"GDP per Capita, USD\",\n       y = \"Life Expectancy, Years\",\n       caption = \"Source: Gapminder\") \nggplot(gapminder_07, \n       aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE) + \n  scale_x_log10() +\n  labs(title = \"Life Expectancy and GDP per Capita (2007)\",\n       subtitle = \"Selected Nations by Continent\",\n       x = \"GDP per Capita, USD\",\n       y = \"Life Expectancy, Years\",\n       caption = \"Source: Gapminder\") +\n  geom_text(aes(label = country), size = 2, \n            color = \"black\", check_overlap = TRUE)"},{"path":"visualization.html","id":"themes","chapter":"1 Visualization","heading":"1.3.6 Themes","text":"almost finished, plot still boring default design. ggplot provides called themes, can used change overall appearance plot without much effort. example, theme_linedraw() uses white background black text:can find overview different themes ggplot . ggthemes package even adds additional themes.addition ready--use themes, theme() function also offers wide selection functions manually changing individual elements. Let’s remove legend, change font plot enlarge axis labels bit:Now take moment compare plot one started :can see things necessary create plot, can make big difference much information can derive . way, remember mentioned Grammar Graphics said build plots layer layer? exactly .","code":"\nggplot(gapminder_07, \n       aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE) + \n  scale_x_log10() +\n  labs(title = \"Life Expectancy and GDP per Capita (2007)\",\n       subtitle = \"Selected Nations by Continent\",\n       x = \"GDP per Capita, USD\",\n       y = \"Life Expectancy, Years\",\n       caption = \"Source: Gapminder\",\n       color = \"Continent\") +\n  geom_text(aes(label = country), size = 2, \n            color = \"black\", check_overlap = TRUE) +\n  theme_linedraw()\nggplot(gapminder_07, \n       aes(gdpPercap, lifeExp, color = continent)) +\n  geom_point() +\n  facet_wrap(~ continent, nrow = 1) +\n  stat_smooth(formula = y ~ x, method = \"lm\", se = FALSE) + \n  scale_x_log10() +\n  labs(title = \"Life Expectancy and GDP per Capita (2007)\",\n       subtitle = \"Selected Nations by Continent\",\n       x = \"GDP per Capita, USD\",\n       y = \"Life Expectancy, Years\",\n       caption = \"Source: Gapminder\",\n       color = \"Continent\") +\n  geom_text(aes(label = country), size = 2, \n            color = \"black\", check_overlap = TRUE) +\n  theme_linedraw() +\n  theme(legend.position = \"none\", \n        text = element_text(family = \"Palatino\"),\n        axis.text.x = element_text(size = 11),\n        axis.text.y = element_text(size = 10))\nggplot(data = gapminder_07, \n       mapping = aes(x = gdpPercap, y = lifeExp, color = continent)) +\n  geom_point()"},{"path":"visualization.html","id":"the-tidyverse","chapter":"1 Visualization","heading":"1.4 The Tidyverse","text":"Let’s go important points specifying arguments (.e., inputs) functions. Run following two segments code:’ll notice code segments create barplot, even though second segment omitted data = mapping = code argument names. ggplot() function default assumes data argument comes first mapping argument comes second. long specify data frame question first aes() mapping second, can omit explicit statement argument names data = mapping =.Going forward rest book, ggplot() code like second segment: data = mapping = explicit naming argument omitted default ordering arguments respected. ’ll brevity’s sake; ’s common see style reviewing R users’ code.Data “wild” never ready visualization. can’t use beautiful plots learned previous chapter “wrangled” data convenient shape. chapter, ’ll introduce series functions tidyverse collection packages help wrangling, everything else need work data. functions include:filter() data frame’s existing rows pick subset . example, alaska_flights data frame.select() specific variable columns data set. example, choose dep_delay arr_delay variables easily view relationship two. Additional functions like slice() can subset data.arrange() rows. example, sort rows weather ascending descending order temp.group_by() rows. words, assign different rows part group. can combine group_by() summarize() report summary statistics group separately. example, say don’t want single overall average departure delay dep_delay three origin airports combined, rather three separate average departure delays, one computed three origin airports.mutate() existing columns/variables create new ones. example, convert hourly temperature recordings degrees Fahrenheit degrees Celsius.Notice used computer_code font describe actions want take data frames. dplyr package, one packages tidyverse, intuitively verb-named functions easy remember.benefit learning use dplyr package data wrangling: similarity database querying language SQL (pronounced “sequel” spelled “S”, “Q”, “L”). SQL (stands “Structured Query Language”) used manage large databases quickly efficiently widely used many institutions lot data. SQL topic left book course database management, keep mind learn dplyr, can learn SQL easily.","code":"\nggplot(data = flights, mapping = aes(x = carrier)) +\n  geom_bar()\nggplot(flights, aes(x = carrier)) +\n  geom_bar()"},{"path":"visualization.html","id":"the-pipe-operator","chapter":"1 Visualization","heading":"1.4.1 The pipe operator: %>%","text":"start data wrangling, let’s first introduce nifty tool gets loaded dplyr package included tidyverse: pipe operator %>%. pipe operator allows us combine multiple operations R single sequential chain actions.Recall chapter 1 add geom layer ggplot format code :Without + end first row, computer know continue onto second. occur without pipe operator. instance, take look following code. can run Rstudio console. happens?Without pipe operator, filter() function work computer know use flights dataset operation within parentheses. become clearer practice using dplyr functions.result transformed/modified data frame want. example, ’ll save result new data frame using <- assignment operator name alaska_flights via alaska_flights <-. assigned modified data frame alaska_flights, separate entity initial flights data frame. , however, written code flights <- flights overwritten previous data frame, original flights data **nycflights13* package re-installed access .Much like adding layers ggplot() using + sign, form single chain data wrangling operations combining verb-named functions single sequence using pipe operator %>%. Furthermore, much like + sign come end lines constructing plots, pipe operator %>% come end lines well. Note also pipe operator can used multiple times sequentially. Simply include end line, following function immediately linked output previous line containing operator. call text within parentheses argument(s) function.worth noting dplyr verbs, well functions larger tidyverse, achieve effect always first argument input tibble. example, look ?dplyr::filter see , example, first argument filter() tibble named .data. , can rewrite code snippet :“.” serves special role using pipes. represents tibble “passed ” previous step pipe. , telling R “.” — flights case — first argument filter(). Since argument names used, can rewrite :almost never write code looks like , least simple dplyr verbs like filter(). , behind scenes, going . , advanced cases, need use “.” refer passed-tibble.Keep mind, many advanced data wrangling functions just six listed introduction chapter; ’ll see examples Section ??. However, just six verb-named functions ’ll able perform broad array data wrangling tasks rest book.","code":"\nggplot(data = flights, mapping = aes(x = carrier, fill = origin)) +\n  geom_bar(position = \"dodge\")\nalaska_flights <- flights \n  filter(carrier == \"AS\")\nalaska_flights <- flights %>% \n  filter(carrier == \"AS\")\nalaska_flights <- flights %>% \n  filter(.data = ., carrier == \"AS\")\nalaska_flights <- flights %>% \n  filter(., carrier == \"AS\")"},{"path":"visualization.html","id":"filter-rows","chapter":"1 Visualization","heading":"1.4.2 filter() rows","text":"\nFigure 1.8: Diagram filter() rows operation.\nfilter() function works much like “Filter” option Microsoft Excel; allows specify criteria values variable dataset filters rows match criteria.begin focusing flights New York City Portland, Oregon. dest destination code (airport code) Portland, Oregon \"PDX\". Run following look results RStudio’s spreadsheet viewer ensure flights heading Portland chosen :Note order code. First, take flights data frame flights filter() data frame dest equals \"PDX\" included. test equality using double equal sign == single equal sign =. words filter(dest = \"PDX\") yield error. convention across many programming languages. new coding, ’ll probably forget use double equal sign == times get hang .can use operators beyond just == operator tests equality:> corresponds “greater ”< corresponds “less ”>= corresponds “greater equal ”<= corresponds “less equal ”!= corresponds “equal .” ! used many programming languages indicate “.”Furthermore, can combine multiple criteria using operators make comparisons:| corresponds “”& corresponds “”see many action, let’s filter flights rows departed JFK heading Burlington, Vermont (\"BTV\") Seattle, Washington (\"SEA\") departed months October, November, December. Run following:Note even though colloquially speaking one might say “flights leaving Burlington, Vermont Seattle, Washington,” terms computer operations, really mean “flights leaving Burlington, Vermont leaving Seattle, Washington.” given row data, dest can \"BTV\", \"SEA\", something else, \"BTV\" \"SEA\" time. Furthermore, note careful use parentheses around dest == \"BTV\" | dest == \"SEA\".can often skip use & just separate conditions comma. previous code return identical output btv_sea_flights_fall following code:Let’s present another example uses ! “” operator pick rows don’t match criteria. mentioned earlier, ! can read “.” filtering rows corresponding flights didn’t go Burlington, VT Seattle, WA., note careful use parentheses around (dest == \"BTV\" | dest == \"SEA\"). didn’t use parentheses follows:returning flights headed \"BTV\" headed \"SEA\", entirely different resulting data frame.Now say larger number airports want filter , say \"SEA\", \"SFO\", \"PDX\", \"BTV\", \"BDL\". continue use | () operator:progressively include airports, get unwieldy write. slightly shorter approach uses %% operator along c() function. Recall Subsection ?? c() function “combines” “concatenates” values single vector values.One common mistakes use == filter() rather %%. diabolical since won’t fail , certain situations, might even issue warning. Beware!code filtering flights flights dest vector airports c(\"BTV\", \"SEA\", \"PDX\", \"SFO\", \"BDL\"). outputs many_airports , can see latter takes much less energy code. %% operator useful looking matches commonly one vector/variable compared another.final note, recommend filter() often among first verbs consider applying data. cleans dataset rows care , put differently, narrows scope data frame just observations care .","code":"\nportland_flights <- flights %>% \n  filter(dest == \"PDX\")\nView(portland_flights)\nbtv_sea_flights_fall <- flights %>% \n  filter(origin == \"JFK\" & \n           (dest == \"BTV\" | dest == \"SEA\") & \n           month >= 10)\nView(btv_sea_flights_fall)\nbtv_sea_flights_fall <- flights %>% \n  filter(origin == \"JFK\", \n         (dest == \"BTV\" | dest == \"SEA\"), \n         month >= 10)         \nView(btv_sea_flights_fall)\nnot_BTV_SEA <- flights %>% \n  filter(!(dest == \"BTV\" | dest == \"SEA\"))\nView(not_BTV_SEA)\nflights %>% filter(!dest == \"BTV\" | dest == \"SEA\")\nmany_airports <- flights %>% \n  filter(dest == \"SEA\" | dest == \"SFO\" | dest == \"PDX\" | \n         dest == \"BTV\" | dest == \"BDL\")\nmany_airports <- flights %>% \n  filter(dest %in% c(\"SEA\", \"SFO\", \"PDX\", \"BTV\", \"BDL\"))\nView(many_airports)"},{"path":"visualization.html","id":"select-variables","chapter":"1 Visualization","heading":"1.4.3 select variables","text":"\nFigure 1.9: Diagram select() columns.\nUsing filter() function able pick specific rows dataset. select() function allows R users pick specific columns/variables instead.’ve seen flights data frame nycflights13 package contains 19 different variables. can identify names 19 variables running glimpse() function dplyr package:However, say need two 19 variables, say carrier flight. can select() two variables:function makes easier explore large datasets since allows us limit scope variables care . example, select() smaller number variables shown Figure ??, make viewing dataset RStudio’s spreadsheet viewer digestible. Using select() can also useful creating ggplot2 visualizations need variables.Let’s say instead want drop, de-select, certain variables. example, consider variable year flights data frame. variable isn’t quite “variable” always 2013 hence doesn’t change. Say want remove variable data frame. can deselect year using - sign:Another way selecting columns/variables specifying range columns:select() columns month day (including two specified columns), well arr_time sched_arr_time, drop rest.select() function can also used reorder columns used everything() helper function. example, suppose want hour, minute, time_hour variables appear immediately year, month, day variables, discarding rest variables. following code, everything() pick remaining variables:Lastly, helper functions starts_with(), ends_with(), contains() can used select variables/columns match conditions. examples,","code":"\nglimpse(flights)\nflights %>% \n  select(carrier, flight)\nflights_no_year <- flights %>% select(-year)\nflight_arr_times <- flights %>% select(month:day, arr_time:sched_arr_time)\nflight_arr_times\nflights_reorder <- flights %>% \n  select(year, month, day, hour, minute, time_hour, everything())\nglimpse(flights_reorder)\nflights %>% select(starts_with(\"a\"))\nflights %>% select(ends_with(\"delay\"))\nflights %>% select(contains(\"time\"))"},{"path":"visualization.html","id":"slice-and-pull-and","chapter":"1 Visualization","heading":"1.4.4 slice() and pull() and []","text":"slice() pull() additional functions can use pick specific rows columns within data frame.Using slice() gives us specific rows flights tibble:Unlike filter(), slice() relies numeric order data.pull() grabs variable vector, rather leaving within tibble, select() :often handy want feed data function, like mean() requires vector input:common way subset vectors use “bracket” operator []. Example:","code":"\nslice(flights, 2:5)## # A tibble: 4 x 19\n##    year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n##   <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n## 1  2013     1     1      533            529         4      850            830\n## 2  2013     1     1      542            540         2      923            850\n## 3  2013     1     1      544            545        -1     1004           1022\n## 4  2013     1     1      554            600        -6      812            837\n## # … with 11 more variables: arr_delay <dbl>, carrier <chr>, flight <int>,\n## #   tailnum <chr>, origin <chr>, dest <chr>, air_time <dbl>, distance <dbl>,\n## #   hour <dbl>, minute <dbl>, time_hour <dttm>\nslice(flights, 2:5) %>% \n  pull(dep_time)## [1] 533 542 544 554\nslice(flights, 2:5) %>% \n  pull(dep_time) %>% \n  mean()## [1] 543\nflights$dep_time[2:5]## [1] 533 542 544 554"},{"path":"visualization.html","id":"arrange-rows","chapter":"1 Visualization","heading":"1.4.5 arrange() rows","text":"One commonly performed data wrangling tasks sort data frame’s rows alphanumeric order one variables. Unlike filter() select(), arrange() remove rows columns data frame. Instead, dplyr package’s arrange() function allows us sort/reorder data frame’s rows according values specified variable.Suppose interested determining flight covers distance domestic flights departing New York City 2013:First, let’s select() pertinent variables make data easy read.order data appears maintained original flights data set. Say instead like see data, sorted distance flight (farthest shortest distance)., however, opposite want. rows sorted flights covering least distance displayed first. arrange() always returns rows sorted ascending order default. switch ordering “descending” order instead, use desc() function like :Let’s try one time character variable. happens try sort destination (dest) variable?can see, character variables sorted alphabetically. Using desc() helper function character variable, sort destinations reverse alphabetically.","code":"\nflights_dist <- flights %>% \n  select(origin, dest, air_time, distance)\nflights_dist## # A tibble: 336,776 x 4\n##    origin dest  air_time distance\n##    <chr>  <chr>    <dbl>    <dbl>\n##  1 EWR    IAH        227     1400\n##  2 LGA    IAH        227     1416\n##  3 JFK    MIA        160     1089\n##  4 JFK    BQN        183     1576\n##  5 LGA    ATL        116      762\n##  6 EWR    ORD        150      719\n##  7 EWR    FLL        158     1065\n##  8 LGA    IAD         53      229\n##  9 JFK    MCO        140      944\n## 10 LGA    ORD        138      733\n## # … with 336,766 more rows\nflights_dist %>% \n  arrange(distance)## # A tibble: 336,776 x 4\n##    origin dest  air_time distance\n##    <chr>  <chr>    <dbl>    <dbl>\n##  1 EWR    LGA         NA       17\n##  2 EWR    PHL         30       80\n##  3 EWR    PHL         30       80\n##  4 EWR    PHL         28       80\n##  5 EWR    PHL         32       80\n##  6 EWR    PHL         29       80\n##  7 EWR    PHL         22       80\n##  8 EWR    PHL         25       80\n##  9 EWR    PHL         30       80\n## 10 EWR    PHL         27       80\n## # … with 336,766 more rows\nflights_dist %>% \n  arrange(desc(distance))## # A tibble: 336,776 x 4\n##    origin dest  air_time distance\n##    <chr>  <chr>    <dbl>    <dbl>\n##  1 JFK    HNL        659     4983\n##  2 JFK    HNL        638     4983\n##  3 JFK    HNL        616     4983\n##  4 JFK    HNL        639     4983\n##  5 JFK    HNL        635     4983\n##  6 JFK    HNL        611     4983\n##  7 JFK    HNL        612     4983\n##  8 JFK    HNL        645     4983\n##  9 JFK    HNL        640     4983\n## 10 JFK    HNL        633     4983\n## # … with 336,766 more rows\nflights_dist %>%\n  arrange(dest)## # A tibble: 336,776 x 4\n##    origin dest  air_time distance\n##    <chr>  <chr>    <dbl>    <dbl>\n##  1 JFK    ABQ        230     1826\n##  2 JFK    ABQ        238     1826\n##  3 JFK    ABQ        251     1826\n##  4 JFK    ABQ        257     1826\n##  5 JFK    ABQ        242     1826\n##  6 JFK    ABQ        240     1826\n##  7 JFK    ABQ        246     1826\n##  8 JFK    ABQ        233     1826\n##  9 JFK    ABQ        236     1826\n## 10 JFK    ABQ        245     1826\n## # … with 336,766 more rows"},{"path":"visualization.html","id":"mutate","chapter":"1 Visualization","heading":"1.4.6 mutate()","text":"\nFigure 1.10: Diagram mutate() columns.\nAnother common transformation data create/compute new variables based existing ones. example, say comfortable thinking temperature degrees Celsius (°C) instead degrees Fahrenheit (°F). formula convert temperatures °F °C \\[\n\\text{temp C} = \\frac{\\text{temp F} - 32}{1.8}\n\\]can apply formula temp variable using mutate() function dplyr package, takes existing variables mutates create new ones.code, mutate() weather data frame creating new variable temp_in_C = (temp - 32) / 1.8 overwrite original weather data frame. overwrite data frame weather, instead assigning result new data frame like weather_new? rough rule thumb, long losing original information might need later, ’s acceptable practice overwrite existing data frames updated ones, . hand, overwrite variable temp, instead created new variable called temp_in_C? , erased original information contained temp temperatures Fahrenheit may still valuable us.Let’s now compute monthly average temperatures °F °C using group_by() summarize() code saw Section ??:Let’s consider another example. Passengers often frustrated flight departs late, aren’t annoyed , end, pilots can make time flight. known airline industry gain, create variable using mutate() function:Let’s take look dep_delay, arr_delay, resulting gain variables first 5 rows updated flights data frame Table ??.flight first row departed 2 minutes late arrived 11 minutes late, “gained time air” loss 9 minutes, hence gain 2 - 11 = -9. hand, flight fourth row departed minute early (dep_delay -1) arrived 18 minutes early (arr_delay -18), “gained time air” \\(-1 - (-18) = -1 + 18 = 17\\) minutes, hence gain +17.Recall Section ?? since gain numerical variable, can visualize distribution using histogram.\nFigure 1.11: Histogram gain variable.\nresulting histogram Figure 1.11 provides different perspective gain variable summary statistics computed earlier. example, note values gain right around 0.close discussion mutate() function create new variables, note can create multiple new variables mutate() code. Furthermore, within mutate() code can refer new variables just created. example, consider code (???):","code":"\nweather <- weather %>% \n  mutate(temp_in_C = (temp - 32) / 1.8)\nsummary_monthly_temp <- weather %>% \n  group_by(month) %>% \n  summarize(mean_temp_in_F = mean(temp, na.rm = TRUE), \n            mean_temp_in_C = mean(temp_in_C, na.rm = TRUE))## `summarise()` ungrouping output (override with `.groups` argument)\nsummary_monthly_temp## # A tibble: 12 x 3\n##    month mean_temp_in_F mean_temp_in_C\n##    <int>          <dbl>          <dbl>\n##  1     1           35.6           2.02\n##  2     2           34.3           1.26\n##  3     3           39.9           4.38\n##  4     4           51.7          11.0 \n##  5     5           61.8          16.6 \n##  6     6           72.2          22.3 \n##  7     7           80.1          26.7 \n##  8     8           74.5          23.6 \n##  9     9           67.4          19.7 \n## 10    10           60.1          15.6 \n## 11    11           45.0           7.22\n## 12    12           38.4           3.58\nflights <- flights %>% \n  mutate(gain = dep_delay - arr_delay)## # A tibble: 5 x 3\n##   dep_delay arr_delay  gain\n##       <dbl>     <dbl> <dbl>\n## 1         2        11    -9\n## 2         4        20   -16\n## 3         2        33   -31\n## 4        -1       -18    17\n## 5        -6       -25    19\nggplot(data = flights, mapping = aes(x = gain)) +\n  geom_histogram(color = \"white\", bins = 20)## Warning: Removed 9430 rows containing non-finite values (stat_bin).\nflights <- flights %>% \n  mutate(gain = dep_delay - arr_delay,\n         hours = air_time / 60,\n         gain_per_hour = gain / hours)"},{"path":"visualization.html","id":"ifelse","chapter":"1 Visualization","heading":"1.4.6.1 ifelse()","text":"ifelse() three arguments. first argument test logical vector. result contain value second argument, yes, test TRUE, value third argument, , FALSE. Imagine want create new variable E, TRUE color diamond “E” FALSE otherwise.Alternatively ifelse(), use dplyr::case_when(). case_when() particularly useful inside mutate want create new variable relies complex combination existing variables. Note robust version ifelse() dplyr: if_else(). works exactly standard version somewhat robust.\nFigure 1.12: (ref:groupby)\n","code":"\ndiamonds %>% \n  select(carat, color, price) %>% \n  mutate(E = ifelse(color == \"E\", TRUE, FALSE))## # A tibble: 53,940 x 4\n##    carat color price E    \n##    <dbl> <ord> <int> <lgl>\n##  1 0.23  E       326 TRUE \n##  2 0.21  E       326 TRUE \n##  3 0.23  E       327 TRUE \n##  4 0.290 I       334 FALSE\n##  5 0.31  J       335 FALSE\n##  6 0.24  J       336 FALSE\n##  7 0.24  I       336 FALSE\n##  8 0.26  H       337 FALSE\n##  9 0.22  E       337 TRUE \n## 10 0.23  H       338 FALSE\n## # … with 53,930 more rows"},{"path":"visualization.html","id":"summarize","chapter":"1 Visualization","heading":"1.4.7 summarize()","text":"next common task working data frames compute summary statistics. Summary statistics single numerical values summarize large number values. Commonly known examples summary statistics include mean (also called average) median (middle value). examples summary statistics might immediately come mind include sum, smallest value also called minimum, largest value also called maximum, standard deviation.Return familiar dataset. Let’s calculate two summary statistics temp temperature variable weather data frame: mean standard deviation. compute summary statistics, need mean() sd() summary functions R. Summary functions R take many values return single value.Recall output summary() function.function offers array summary statistics columns dataset, summarize() (alternatively summarise()) allows us calculate statistics individual columns dataset.precisely, ’ll use mean() sd() summary functions within summarize() function dplyr package. Note can also use British English spelling summarise(). summarize() function takes data frame returns data frame one row corresponding summary statistics.’ll save results new data frame called summary_temp two columns/variables: mean std_dev:values returned NA?`NA R encodes missing values NA indicates “available” “applicable.” value particular row particular column exist, NA stored instead. Values can missing many reasons. Perhaps data collected someone forgot enter ? Perhaps data collected difficult ? Perhaps erroneous value someone entered corrected read missing? ’ll often encounter issues missing values working real data.Going back summary_temp output, default time try calculate summary statistic variable one NA missing values R, NA returned. work around fact, can set na.rm argument TRUE, rm short “remove”; ignore NA missing values return summary value non-missing values.code follows computes mean standard deviation non-missing values temp:Notice na.rm = TRUE used arguments mean() sd() summary functions individually, summarize() function.However, one needs cautious whenever ignoring missing values ’ve just done. possible ramifications blindly sweeping rows missing values “rug.” fact na.rm argument summary statistic function R set FALSE default. words, R ignore rows missing values default. R alerting presence missing data mindful missingness potential causes missingness throughout analysis.","code":"##     origin               year          month           day            hour     \n##  Length:26115       Min.   :2013   Min.   : 1.0   Min.   : 1.0   Min.   : 0.0  \n##  Class :character   1st Qu.:2013   1st Qu.: 4.0   1st Qu.: 8.0   1st Qu.: 6.0  \n##  Mode  :character   Median :2013   Median : 7.0   Median :16.0   Median :11.0  \n##                     Mean   :2013   Mean   : 6.5   Mean   :15.7   Mean   :11.5  \n##                     3rd Qu.:2013   3rd Qu.: 9.0   3rd Qu.:23.0   3rd Qu.:17.0  \n##                     Max.   :2013   Max.   :12.0   Max.   :31.0   Max.   :23.0  \n##                                                                                \n##       temp          dewp         humid        wind_dir     wind_speed  \n##  Min.   : 11   Min.   :-10   Min.   : 13   Min.   :  0   Min.   :   0  \n##  1st Qu.: 40   1st Qu.: 26   1st Qu.: 47   1st Qu.:120   1st Qu.:   7  \n##  Median : 55   Median : 42   Median : 62   Median :220   Median :  10  \n##  Mean   : 55   Mean   : 41   Mean   : 63   Mean   :200   Mean   :  11  \n##  3rd Qu.: 70   3rd Qu.: 58   3rd Qu.: 79   3rd Qu.:290   3rd Qu.:  14  \n##  Max.   :100   Max.   : 78   Max.   :100   Max.   :360   Max.   :1048  \n##  NA's   :1     NA's   :1     NA's   :1     NA's   :460   NA's   :4     \n##    wind_gust         precip        pressure        visib     \n##  Min.   :16      Min.   :0.00   Min.   : 984   Min.   : 0.0  \n##  1st Qu.:21      1st Qu.:0.00   1st Qu.:1013   1st Qu.:10.0  \n##  Median :24      Median :0.00   Median :1018   Median :10.0  \n##  Mean   :25      Mean   :0.00   Mean   :1018   Mean   : 9.3  \n##  3rd Qu.:29      3rd Qu.:0.00   3rd Qu.:1023   3rd Qu.:10.0  \n##  Max.   :67      Max.   :1.21   Max.   :1042   Max.   :10.0  \n##  NA's   :20778                  NA's   :2729                 \n##    time_hour                     temp_in_C  \n##  Min.   :2013-01-01 01:00:00   Min.   :-12  \n##  1st Qu.:2013-04-01 21:30:00   1st Qu.:  4  \n##  Median :2013-07-01 14:00:00   Median : 13  \n##  Mean   :2013-07-01 18:26:37   Mean   : 13  \n##  3rd Qu.:2013-09-30 13:00:00   3rd Qu.: 21  \n##  Max.   :2013-12-30 18:00:00   Max.   : 38  \n##                                NA's   :1\nsummary_temp <- weather %>% \n  summarize(mean = mean(temp), std_dev = sd(temp))\nsummary_temp## # A tibble: 1 x 2\n##    mean std_dev\n##   <dbl>   <dbl>\n## 1    NA      NA\nsummary_temp <- weather %>% \n  summarize(mean = mean(temp, na.rm = TRUE), \n            std_dev = sd(temp, na.rm = TRUE))\nsummary_temp## # A tibble: 1 x 2\n##    mean std_dev\n##   <dbl>   <dbl>\n## 1  55.3    17.8"},{"path":"visualization.html","id":"basic-statistical-terms","chapter":"1 Visualization","heading":"1.4.8 Basic statistical terms","text":"summary functions can use inside summarize() verb compute summary statistics? can use function R takes many values returns just one. just :mean(): averagemin() max(): minimum maximum values, respectivelysd(): standard deviation, measure spreadsum(): total amount adding multiple numbersn(): count number rowsn_distinct(): number distinct valuesmean()mean commonly reported measure center. commonly called average though term can little ambiguous. mean sum data elements divided many elements . \\(n\\) data points, mean given :\\[Mean = \\frac{x_1 + x_2 + \\cdots + x_n}{n}\\]median()median calculated first sorting variable’s data smallest largest. sorting data, middle element list median. middle falls two values, median mean two middle values.sd()next discuss standard deviation (\\(sd\\)) variable. formula can little intimidating first important remember essentially measure far expect given data value mean:\\[sd = \\sqrt{\\frac{(x_1 - Mean)^2 + (x_2 - Mean)^2 + \\cdots + (x_n - Mean)^2}{n - 1}}\\]Let’s return gain variable previous chapter look summary statistics considering multiple summary functions summarize() code:see example average gain +5 minutes, largest +109 minutes! However, code take time type practice.can also run summary statistics across() multiple columns time. get better understanding across() helper function, run ?across console see arguments takes. Suppose wanted take mean() temp dewp variables., encounter NA values missing values, set na.rm = TRUE argument mean() function.","code":"\nflights %>% \n  mutate(gain = arr_delay - dep_delay) %>% \n  summarize(min = min(gain, na.rm = TRUE),\n            q1 = quantile(gain, 0.25, na.rm = TRUE),\n            median = quantile(gain, 0.5, na.rm = TRUE),\n            q3 = quantile(gain, 0.75, na.rm = TRUE),\n            max = max(gain, na.rm = TRUE),\n            mean = mean(gain, na.rm = TRUE),\n            sd = sd(gain, na.rm = TRUE),\n            missing = sum(is.na(gain)))## # A tibble: 1 x 8\n##     min    q1 median    q3   max  mean    sd missing\n##   <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>   <int>\n## 1  -109   -17     -7     3   196 -5.66  18.0    9430\nweather %>%\n  summarize(across(c(temp, dewp), mean))## # A tibble: 1 x 2\n##    temp  dewp\n##   <dbl> <dbl>\n## 1    NA    NA\nweather %>%\n  summarize(across(c(temp, dewp), ~mean(., na.rm = TRUE)))## # A tibble: 1 x 2\n##    temp  dewp\n##   <dbl> <dbl>\n## 1  55.3  41.4\nweather %>%\n  summarize(across(where(is.numeric), ~mean(.x, na.rm = TRUE)))## # A tibble: 1 x 14\n##    year month   day  hour  temp  dewp humid wind_dir wind_speed wind_gust\n##   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>      <dbl>     <dbl>\n## 1  2013  6.50  15.7  11.5  55.3  41.4  62.5     200.       10.5      25.5\n## # … with 4 more variables: precip <dbl>, pressure <dbl>, visib <dbl>,\n## #   temp_in_C <dbl>"},{"path":"visualization.html","id":"group_by","chapter":"1 Visualization","heading":"1.4.9 group_by()","text":"Say instead single mean temperature whole year, like 12 mean temperatures, one 12 months separately. words, like compute mean temperature split month. can “grouping” temperature observations values another variable, case 12 values variable month. Run following code:Notice warning. R trying save us . warning means tibble issues forth end pipe ungrouped, meaning longer group attribute. probably want happen, default behavior. many cases want keep group attribute, .e., want resulting tibble still grouped month. warning urging us sure want. proper way handle situation, everywhere else use group_by() summarize(), specify .groups argument.code thing first version, issue warning, since made affirmative decision drop grouping variables. See ?summarize discussion possible values .groups.code identical previous code created summary_temp, extra group_by(month) added summarize(). Grouping weather dataset month applying summarize() functions yields data frame displays mean standard deviation temperature split 12 months year.important note group_by() function doesn’t change data frames . Rather changes meta-data, data data, specifically grouping structure. apply summarize() function data frame changes.Run code (forget load package nycflights13 console already):Observe first line output reads # tibble: 336,776 x 20. example meta-data, case number observations/rows variables/columns flights. actual data subsequent table values. Now let’s pipe flights data frame group_by(origin):Observe now additional meta-data: # Groups: origin [3] indicating grouping structure meta-data set based 3 possible levels categorical variable origin: \"EWR\", \"JFK\", \"LGA\". hand, observe data changed: still table 336,776 \\(\\times\\) 19 values.combining group_by() another data wrangling operation, case summarize(), data actually transformed.Let’s revisit n() counting summary function briefly introduced previously. Recall n() function counts rows. opposed sum() summary function returns sum numerical variable. example, suppose ’d like count many flights departed three airports New York City:see Newark (\"EWR\") flights departing 2013 followed \"JFK\" lastly LaGuardia (\"LGA\"). Note subtle important difference sum() n(); sum() returns sum numerical variable, n() returns count number rows/observations.like remove grouping structure meta-data, can pipe resulting data frame ungroup() function:Observe # Groups: origin [3] meta-data longer present.","code":"\nweather %>% \n  group_by(month) %>% \n  summarize(mean = mean(temp, na.rm = TRUE), \n            std_dev = sd(temp, na.rm = TRUE))## `summarise()` ungrouping output (override with `.groups` argument)## # A tibble: 12 x 3\n##    month  mean std_dev\n##    <int> <dbl>   <dbl>\n##  1     1  35.6   10.2 \n##  2     2  34.3    6.98\n##  3     3  39.9    6.25\n##  4     4  51.7    8.79\n##  5     5  61.8    9.68\n##  6     6  72.2    7.55\n##  7     7  80.1    7.12\n##  8     8  74.5    5.19\n##  9     9  67.4    8.47\n## 10    10  60.1    8.85\n## 11    11  45.0   10.4 \n## 12    12  38.4    9.98\nweather %>% \n  group_by(month) %>% \n  summarize(mean = mean(temp, na.rm = TRUE), \n            std_dev = sd(temp, na.rm = TRUE),\n            .groups = \"drop\")## # A tibble: 12 x 3\n##    month  mean std_dev\n##    <int> <dbl>   <dbl>\n##  1     1  35.6   10.2 \n##  2     2  34.3    6.98\n##  3     3  39.9    6.25\n##  4     4  51.7    8.79\n##  5     5  61.8    9.68\n##  6     6  72.2    7.55\n##  7     7  80.1    7.12\n##  8     8  74.5    5.19\n##  9     9  67.4    8.47\n## 10    10  60.1    8.85\n## 11    11  45.0   10.4 \n## 12    12  38.4    9.98\nflights## # A tibble: 336,776 x 22\n##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n##    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n##  1  2013     1     1      517            515         2      830            819\n##  2  2013     1     1      533            529         4      850            830\n##  3  2013     1     1      542            540         2      923            850\n##  4  2013     1     1      544            545        -1     1004           1022\n##  5  2013     1     1      554            600        -6      812            837\n##  6  2013     1     1      554            558        -4      740            728\n##  7  2013     1     1      555            600        -5      913            854\n##  8  2013     1     1      557            600        -3      709            723\n##  9  2013     1     1      557            600        -3      838            846\n## 10  2013     1     1      558            600        -2      753            745\n## # … with 336,766 more rows, and 14 more variables: arr_delay <dbl>,\n## #   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n## #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>,\n## #   gain <dbl>, hours <dbl>, gain_per_hour <dbl>\nflights %>% \n  group_by(origin)## # A tibble: 336,776 x 22\n## # Groups:   origin [3]\n##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n##    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n##  1  2013     1     1      517            515         2      830            819\n##  2  2013     1     1      533            529         4      850            830\n##  3  2013     1     1      542            540         2      923            850\n##  4  2013     1     1      544            545        -1     1004           1022\n##  5  2013     1     1      554            600        -6      812            837\n##  6  2013     1     1      554            558        -4      740            728\n##  7  2013     1     1      555            600        -5      913            854\n##  8  2013     1     1      557            600        -3      709            723\n##  9  2013     1     1      557            600        -3      838            846\n## 10  2013     1     1      558            600        -2      753            745\n## # … with 336,766 more rows, and 14 more variables: arr_delay <dbl>,\n## #   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n## #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>,\n## #   gain <dbl>, hours <dbl>, gain_per_hour <dbl>\nby_origin <- flights %>% \n  group_by(origin) %>% \n  summarize(count = n(), \n            .groups = \"drop\")\n\nby_origin## # A tibble: 3 x 2\n##   origin  count\n##   <chr>   <int>\n## 1 EWR    120835\n## 2 JFK    111279\n## 3 LGA    104662\nflights %>% \n  group_by(origin) %>% \n  ungroup()## # A tibble: 336,776 x 22\n##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n##    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n##  1  2013     1     1      517            515         2      830            819\n##  2  2013     1     1      533            529         4      850            830\n##  3  2013     1     1      542            540         2      923            850\n##  4  2013     1     1      544            545        -1     1004           1022\n##  5  2013     1     1      554            600        -6      812            837\n##  6  2013     1     1      554            558        -4      740            728\n##  7  2013     1     1      555            600        -5      913            854\n##  8  2013     1     1      557            600        -3      709            723\n##  9  2013     1     1      557            600        -3      838            846\n## 10  2013     1     1      558            600        -2      753            745\n## # … with 336,766 more rows, and 14 more variables: arr_delay <dbl>,\n## #   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n## #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>,\n## #   gain <dbl>, hours <dbl>, gain_per_hour <dbl>"},{"path":"visualization.html","id":"grouping-by-more-than-one-variable","chapter":"1 Visualization","heading":"1.4.9.1 Grouping by more than one variable","text":"limited grouping one variable. Say want know number flights leaving three New York City airports month. can also group second variable month using group_by(origin, month):Observe 36 rows by_origin_monthly 12 months 3 airports (EWR, JFK, LGA).group_by(origin, month) group_by(origin) group_by(month)? Let’s investigate:happened second group_by(month) overwrote grouping structure meta-data earlier group_by(origin), end grouping month. lesson want group_by() two variables, include variables time group_by() adding comma variable names.","code":"\nflights %>% \n  group_by(origin, month) %>% \n  summarize(count = n(),\n            .groups = \"drop\")## # A tibble: 36 x 3\n##    origin month count\n##    <chr>  <int> <int>\n##  1 EWR        1  9893\n##  2 EWR        2  9107\n##  3 EWR        3 10420\n##  4 EWR        4 10531\n##  5 EWR        5 10592\n##  6 EWR        6 10175\n##  7 EWR        7 10475\n##  8 EWR        8 10359\n##  9 EWR        9  9550\n## 10 EWR       10 10104\n## # … with 26 more rows\nflights %>% \n  group_by(origin) %>% \n  group_by(month) %>% \n  summarize(count = n(),\n            .groups = \"drop\")## # A tibble: 12 x 2\n##    month count\n##    <int> <int>\n##  1     1 27004\n##  2     2 24951\n##  3     3 28834\n##  4     4 28330\n##  5     5 28796\n##  6     6 28243\n##  7     7 29425\n##  8     8 29327\n##  9     9 27574\n## 10    10 28889\n## 11    11 27268\n## 12    12 28135"},{"path":"visualization.html","id":"summary","chapter":"1 Visualization","heading":"1.5 Summary","text":"first section looked basic concepts terms dealing programming R. section two, learned three basic components make plot: Data, mapping, one multiple geoms. ggplot2 package offers wide range geoms can use create different types plots. third section looked additional elements can use modify plots. include features axis scaling, labeling themes. Finally, fourth section, took look “super package” tidyverse, also includes ggplot2. Besides tools visualization, offers features importing manipulating data, main topic next chapter.Finally, mentioned seen small part R offers. Since R open source software, many independent developers constantly releasing new R packages new features functions. example, can use gganimate package bring gapminder plot life:rayshader package allows us create beautiful landscapes maps.Plotting cool! end course, know create things like (much ) .","code":"\nlibrary(gganimate)\n\ngapminder %>%\n  filter(continent != \"Oceania\") %>%\n  ggplot(aes(gdpPercap, lifeExp, size = pop, color = continent)) +\n    geom_point(show.legend = FALSE, alpha = 0.7) +\n    facet_wrap(~continent, nrow = 1) +\n    scale_size(range = c(2, 12)) +\n    scale_x_log10() +\n    labs(subtitle = \"Life Expectancy and GDP per Capita (1952-2007)\",\n         x = \"GDP per Capita, USD\",\n         y = \"Life Expectancy, Years\") +\n    theme_linedraw() +\n    transition_time(year) +\n    labs(title = \"Year: {frame_time}\") +\n    shadow_wake(wake_length = 0.1, alpha = FALSE)"},{"path":"wrangling.html","id":"wrangling","chapter":"2 Wrangling","heading":"2 Wrangling","text":"Start loading packages need chapter.tidyverse package used every chapter. PPBDS.data data package created specifically course. lubridate package working dates times. janitor offers functions cleaning dirty data. skimr contains functions useful providing summary statistics. nycflights includes data associated flights New York City’s three major airports. gapminder data countries across decades. fivethirtyeight cleans data FiveThirtyEight team.","code":"\nlibrary(tidyverse)\nlibrary(PPBDS.data)\nlibrary(lubridate)\nlibrary(skimr)\nlibrary(janitor)\nlibrary(gapminder)\nlibrary(nycflights13)\nlibrary(fivethirtyeight)"},{"path":"wrangling.html","id":"data-gathering","chapter":"2 Wrangling","heading":"2.1 Data Gathering","text":"Recall read_csv() function introduced briefly chapter 1 textbook. Let’s import Comma Separated Values .csv file exists internet. .csv file dem_score.csv contains ratings level democracy different countries spanning 1952 1992 accessible https://moderndive.com/data/dem_score.csv. Let’s use read_csv() function readr package read web, import R, save data frame called dem_score.dem_score data frame, minimum value -10 corresponds highly autocratic nation, whereas value 10 corresponds highly democratic nation. Note also backticks surround different variable names. Variable names R default allowed start number include spaces, can get around fact surrounding column name backticks.Note read_csv() function included readr package different read.csv() function comes installed R. difference names might seem trivial (_ instead .), read_csv() function , opinion, easier use since can easily read data web generally imports data much faster speed. Furthermore, read_csv() function included readr saves data frames tibbles default.result code chunk pretty tame. tells us comma .csv file corresponds column, column names taken first line file. , function “guesses” appropriate data type columns creates. Sometimes .csv files lot dirtier require significant wrangling can explore data create usable graphics.Let’s try run read_csv() another dataset. link file containing faculty’s gender data across departments Harvard University. Note, file argument read_csv() function can take link dataset number forms. previous example one , file argument takes url. formats argument take full partial file paths .csv files saved locally computer.Now, call gender_data.can see, second row likely meant contain column names. can run ?read_csv() console see additional arguments read_csv() function may contain make new dataframe easier work . skip argument allows skip rows dataset.Now suppose want change data type one columns. col_type argument allows us . Without col_type argument, division column read character column. Instead, want read factor.Now new dataset read , explore using View() glimpse() functions $ operator previous chapter.Run summary() function gender_data dataframe.may notice something appears wrong dataset. department employed 644 male full professors? Let’s explore going wrong .seems one row table takes sum rows. likely last row dataframe. Use tail() print last rows dataframe check final row.Now, remove “Total” row affect dplyr functions try run dataframe. Check tail() dataframe make sure proper row removed.","code":"\ndem_score <- read_csv(file = \"https://moderndive.com/data/dem_score.csv\")## \n## ── Column specification ────────────────────────────────────────────────────────\n## cols(\n##   country = col_character(),\n##   `1952` = col_double(),\n##   `1957` = col_double(),\n##   `1962` = col_double(),\n##   `1967` = col_double(),\n##   `1972` = col_double(),\n##   `1977` = col_double(),\n##   `1982` = col_double(),\n##   `1987` = col_double(),\n##   `1992` = col_double()\n## )\nurl <- \"https://raw.githubusercontent.com/davidkane9/PPBDS/master/02-wrangling/data/harvard-faculty-gender-final.csv\"\ngender_data <- read_csv(file = url)## Warning: Missing column names filled in: 'X1' [1], 'X2' [2], 'X3' [3], 'X4' [4],\n## 'X5' [5], 'X6' [6], 'X7' [7], 'X8' [8], 'X9' [9], 'X10' [10], 'X11' [11],\n## 'X12' [12]## \n## ── Column specification ────────────────────────────────────────────────────────\n## cols(\n##   X1 = col_character(),\n##   X2 = col_character(),\n##   X3 = col_character(),\n##   X4 = col_character(),\n##   X5 = col_character(),\n##   X6 = col_character(),\n##   X7 = col_character(),\n##   X8 = col_character(),\n##   X9 = col_character(),\n##   X10 = col_character(),\n##   X11 = col_character(),\n##   X12 = col_character()\n## )\ngender_data## # A tibble: 46 x 12\n##    X1      X2     X3     X4     X5     X6    X7    X8    X9    X10   X11   X12  \n##    <chr>   <chr>  <chr>  <chr>  <chr>  <chr> <chr> <chr> <chr> <chr> <chr> <chr>\n##  1 concen… full_… full_… assoc… assoc… asst… asst… lec_… lec_… prof… prof… divi…\n##  2 Theate… 0      2      0      0      1     0     0     0     0     1     Arts…\n##  3 Women,… 1      5      0      0      0     1     1     9     1     0     Soci…\n##  4 Histor… 5      8      2      1      3     1     2     5     0     0     Soci…\n##  5 Romanc… 6      9      1      1      1     2     2     11    0     0     Arts…\n##  6 Music   6      8      0      0      1     0     5     4     0     2     Arts…\n##  7 Africa… 19     15     1      0      1     0     0     0     1     0     Soci…\n##  8 History 23     18     0      1      0     0     4     2     0     0     Soci…\n##  9 Histor… 11     7      0      1      1     1     0     1     0     0     Arts…\n## 10 Psycho… 11     7      1      2      4     2     1     0     0     0     Soci…\n## # … with 36 more rows\ngender_data <- read_csv(file = url, skip = 1)## \n## ── Column specification ────────────────────────────────────────────────────────\n## cols(\n##   concentration = col_character(),\n##   full_profs_m = col_double(),\n##   full_profs_f = col_double(),\n##   assoc_m = col_double(),\n##   assoc_f = col_double(),\n##   asst_m = col_double(),\n##   asst_f = col_double(),\n##   lec_precep_adj_m = col_double(),\n##   lec_precep_adj_f = col_double(),\n##   prof_of_practice_m = col_double(),\n##   prof_of_practic_f = col_double(),\n##   division = col_character()\n## )\ngender_data## # A tibble: 45 x 12\n##    concentration full_profs_m full_profs_f assoc_m assoc_f asst_m asst_f\n##    <chr>                <dbl>        <dbl>   <dbl>   <dbl>  <dbl>  <dbl>\n##  1 Theater, Dan…            0            2       0       0      1      0\n##  2 Women, Gende…            1            5       0       0      0      1\n##  3 History of S…            5            8       2       1      3      1\n##  4 Romance Lang…            6            9       1       1      1      2\n##  5 Music                    6            8       0       0      1      0\n##  6 African & Af…           19           15       1       0      1      0\n##  7 History                 23           18       0       1      0      0\n##  8 History of A…           11            7       0       1      1      1\n##  9 Psychology              11            7       1       2      4      2\n## 10 Sociology               11            7       2       0      0      1\n## # … with 35 more rows, and 5 more variables: lec_precep_adj_m <dbl>,\n## #   lec_precep_adj_f <dbl>, prof_of_practice_m <dbl>, prof_of_practic_f <dbl>,\n## #   division <chr>\ngender_data <- read_csv(file = url, skip = 1, col_type = cols(division = col_factor()))\nView(gender_data)\nglimpse(gender_data)## Rows: 45\n## Columns: 12\n## $ concentration      <chr> \"Theater, Dance & Media\", \"Women, Gender, & Sexual…\n## $ full_profs_m       <dbl> 0, 1, 5, 6, 6, 19, 23, 11, 11, 11, 13, 20, 33, 2, …\n## $ full_profs_f       <dbl> 2, 5, 8, 9, 8, 15, 18, 7, 7, 7, 8, 11, 17, 1, 2, 2…\n## $ assoc_m            <dbl> 0, 0, 2, 1, 0, 1, 0, 0, 1, 2, 1, 3, 2, 0, 1, 0, 1,…\n## $ assoc_f            <dbl> 0, 0, 1, 1, 0, 0, 1, 1, 2, 0, 0, 2, 1, 0, 0, 0, 0,…\n## $ asst_m             <dbl> 1, 0, 3, 1, 1, 1, 0, 1, 4, 0, 1, 1, 1, 0, 0, 0, 2,…\n## $ asst_f             <dbl> 0, 1, 1, 2, 0, 0, 0, 1, 2, 1, 2, 3, 2, 1, 1, 2, 0,…\n## $ lec_precep_adj_m   <dbl> 0, 1, 2, 2, 5, 0, 4, 0, 1, 0, 4, 4, 3, 0, 0, 2, 2,…\n## $ lec_precep_adj_f   <dbl> 0, 9, 5, 11, 4, 0, 2, 1, 0, 0, 10, 3, 2, 0, 0, 7, …\n## $ prof_of_practice_m <dbl> 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2,…\n## $ prof_of_practic_f  <dbl> 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,…\n## $ division           <fct> Arts & Humanities, Social Sciences, Social Science…\ngender_data$division##  [1] Arts & Humanities Social Sciences   Social Sciences   Arts & Humanities\n##  [5] Arts & Humanities Social Sciences   Social Sciences   Arts & Humanities\n##  [9] Social Sciences   Social Sciences   Arts & Humanities Arts & Humanities\n## [13] Arts & Humanities Arts & Humanities Science           Arts & Humanities\n## [17] Science           Arts & Humanities SEAS              Arts & Humanities\n## [21] SEAS              Arts & Humanities Arts & Humanities Arts & Humanities\n## [25] Social Sciences   Science           Science           Social Sciences  \n## [29] Arts & Humanities Arts & Humanities Science           SEAS             \n## [33] SEAS              Social Sciences   Science           Science          \n## [37] Science           Science           SEAS              Arts & Humanities\n## [41] Social Sciences   SEAS              Arts & Humanities Science          \n## [45] <NA>             \n## Levels: Arts & Humanities Social Sciences Science SEAS\nsummary(gender_data)##  concentration       full_profs_m  full_profs_f    assoc_m      assoc_f    \n##  Length:45          Min.   :  0   Min.   :  0   Min.   : 0   Min.   : 0.0  \n##  Class :character   1st Qu.:  7   1st Qu.:  2   1st Qu.: 0   1st Qu.: 0.0  \n##  Mode  :character   Median : 13   Median :  4   Median : 1   Median : 0.0  \n##                     Mean   : 29   Mean   : 10   Mean   : 2   Mean   : 0.8  \n##                     3rd Qu.: 20   3rd Qu.:  7   3rd Qu.: 2   3rd Qu.: 1.0  \n##                     Max.   :644   Max.   :220   Max.   :40   Max.   :17.0  \n##      asst_m       asst_f   lec_precep_adj_m lec_precep_adj_f prof_of_practice_m\n##  Min.   : 0   Min.   : 0   Min.   :  0      Min.   :  0      Min.   : 0.0      \n##  1st Qu.: 0   1st Qu.: 0   1st Qu.:  0      1st Qu.:  0      1st Qu.: 0.0      \n##  Median : 1   Median : 1   Median :  1      Median :  1      Median : 0.0      \n##  Mean   : 2   Mean   : 2   Mean   :  5      Mean   :  5      Mean   : 0.6      \n##  3rd Qu.: 2   3rd Qu.: 2   3rd Qu.:  3      3rd Qu.:  3      3rd Qu.: 1.0      \n##  Max.   :50   Max.   :49   Max.   :102      Max.   :107      Max.   :14.0      \n##  prof_of_practic_f              division \n##  Min.   :0.0       Arts & Humanities:18  \n##  1st Qu.:0.0       Social Sciences  :10  \n##  Median :0.0       Science          :10  \n##  Mean   :0.4       SEAS             : 6  \n##  3rd Qu.:0.0       NA's             : 1  \n##  Max.   :8.0\ngender_data %>% filter(full_profs_m == 644)## # A tibble: 1 x 12\n##   concentration full_profs_m full_profs_f assoc_m assoc_f asst_m asst_f\n##   <chr>                <dbl>        <dbl>   <dbl>   <dbl>  <dbl>  <dbl>\n## 1 Total                  644          220      40      17     50     49\n## # … with 5 more variables: lec_precep_adj_m <dbl>, lec_precep_adj_f <dbl>,\n## #   prof_of_practice_m <dbl>, prof_of_practic_f <dbl>, division <fct>\ntail(gender_data)## # A tibble: 6 x 12\n##   concentration full_profs_m full_profs_f assoc_m assoc_f asst_m asst_f\n##   <chr>                <dbl>        <dbl>   <dbl>   <dbl>  <dbl>  <dbl>\n## 1 Near Eastern…           11            1       0       0      2      1\n## 2 Economics               40            3       1       0      2      2\n## 3 Environmenta…           13            0       1       1      1      0\n## 4 Linguistics              5            0       1       1      0      1\n## 5 Math                    19            0       0       0      0      0\n## 6 Total                  644          220      40      17     50     49\n## # … with 5 more variables: lec_precep_adj_m <dbl>, lec_precep_adj_f <dbl>,\n## #   prof_of_practice_m <dbl>, prof_of_practic_f <dbl>, division <fct>\ngender_data <- gender_data %>%\n  filter(concentration != \"Total\")\n\ntail(gender_data)## # A tibble: 6 x 12\n##   concentration full_profs_m full_profs_f assoc_m assoc_f asst_m asst_f\n##   <chr>                <dbl>        <dbl>   <dbl>   <dbl>  <dbl>  <dbl>\n## 1 Biomedical E…           15            2       2       0      1      0\n## 2 Near Eastern…           11            1       0       0      2      1\n## 3 Economics               40            3       1       0      2      2\n## 4 Environmenta…           13            0       1       1      1      0\n## 5 Linguistics              5            0       1       1      0      1\n## 6 Math                    19            0       0       0      0      0\n## # … with 5 more variables: lec_precep_adj_m <dbl>, lec_precep_adj_f <dbl>,\n## #   prof_of_practice_m <dbl>, prof_of_practic_f <dbl>, division <fct>"},{"path":"wrangling.html","id":"html","chapter":"2 Wrangling","heading":"2.1.1 HTML","text":"data need answer question always spreadsheet ready us read. example, can find interesting data murders US Wikipedia page:can see data table visit webpage:get data, need web scraping.Web scraping, web harvesting, term use describe process extracting data website. reason can information used browser render webpages received text file server. text code written hyper text markup language (HTML). Every browser way show html source code page, one different. Chrome, can use Control-U PC command+option+U Mac. see something like :code accessible, can download HTML file, import R, write programs extract information need page. However, look HTML code, might seem like daunting task. show convenient tools facilitate process. get idea works, lines code Wikipedia page provides US murders data:can actually see data, except data values surrounded html code <td>. can also see pattern stored. know HTML, can write programs leverage knowledge patterns extract want. also take advantage language widely used make webpages look “pretty” called Cascading Style Sheets (CSS).Although provide tools make possible scrape data without knowing HTML, data scientist quite useful learn HTML CSS. improve scraping skills, might come handy creating webpage showcase work.","code":"\nurl <- paste0(\"https://en.wikipedia.org/w/index.php?title=\",\n              \"Gun_violence_in_the_United_States_by_state\",\n              \"&direction=prev&oldid=810166167\")<table class=\"wikitable sortable\">\n<tr>\n<th>State<\/th>\n<th><a href=\"/wiki/List_of_U.S._states_and_territories_by_population\" \ntitle=\"List of U.S. states and territories by population\">Population<\/a><br />\n<small>(total inhabitants)<\/small><br />\n<small>(2015)<\/small> <sup id=\"cite_ref-1\" class=\"reference\">\n<a href=\"#cite_note-1\">[1]<\/a><\/sup><\/th>\n<th>Murders and Nonnegligent\n<p>Manslaughter<br />\n<small>(total deaths)<\/small><br />\n<small>(2015)<\/small> <sup id=\"cite_ref-2\" class=\"reference\">\n<a href=\"#cite_note-2\">[2]<\/a><\/sup><\/p>\n<\/th>\n<th>Murder and Nonnegligent\n<p>Manslaughter Rate<br />\n<small>(per 100,000 inhabitants)<\/small><br />\n<small>(2015)<\/small><\/p>\n<\/th>\n<\/tr>\n<tr>\n<td><a href=\"/wiki/Alabama\" title=\"Alabama\">Alabama<\/a><\/td>\n<td>4,853,875<\/td>\n<td>348<\/td>\n<td>7.2<\/td>\n<\/tr>\n<tr>\n<td><a href=\"/wiki/Alaska\" title=\"Alaska\">Alaska<\/a><\/td>\n<td>737,709<\/td>\n<td>59<\/td>\n<td>8.0<\/td>\n<\/tr>\n<tr>"},{"path":"wrangling.html","id":"the-rvest-package","chapter":"2 Wrangling","heading":"2.1.2 The rvest package","text":"tidyverse contains web harvesting package called rvest. first step using package import webpage R. package makes quite simple:Note entire Murders US Wikipedia webpage now contained h. class object :rvest package actually general; handles XML documents. XML general markup language (’s ML stands ) can used represent kind data. HTML specific type XML specifically developed representing webpages. focus HTML documents.Now, extract table object h? print h, don’t really see much:can see code defines downloaded webpage using html_text function like :don’t show output includes thousands characters, look , can see data stored HTML table: can see line HTML code <table class=\"wikitable sortable\">. different parts HTML document, often defined message < > referred nodes. rvest package includes functions extract nodes HTML document: html_nodes extracts nodes different types html_node extracts first one. extract tables html code use:Now, instead entire webpage, just html code tables page:table interested first one:clearly tidy dataset, even data frame. code , can definitely see pattern writing code extract just data doable. fact, rvest includes function just converting HTML tables data frames:now much closer usable data table:still wrangling . example, need remove commas turn characters numbers. continuing , learn general approach extracting information web sites.","code":"\nlibrary(tidyverse)\nlibrary(rvest)\nh <- read_html(url)\nclass(h)## [1] \"xml_document\" \"xml_node\"\nh## {html_document}\n## <html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n## [1] <head>\\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n## [2] <body class=\"mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject  ...\nhtml_text(h)\ntab <- h %>% html_nodes(\"table\")\ntab## {xml_nodeset (2)}\n## [1] <table class=\"wikitable sortable\"><tbody>\\n<tr>\\n<th>State\\n<\/th>\\n<th>\\n ...\n## [2] <table class=\"nowraplinks hlist mw-collapsible mw-collapsed navbox-inner\" ...\ntab[[1]]## {html_node}\n## <table class=\"wikitable sortable\">\n## [1] <tbody>\\n<tr>\\n<th>State\\n<\/th>\\n<th>\\n<a href=\"/wiki/List_of_U.S._states ...\ntab <- tab[[1]] %>% html_table\nclass(tab)## [1] \"data.frame\"\ntab <- tab %>% setNames(c(\"state\", \"population\", \"total\", \"murder_rate\")) \nhead(tab)##        state population total murder_rate\n## 1    Alabama  4,853,875   348         7.2\n## 2     Alaska    737,709    59         8.0\n## 3    Arizona  6,817,565   309         4.5\n## 4   Arkansas  2,977,853   181         6.1\n## 5 California 38,993,940 1,861         4.8\n## 6   Colorado  5,448,819   176         3.2"},{"path":"wrangling.html","id":"css-selectors","chapter":"2 Wrangling","heading":"2.1.3 CSS selectors","text":"default look webpage made basic HTML quite unattractive. aesthetically pleasing pages see today made using CSS define look style webpages. fact pages company style usually results use CSS file define style. general way CSS files work defining elements webpage look. title, headings, itemized lists, tables, links, example, receive style including font, color, size, distance margin. CSS leveraging patterns used define elements, referred selectors. example pattern, used , table, many, many .want grab data webpage happen know selector unique part page containing data, can use html_nodes function. However, knowing selector can quite complicated.\nfact, complexity webpages increasing become sophisticated. advanced ones, seems almost impossible find nodes define particular piece data. However, selector gadgets actually make possible.SelectorGadget1 piece software allows interactively determine CSS selector need extract specific components webpage. plan scraping data tables html pages, highly recommend install . Chrome extension available permits turn gadget , click page, highlights parts shows selector need extract parts. various demos including rvest author Hadley Wickham’s\nvignette2 tutorials based vignette3.4","code":""},{"path":"wrangling.html","id":"json","chapter":"2 Wrangling","heading":"2.1.4 JSON","text":"Sharing data internet become common. Unfortunately, providers use different formats, makes harder data scientists wrangle data R. Yet standards also becoming common. Currently, format widely adopted JavaScript Object Notation JSON. format general, nothing like spreadsheet. JSON file looks like code use define list. example information stored JSON format:file actually represents data frame. read , can use function fromJSON jsonlite package. Note JSON files often made available via internet. Several organizations provide JSON API web service can connect directly obtain data.can learn much examining tutorials help files jsonlite package. package intended relatively simple tasks converging data tables. flexibility, recommend rjson.","code":"## \n## Attaching package: 'jsonlite'## The following object is masked from 'package:purrr':\n## \n##     flatten## [\n##   {\n##     \"name\": \"Miguel\",\n##     \"student_id\": 1,\n##     \"exam_1\": 85,\n##     \"exam_2\": 86\n##   },\n##   {\n##     \"name\": \"Sofia\",\n##     \"student_id\": 2,\n##     \"exam_1\": 94,\n##     \"exam_2\": 93\n##   },\n##   {\n##     \"name\": \"Aya\",\n##     \"student_id\": 3,\n##     \"exam_1\": 87,\n##     \"exam_2\": 88\n##   },\n##   {\n##     \"name\": \"Cheng\",\n##     \"student_id\": 4,\n##     \"exam_1\": 90,\n##     \"exam_2\": 91\n##   }\n## ]"},{"path":"wrangling.html","id":"characters","chapter":"2 Wrangling","heading":"2.2 Characters","text":"’ve spent lot time working big, beautiful data frames clean wholesome, like gapminder nycflights13 data.real life much nastier. bring data R outside world discover problems. might think: hard can deal character data? answer : can hard!discuss common remedial tasks cleaning transforming character data, also known “strings”. data frame tibble consist one atomic vectors certain class. lesson deals things can vectors class character.beginning chapter, loaded tidyverse, includes stringr. package allows users manipulate strings functions str_.basic string manipulation tasks:Study single character vector\nlong strings?\nPresence/absence literal string\nlong strings?Presence/absence literal stringOperate single character vector\nKeep/discard elements contain literal string\nSplit two character vectors using fixed delimiter\nSnip pieces strings based character position\nCollapse single string\nKeep/discard elements contain literal stringSplit two character vectors using fixed delimiterSnip pieces strings based character positionCollapse single stringOperate two character vectors\nGlue together element-wise get new character vector.\nGlue together element-wise get new character vector.fruit, words, sentences character vectors ship stringr practicing.*","code":""},{"path":"wrangling.html","id":"studying-a-single-character-vector","chapter":"2 Wrangling","heading":"2.2.1 Studying a single character vector","text":"Determine presence/absence literal string str_detect(). Spoiler: later see str_detect() also detects regular expressions.fruits actually use word “fruit”?’s easiest way get actual fruits match? Use str_subset() keep matching elements. Note storing new vector my_fruit use later examples!Use stringr::str_view() create window viewer highlights specified pattern instances within list. look subset fruit highlight pattern “berry” within items list.can helpful want check highlighting correct pattern (especially using regex). think following regex means? (explained depth later)","code":"\nstr_detect(fruit, pattern = \"fruit\")##  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE\n## [13] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n## [25] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE\n## [37] FALSE FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n## [49] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n## [61] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n## [73] FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE\n(my_fruit <- str_subset(fruit, pattern = \"fruit\"))## [1] \"breadfruit\"   \"dragonfruit\"  \"grapefruit\"   \"jackfruit\"    \"kiwi fruit\"  \n## [6] \"passionfruit\" \"star fruit\"   \"ugli fruit\"\nstr_view(fruit[5:10], pattern = \"berry\")\nstr_view(fruit[1:5], pattern = \"^a.*o\")"},{"path":"wrangling.html","id":"operating-on-a-single-character-vector","chapter":"2 Wrangling","heading":"2.2.2 Operating on a single character vector","text":"Use stringr::str_split() split strings delimiter. fruits compound words, like “grapefruit”, two words, like “ugli fruit”. split single space \" \", show use regular expression later.’s bummer get list back. must ! full generality, split strings must return list, knows many pieces ?willing commit number pieces, can use str_split_fixed() get character matrix. ’re welcome!--split variable lives data frame, tidyr::separate() split 2 variables.Count characters strings str_length(). Note different length character vector .can snip substrings based character position str_sub().start end arguments vectorised. Example: sliding 3-character window.Finally, str_sub() also works assignment, .e. left hand side <-.can collapse character vector length n > 1 single string str_c(), also uses (see next section).can replace pattern str_replace(). use explicit string--replace, later revisit regular expression.special case comes lot replacing NA, str_replace_na().NA-afflicted variable lives data frame, can use tidyr::replace_na().concludes treatment regex-free manipulations character data!","code":"\nstr_split(my_fruit, pattern = \" \")## [[1]]\n## [1] \"breadfruit\"\n## \n## [[2]]\n## [1] \"dragonfruit\"\n## \n## [[3]]\n## [1] \"grapefruit\"\n## \n## [[4]]\n## [1] \"jackfruit\"\n## \n## [[5]]\n## [1] \"kiwi\"  \"fruit\"\n## \n## [[6]]\n## [1] \"passionfruit\"\n## \n## [[7]]\n## [1] \"star\"  \"fruit\"\n## \n## [[8]]\n## [1] \"ugli\"  \"fruit\"\nstr_split_fixed(my_fruit, pattern = \" \", n = 2)##      [,1]           [,2]   \n## [1,] \"breadfruit\"   \"\"     \n## [2,] \"dragonfruit\"  \"\"     \n## [3,] \"grapefruit\"   \"\"     \n## [4,] \"jackfruit\"    \"\"     \n## [5,] \"kiwi\"         \"fruit\"\n## [6,] \"passionfruit\" \"\"     \n## [7,] \"star\"         \"fruit\"\n## [8,] \"ugli\"         \"fruit\"\nmy_fruit_df <- tibble(my_fruit)\nmy_fruit_df %>% \n  separate(my_fruit, into = c(\"pre\", \"post\"), sep = \" \")## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 5 rows [1, 2, 3,\n## 4, 6].## # A tibble: 8 x 2\n##   pre          post \n##   <chr>        <chr>\n## 1 breadfruit   <NA> \n## 2 dragonfruit  <NA> \n## 3 grapefruit   <NA> \n## 4 jackfruit    <NA> \n## 5 kiwi         fruit\n## 6 passionfruit <NA> \n## 7 star         fruit\n## 8 ugli         fruit\nlength(my_fruit)## [1] 8\nstr_length(my_fruit)## [1] 10 11 10  9 10 12 10 10\nhead(fruit) %>% \n  str_sub(1, 3)## [1] \"app\" \"apr\" \"avo\" \"ban\" \"bel\" \"bil\"\ntibble(fruit) %>% \n  head() %>% \n  mutate(snip = str_sub(fruit, 1:6, 3:8))## # A tibble: 6 x 2\n##   fruit       snip \n##   <chr>       <chr>\n## 1 apple       \"app\"\n## 2 apricot     \"pri\"\n## 3 avocado     \"oca\"\n## 4 banana      \"ana\"\n## 5 bell pepper \" pe\"\n## 6 bilberry    \"rry\"\n(x <- head(fruit, 3))## [1] \"apple\"   \"apricot\" \"avocado\"\nstr_sub(x, 1, 3) <- \"AAA\"\nx## [1] \"AAAle\"   \"AAAicot\" \"AAAcado\"\nhead(fruit) %>% \n  str_c(collapse = \", \")## [1] \"apple, apricot, avocado, banana, bell pepper, bilberry\"\nstr_replace(my_fruit, pattern = \"fruit\", replacement = \"THINGY\")## [1] \"breadTHINGY\"   \"dragonTHINGY\"  \"grapeTHINGY\"   \"jackTHINGY\"   \n## [5] \"kiwi THINGY\"   \"passionTHINGY\" \"star THINGY\"   \"ugli THINGY\"\nmelons <- str_subset(fruit, pattern = \"melon\")\nmelons[2] <- NA\nmelons## [1] \"canary melon\" NA             \"watermelon\"\nstr_replace_na(melons, \"UNKNOWN MELON\")## [1] \"canary melon\"  \"UNKNOWN MELON\" \"watermelon\"\ntibble(melons) %>% \n  replace_na(replace = list(melons = \"UNKNOWN MELON\"))## # A tibble: 3 x 1\n##   melons       \n##   <chr>        \n## 1 canary melon \n## 2 UNKNOWN MELON\n## 3 watermelon"},{"path":"wrangling.html","id":"operating-on-two-or-more-character-vectors","chapter":"2 Wrangling","heading":"2.2.3 Operating on two or more character vectors","text":"two character vectors length, can glue together element-wise, get new vector length. … awful smoothie flavors?Element-wise catenation can combined collapsing.--combined vectors variables data frame, can use tidyr::unite() make single new variable .","code":"\nstr_c(fruit[1:4], fruit[5:8], sep = \" & \")## [1] \"apple & bell pepper\"   \"apricot & bilberry\"    \"avocado & blackberry\" \n## [4] \"banana & blackcurrant\"\nstr_c(fruit[1:4], fruit[5:8], sep = \" & \", collapse = \", \")## [1] \"apple & bell pepper, apricot & bilberry, avocado & blackberry, banana & blackcurrant\"\nfruit_df <- tibble(\n  fruit1 = fruit[1:4],\n  fruit2 = fruit[5:8]\n)\nfruit_df %>% \n  unite(\"flavor_combo\", fruit1, fruit2, sep = \" & \")## # A tibble: 4 x 1\n##   flavor_combo         \n##   <chr>                \n## 1 apple & bell pepper  \n## 2 apricot & bilberry   \n## 3 avocado & blackberry \n## 4 banana & blackcurrant"},{"path":"wrangling.html","id":"regular-expressions-with-stringr","chapter":"2 Wrangling","heading":"2.2.4 Regular expressions with stringr","text":"\nFigure 2.1: @ThePracticalDev\nFrequently string tasks expressed terms fixed string, can described terms pattern. Regular expressions, aka “regexes”, standard way specify patterns. regexes, specific characters constructs take special meaning order match multiple strings.country names gapminder dataset convenient examples. Load now store\n142 unique country names object countries.first metacharacter period ., stands single character, except newline (way, represented \\n). regex .match countries , followed single character, followed . Yes, regexes case sensitive, .e. “Italy” match.Notice .matches “ina”, “ica”, “ita”, .Anchors can included express expression must occur within string. ^ indicates beginning string $ indicates end.Note regex .$ matches many fewer countries .alone. Likewise, elements my_fruit match d ^d, requires “d” string start.metacharacter \\b indicates word boundary \\B indicates word boundary. first encounter something called “escaping” right now just want accept need prepend second backslash use sequences regexes R. ’ll come back tedious point later.Characters can specified via classes. can make explicitly “hand” use pre-existing ones. Character classes usually given inside square brackets, [] come often metacharacter , \\d single digit.match ia end country name, preceded one characters class. , negated class, preceded anything one characters.revisit splitting my_fruit two general ways match whitespace: \\s metacharacter POSIX class [:space:]. Notice must prepend extra backslash \\ escape \\s POSIX class surrounded two sets square brackets.Let’s see country names contain punctuation.","code":"\ncountries <- levels(gapminder$country)\nstr_subset(countries, pattern = \"i.a\")##  [1] \"Argentina\"                \"Bosnia and Herzegovina\"  \n##  [3] \"Burkina Faso\"             \"Central African Republic\"\n##  [5] \"China\"                    \"Costa Rica\"              \n##  [7] \"Dominican Republic\"       \"Hong Kong, China\"        \n##  [9] \"Jamaica\"                  \"Mauritania\"              \n## [11] \"Nicaragua\"                \"South Africa\"            \n## [13] \"Swaziland\"                \"Taiwan\"                  \n## [15] \"Thailand\"                 \"Trinidad and Tobago\"\nstr_subset(countries, pattern = \"i.a$\")## [1] \"Argentina\"              \"Bosnia and Herzegovina\" \"China\"                 \n## [4] \"Costa Rica\"             \"Hong Kong, China\"       \"Jamaica\"               \n## [7] \"South Africa\"\nstr_subset(my_fruit, pattern = \"d\")## [1] \"breadfruit\"  \"dragonfruit\"\nstr_subset(my_fruit, pattern = \"^d\")## [1] \"dragonfruit\"\nstr_subset(fruit, pattern = \"melon\")## [1] \"canary melon\" \"rock melon\"   \"watermelon\"\nstr_subset(fruit, pattern = \"\\\\bmelon\")## [1] \"canary melon\" \"rock melon\"\nstr_subset(fruit, pattern = \"\\\\Bmelon\")## [1] \"watermelon\"\n# Make a class \"by hand\"\n\nstr_subset(countries, pattern = \"[nls]ia$\")##  [1] \"Albania\"    \"Australia\"  \"Indonesia\"  \"Malaysia\"   \"Mauritania\"\n##  [6] \"Mongolia\"   \"Romania\"    \"Slovenia\"   \"Somalia\"    \"Tanzania\"  \n## [11] \"Tunisia\"\n# Use ^ to negate the class\n\nstr_subset(countries, pattern = \"[^nls]ia$\")##  [1] \"Algeria\"      \"Austria\"      \"Bolivia\"      \"Bulgaria\"     \"Cambodia\"    \n##  [6] \"Colombia\"     \"Croatia\"      \"Ethiopia\"     \"Gambia\"       \"India\"       \n## [11] \"Liberia\"      \"Namibia\"      \"Nigeria\"      \"Saudi Arabia\" \"Serbia\"      \n## [16] \"Syria\"        \"Zambia\"\n# Remember this?\n# str_split_fixed(fruit, pattern = \" \", n = 2)\n# Alternatives:\n\nstr_split_fixed(my_fruit, pattern = \"\\\\s\", n = 2)##      [,1]           [,2]   \n## [1,] \"breadfruit\"   \"\"     \n## [2,] \"dragonfruit\"  \"\"     \n## [3,] \"grapefruit\"   \"\"     \n## [4,] \"jackfruit\"    \"\"     \n## [5,] \"kiwi\"         \"fruit\"\n## [6,] \"passionfruit\" \"\"     \n## [7,] \"star\"         \"fruit\"\n## [8,] \"ugli\"         \"fruit\"\nstr_split_fixed(my_fruit, pattern = \"[[:space:]]\", n = 2)##      [,1]           [,2]   \n## [1,] \"breadfruit\"   \"\"     \n## [2,] \"dragonfruit\"  \"\"     \n## [3,] \"grapefruit\"   \"\"     \n## [4,] \"jackfruit\"    \"\"     \n## [5,] \"kiwi\"         \"fruit\"\n## [6,] \"passionfruit\" \"\"     \n## [7,] \"star\"         \"fruit\"\n## [8,] \"ugli\"         \"fruit\"\nstr_subset(countries, \"[[:punct:]]\")## [1] \"Congo, Dem. Rep.\" \"Congo, Rep.\"      \"Cote d'Ivoire\"    \"Guinea-Bissau\"   \n## [5] \"Hong Kong, China\" \"Korea, Dem. Rep.\" \"Korea, Rep.\"      \"Yemen, Rep.\""},{"path":"wrangling.html","id":"quantifiers","chapter":"2 Wrangling","heading":"2.2.5 Quantifiers","text":"can decorate characters (constructs, like metacharacters classes) information many characters allowed match.Explore inspecting matches l followed e, allowing various numbers characters .l.*e match strings 0 characters , .e. string l eventually followed e. inclusive regex example, store result matches use baseline comparison.Change quantifier * + require least one intervening character. strings longer match: literal le preceding l following e.Change quantifier * ? require one intervening character. strings longer match, shortest gap l following e least two characters.Finally, remove quantifier allow intervening characters. strings longer match lack literal le.","code":"\n(matches <- str_subset(fruit, pattern = \"l.*e\"))##  [1] \"apple\"             \"bell pepper\"       \"bilberry\"         \n##  [4] \"blackberry\"        \"blood orange\"      \"blueberry\"        \n##  [7] \"cantaloupe\"        \"chili pepper\"      \"clementine\"       \n## [10] \"cloudberry\"        \"elderberry\"        \"huckleberry\"      \n## [13] \"lemon\"             \"lime\"              \"lychee\"           \n## [16] \"mulberry\"          \"olive\"             \"pineapple\"        \n## [19] \"purple mangosteen\" \"salal berry\"\nlist(match = intersect(matches, str_subset(fruit, pattern = \"l.+e\")),\n     no_match = setdiff(matches, str_subset(fruit, pattern = \"l.+e\")))## $match\n##  [1] \"bell pepper\"       \"bilberry\"          \"blackberry\"       \n##  [4] \"blood orange\"      \"blueberry\"         \"cantaloupe\"       \n##  [7] \"chili pepper\"      \"clementine\"        \"cloudberry\"       \n## [10] \"elderberry\"        \"huckleberry\"       \"lime\"             \n## [13] \"lychee\"            \"mulberry\"          \"olive\"            \n## [16] \"purple mangosteen\" \"salal berry\"      \n## \n## $no_match\n## [1] \"apple\"     \"lemon\"     \"pineapple\"\nlist(match = intersect(matches, str_subset(fruit, pattern = \"l.?e\")),\n     no_match = setdiff(matches, str_subset(fruit, pattern = \"l.?e\")))## $match\n##  [1] \"apple\"             \"bilberry\"          \"blueberry\"        \n##  [4] \"clementine\"        \"elderberry\"        \"huckleberry\"      \n##  [7] \"lemon\"             \"mulberry\"          \"pineapple\"        \n## [10] \"purple mangosteen\"\n## \n## $no_match\n##  [1] \"bell pepper\"  \"blackberry\"   \"blood orange\" \"cantaloupe\"   \"chili pepper\"\n##  [6] \"cloudberry\"   \"lime\"         \"lychee\"       \"olive\"        \"salal berry\"\nlist(match = intersect(matches, str_subset(fruit, pattern = \"le\")),\n     no_match = setdiff(matches, str_subset(fruit, pattern = \"le\")))## $match\n## [1] \"apple\"             \"clementine\"        \"huckleberry\"      \n## [4] \"lemon\"             \"pineapple\"         \"purple mangosteen\"\n## \n## $no_match\n##  [1] \"bell pepper\"  \"bilberry\"     \"blackberry\"   \"blood orange\" \"blueberry\"   \n##  [6] \"cantaloupe\"   \"chili pepper\" \"cloudberry\"   \"elderberry\"   \"lime\"        \n## [11] \"lychee\"       \"mulberry\"     \"olive\"        \"salal berry\""},{"path":"wrangling.html","id":"raw-strings","chapter":"2 Wrangling","heading":"2.2.6 Raw strings","text":"’ve probably caught now certain characters special meaning regexes,\nincluding $ * + . ? [ ] ^ { } | ( ) \\. makes things difficult want use characters within strings instead regexes. Previously, lot maneuvering create strings containing special characters, now can use r\"()\".\\ preceding quote known escaping. signals computer quotations part string. Now, happens backslash within string.can see, backslash used escape initial backslash.","code":"\nr\"(Do you use \"airquotes\" much?)\"## [1] \"Do you use \\\"airquotes\\\" much?\"\nr\"(\\)\"## [1] \"\\\\\""},{"path":"wrangling.html","id":"factors","chapter":"2 Wrangling","heading":"2.3 Factors","text":"Factors categorical variables may take specified set values. Thus, known categorical variables, can separated categories. manipulate factors use [forcats][forcats-web] package, core package tidyverse. Like stringr package whose functions begin str_, main functions forcats package start fct_.Get know factor start touching ! ’s polite. Let’s use gapminder$continent example.get frequency table tibble, tibble, use dplyr::count(). get similar result free-range factor, use forcats::fct_count().","code":"\nstr(gapminder$continent)##  Factor w/ 5 levels \"Africa\",\"Americas\",..: 3 3 3 3 3 3 3 3 3 3 ...\nlevels(gapminder$continent)## [1] \"Africa\"   \"Americas\" \"Asia\"     \"Europe\"   \"Oceania\"\nnlevels(gapminder$continent)## [1] 5\nclass(gapminder$continent)## [1] \"factor\"\ngapminder %>% \n  count(continent)## # A tibble: 5 x 2\n##   continent     n\n##   <fct>     <int>\n## 1 Africa      624\n## 2 Americas    300\n## 3 Asia        396\n## 4 Europe      360\n## 5 Oceania      24\nfct_count(gapminder$continent)## # A tibble: 5 x 2\n##   f            n\n##   <fct>    <int>\n## 1 Africa     624\n## 2 Americas   300\n## 3 Asia       396\n## 4 Europe     360\n## 5 Oceania     24"},{"path":"wrangling.html","id":"dropping-unused-levels","chapter":"2 Wrangling","heading":"2.3.1 Dropping unused levels","text":"Just drop rows corresponding specific factor level, levels factor change. Sometimes unused levels can come back haunt later, e.g., figure legends.Watch happens levels country filter Gapminder handful countries.Even though h_gap data handful countries, still schlepping around levels original gapminder tibble.can get rid ? base function droplevels() operates factors data frame single factor. function forcats::fct_drop() operates factor.","code":"\nnlevels(gapminder$country)## [1] 142\nh_countries <- c(\"Egypt\", \"Haiti\", \"Romania\", \"Thailand\", \"Venezuela\")\nh_gap <- gapminder %>%\nfilter(country %in% h_countries)\nnlevels(h_gap$country)## [1] 142\nh_gap_dropped <- h_gap %>% \n  droplevels()\nnlevels(h_gap_dropped$country)## [1] 5\n# Use forcats::fct_drop() on a free-range factor\n\nh_gap$country %>%\n  fct_drop() %>%\n  levels()## [1] \"Egypt\"     \"Haiti\"     \"Romania\"   \"Thailand\"  \"Venezuela\""},{"path":"wrangling.html","id":"change-order-of-the-levels","chapter":"2 Wrangling","heading":"2.3.2 Change order of the levels","text":"default, factor levels ordered alphabetically. think , ordering might well random! preferable order levels according principle:Frequency. Make common level first .Another variable. Order factor levels according summary statistic another variable.First, let’s order continent frequency, forwards backwards. often great idea tables figures, esp. frequency barplots.two barcharts frequency continent differ order continents. prefer?Now order country another variable, forwards backwards. variable usually quantitative order factor according grouped summary. factor grouping variable default summarizing function median() can specify something else.reorder factor levels? often makes plots much better! factor mapped x y, almost always reordered quantitative variable mapping one.\nCompare interpretability two plots life expectancy Asian countries 2007. difference order country factor. one find easier learn ?Use fct_reorder2() line chart quantitative x another quantitative y factor provides color. way legend appears order data! Note, order taken right side plot (left). Contrast legend left one right.Sometimes just want hoist one levels front. ? said . resembles move variables front dplyr::select(special_var, everything()).might useful preparing report , say, Romanian government. reason always putting Romania first nothing data, important external reasons need way express .","code":"\n# Default order is alphabetical\n\ngapminder$continent %>%\n  levels()## [1] \"Africa\"   \"Americas\" \"Asia\"     \"Europe\"   \"Oceania\"\n# Order by frequency\n\ngapminder$continent %>% \n  fct_infreq() %>%\n  levels()## [1] \"Africa\"   \"Asia\"     \"Europe\"   \"Americas\" \"Oceania\"\n# Backwards!\n\ngapminder$continent %>% \n  fct_infreq() %>%\n  fct_rev() %>% \n  levels()## [1] \"Oceania\"  \"Americas\" \"Europe\"   \"Asia\"     \"Africa\"\n# Order countries by median life expectancy\n\nfct_reorder(gapminder$country, gapminder$lifeExp) %>% \n  levels() %>% head()## [1] \"Sierra Leone\"  \"Guinea-Bissau\" \"Afghanistan\"   \"Angola\"       \n## [5] \"Somalia\"       \"Guinea\"\n# Order according to minimum life exp instead of median\n\nfct_reorder(gapminder$country, gapminder$lifeExp, min) %>% \n  levels() %>% head()## [1] \"Rwanda\"       \"Afghanistan\"  \"Gambia\"       \"Angola\"       \"Sierra Leone\"\n## [6] \"Cambodia\"\n# Backwards!\n\nfct_reorder(gapminder$country, gapminder$lifeExp, .desc = TRUE) %>% \n  levels() %>% head()## [1] \"Iceland\"     \"Japan\"       \"Sweden\"      \"Switzerland\" \"Netherlands\"\n## [6] \"Norway\"\ngap_asia_2007 <- gapminder %>% filter(year == 2007, continent == \"Asia\")\nggplot(gap_asia_2007, aes(x = lifeExp, y = country)) + geom_point()\nggplot(gap_asia_2007, aes(x = lifeExp, y = fct_reorder(country, lifeExp))) +\n  geom_point()\nh_countries <- c(\"Egypt\", \"Haiti\", \"Romania\", \"Thailand\", \"Venezuela\")\nh_gap <- gapminder %>%\n  filter(country %in% h_countries) %>% \n  droplevels()\nggplot(h_gap, aes(x = year, y = lifeExp, color = country)) +\n  geom_line()\nggplot(h_gap, aes(x = year, y = lifeExp,\n                  color = fct_reorder2(country, year, lifeExp))) +\n  geom_line() +\n  labs(color = \"country\")\nh_gap$country %>% \n  levels()## [1] \"Egypt\"     \"Haiti\"     \"Romania\"   \"Thailand\"  \"Venezuela\"\nh_gap$country %>% \n  fct_relevel(\"Romania\", \"Haiti\") %>% \n  levels()## [1] \"Romania\"   \"Haiti\"     \"Egypt\"     \"Thailand\"  \"Venezuela\""},{"path":"wrangling.html","id":"recode-the-levels","chapter":"2 Wrangling","heading":"2.3.3 Recode the levels","text":"Sometimes better ideas certain levels . called recoding.","code":"\ni_gap <- gapminder %>% \n  filter(country %in% c(\"United States\", \"Sweden\", \n                        \"Australia\")) %>% \n  droplevels()\n\ni_gap$country %>% \n  levels()## [1] \"Australia\"     \"Sweden\"        \"United States\"\ni_gap$country %>%\n  fct_recode(\"USA\" = \"United States\", \"Oz\" = \"Australia\") %>% \n  levels()## [1] \"Oz\"     \"Sweden\" \"USA\""},{"path":"wrangling.html","id":"grow-a-factor","chapter":"2 Wrangling","heading":"2.3.4 Grow a factor","text":"Let’s create two data frames, data two countries, dropping unused factor levels.country factors df1 df2 different levels.Can just combine ?Umm, . wrong many levels! Use fct_c() .","code":"\ndf1 <- gapminder %>%\n  filter(country %in% c(\"United States\", \"Mexico\"), year > 2000) %>%\n  droplevels()\ndf2 <- gapminder %>%\n  filter(country %in% c(\"France\", \"Germany\"), year > 2000) %>%\n  droplevels()\nlevels(df1$country)## [1] \"Mexico\"        \"United States\"\nlevels(df2$country)## [1] \"France\"  \"Germany\"\nc(df1$country, df2$country)## [1] 1 1 2 2 1 1 2 2\nfct_c(df1$country, df2$country)## [1] Mexico        Mexico        United States United States France       \n## [6] France        Germany       Germany      \n## Levels: Mexico United States France Germany"},{"path":"wrangling.html","id":"lists","chapter":"2 Wrangling","heading":"2.4 Lists","text":"Lists type vector step complexity atomic vectors, lists can contain lists. makes suitable representing hierarchical tree-like structures. create list list():useful tool working lists str() focuses structure, contents.Unlike atomic vectors, list() can contain mix objects:Lists can even contain lists!","code":"\nx <- list(1, 2, 3)\nx## [[1]]\n## [1] 1\n## \n## [[2]]\n## [1] 2\n## \n## [[3]]\n## [1] 3\nstr(x)## List of 3\n##  $ : num 1\n##  $ : num 2\n##  $ : num 3\nx_named <- list(a = 1, b = 2, c = 3)\nstr(x_named)## List of 3\n##  $ a: num 1\n##  $ b: num 2\n##  $ c: num 3\ny <- list(\"a\", 1L, 1.5, TRUE)\nstr(y)## List of 4\n##  $ : chr \"a\"\n##  $ : int 1\n##  $ : num 1.5\n##  $ : logi TRUE\nz <- list(list(1, 2), list(3, 4))\nstr(z)## List of 2\n##  $ :List of 2\n##   ..$ : num 1\n##   ..$ : num 2\n##  $ :List of 2\n##   ..$ : num 3\n##   ..$ : num 4"},{"path":"wrangling.html","id":"visualizing-lists","chapter":"2 Wrangling","heading":"2.4.1 Visualizing lists","text":"explain complicated list manipulation functions, ’s helpful visual representation lists. example, take three lists:’ll draw follows:three principles:Lists rounded corners. Atomic vectors square corners.Children drawn inside parent, slightly darker background make easier see hierarchy.orientation children (.e. rows columns) isn’t important, ’ll pick row column orientation either save space illustrate important property example.","code":"\nx1 <- list(c(1, 2), c(3, 4))\nx2 <- list(list(1, 2), list(3, 4))\nx3 <- list(1, list(2, list(3)))"},{"path":"wrangling.html","id":"subsetting","chapter":"2 Wrangling","heading":"2.4.2 Subsetting","text":"three ways subset list, ’ll illustrate list named :[ extracts sub-list. result always list.Like vectors, can subset logical, integer, character vector.[[ extracts single component list. removes level hierarchy list.$ shorthand extracting named elements list. works similarly [[ except don’t need use quotes.distinction [ [[ really important lists, [[ drills list [ returns new, smaller list. Compare code output visual representation.\nFigure 2.2: Subsetting list, visually.\n","code":"\na <- list(a = 1:3, b = \"a string\", c = pi, d = list(-1, -5))\nstr(a[1:2])## List of 2\n##  $ a: int [1:3] 1 2 3\n##  $ b: chr \"a string\"\nstr(a[4])## List of 1\n##  $ d:List of 2\n##   ..$ : num -1\n##   ..$ : num -5\nstr(a[[1]])##  int [1:3] 1 2 3\nstr(a[[4]])## List of 2\n##  $ : num -1\n##  $ : num -5\na$a## [1] 1 2 3\na[[\"a\"]]## [1] 1 2 3"},{"path":"wrangling.html","id":"lists-of-condiments","chapter":"2 Wrangling","heading":"2.4.3 Lists of condiments","text":"difference [ [[ important, ’s easy get confused. help remember, let show unusual pepper shaker.pepper shaker list x, , x[1] pepper shaker containing single pepper packet:x[2] look , contain second packet. x[1:2] pepper shaker containing two pepper packets.x[[1]] :wanted get content pepper package, ’d need x[[1]][[1]]:","code":""},{"path":"wrangling.html","id":"date-times","chapter":"2 Wrangling","heading":"2.5 Date-Times","text":"manipulate date-times using lubridate package, makes easier work dates times R. lubridate part core tidyverse need ’re working dates/times.three types date/time data refer instant time:date. Tibbles print <date>.date. Tibbles print <date>.time within day. Tibbles print <time>.time within day. Tibbles print <time>.date-time date plus time: uniquely identifies \ninstant time (typically nearest second). Tibbles print \n<dttm>. Elsewhere R called POSIXct, don’t think\n’s useful name.date-time date plus time: uniquely identifies \ninstant time (typically nearest second). Tibbles print \n<dttm>. Elsewhere R called POSIXct, don’t think\n’s useful name.always use simplest possible data type works needs. means can use date instead date-time, . Date-times substantially complicated need handle time zones, ’ll come back end chapter.get current date date-time can use today() now():Otherwise, three ways ’re likely create date/time:string.individual date-time components.existing date/time object.work follows:","code":"\ntoday()## [1] \"2020-11-27\"\nnow()## [1] \"2020-11-27 19:34:10 CET\""},{"path":"wrangling.html","id":"from-strings","chapter":"2 Wrangling","heading":"2.5.1 From strings","text":"Date/time data often comes strings. lubridate functions automatically work format specify order component. use , identify order year, month, day appear dates, arrange “y”, “m”, “d” order. gives name lubridate function parse date. example:functions also take unquoted numbers. concise way create single date/time object, might need filtering date/time data. ymd() short unambiguous:ymd() friends create dates. create date-time, add underscore one “h”, “m”, “s” name parsing function:can also force creation date-time date supplying timezone:","code":"\nymd(\"2017-01-31\")## [1] \"2017-01-31\"\nmdy(\"January 31st, 2017\")## [1] \"2017-01-31\"\ndmy(\"31-Jan-2017\")## [1] \"2017-01-31\"\nymd(20170131)## [1] \"2017-01-31\"\nymd_hms(\"2017-01-31 20:11:59\")## [1] \"2017-01-31 20:11:59 UTC\"\nmdy_hm(\"01/31/2017 08:01\")## [1] \"2017-01-31 08:01:00 UTC\"\nymd(20170131, tz = \"UTC\")## [1] \"2017-01-31 UTC\""},{"path":"wrangling.html","id":"from-individual-components","chapter":"2 Wrangling","heading":"2.5.2 From individual components","text":"Instead single string, sometimes ’ll individual components date-time spread across multiple columns. flights data:create date/time sort input, use make_date() dates, make_datetime() date-times:Let’s thing four time columns flights. times represented slightly odd format, use modulus arithmetic pull hour minute components. ’ve created date-time variables, focus variables ’ll explore rest chapter.data, can visualise distribution departure times across year:within single day:Note use date-times numeric context (like histogram), 1 means 1 second, binwidth 86400 means one day. dates, 1 means 1 day.","code":"\nflights %>% \n  select(year, month, day, hour, minute)## # A tibble: 336,776 x 5\n##     year month   day  hour minute\n##    <int> <int> <int> <dbl>  <dbl>\n##  1  2013     1     1     5     15\n##  2  2013     1     1     5     29\n##  3  2013     1     1     5     40\n##  4  2013     1     1     5     45\n##  5  2013     1     1     6      0\n##  6  2013     1     1     5     58\n##  7  2013     1     1     6      0\n##  8  2013     1     1     6      0\n##  9  2013     1     1     6      0\n## 10  2013     1     1     6      0\n## # … with 336,766 more rows\nflights %>% \n  select(year, month, day, hour, minute) %>% \n  mutate(departure = make_datetime(year, month, day, hour, minute))## # A tibble: 336,776 x 6\n##     year month   day  hour minute departure          \n##    <int> <int> <int> <dbl>  <dbl> <dttm>             \n##  1  2013     1     1     5     15 2013-01-01 05:15:00\n##  2  2013     1     1     5     29 2013-01-01 05:29:00\n##  3  2013     1     1     5     40 2013-01-01 05:40:00\n##  4  2013     1     1     5     45 2013-01-01 05:45:00\n##  5  2013     1     1     6      0 2013-01-01 06:00:00\n##  6  2013     1     1     5     58 2013-01-01 05:58:00\n##  7  2013     1     1     6      0 2013-01-01 06:00:00\n##  8  2013     1     1     6      0 2013-01-01 06:00:00\n##  9  2013     1     1     6      0 2013-01-01 06:00:00\n## 10  2013     1     1     6      0 2013-01-01 06:00:00\n## # … with 336,766 more rows\nmake_datetime_100 <- function(year, month, day, time) {\n  make_datetime(year, month, day, time %/% 100, time %% 100)\n}\nflights_dt <- flights %>% \n  filter(!is.na(dep_time), !is.na(arr_time)) %>% \n  mutate(\n    dep_time = make_datetime_100(year, month, day, dep_time),\n    arr_time = make_datetime_100(year, month, day, arr_time),\n    sched_dep_time = make_datetime_100(year, month, day, sched_dep_time),\n    sched_arr_time = make_datetime_100(year, month, day, sched_arr_time)\n  ) %>% \n  select(origin, dest, ends_with(\"delay\"), ends_with(\"time\"))\nflights_dt## # A tibble: 328,063 x 9\n##    origin dest  dep_delay arr_delay dep_time            sched_dep_time     \n##    <chr>  <chr>     <dbl>     <dbl> <dttm>              <dttm>             \n##  1 EWR    IAH           2        11 2013-01-01 05:17:00 2013-01-01 05:15:00\n##  2 LGA    IAH           4        20 2013-01-01 05:33:00 2013-01-01 05:29:00\n##  3 JFK    MIA           2        33 2013-01-01 05:42:00 2013-01-01 05:40:00\n##  4 JFK    BQN          -1       -18 2013-01-01 05:44:00 2013-01-01 05:45:00\n##  5 LGA    ATL          -6       -25 2013-01-01 05:54:00 2013-01-01 06:00:00\n##  6 EWR    ORD          -4        12 2013-01-01 05:54:00 2013-01-01 05:58:00\n##  7 EWR    FLL          -5        19 2013-01-01 05:55:00 2013-01-01 06:00:00\n##  8 LGA    IAD          -3       -14 2013-01-01 05:57:00 2013-01-01 06:00:00\n##  9 JFK    MCO          -3        -8 2013-01-01 05:57:00 2013-01-01 06:00:00\n## 10 LGA    ORD          -2         8 2013-01-01 05:58:00 2013-01-01 06:00:00\n## # … with 328,053 more rows, and 3 more variables: arr_time <dttm>,\n## #   sched_arr_time <dttm>, air_time <dbl>\nflights_dt %>% \n  ggplot(aes(dep_time)) + \n  geom_freqpoly(binwidth = 86400) # 86400 seconds = 1 day\nflights_dt %>% \n  filter(dep_time < ymd(20130102)) %>% \n  ggplot(aes(dep_time)) + \n  geom_freqpoly(binwidth = 600) # 600 s = 10 minutes"},{"path":"wrangling.html","id":"from-other-types","chapter":"2 Wrangling","heading":"2.5.3 From other types","text":"may want switch date-time date. ’s job as_datetime() as_date():Sometimes ’ll get date/times numeric offsets “Unix Epoch”, 1970-01-01. offset seconds, use as_datetime(); ’s days, use as_date().","code":"\nas_datetime(today())## [1] \"2020-11-27 UTC\"\nas_date(now())## [1] \"2020-11-27\"\nas_datetime(60 * 60 * 10)## [1] \"1970-01-01 10:00:00 UTC\"\nas_date(365 * 10 + 2)## [1] \"1980-01-01\""},{"path":"wrangling.html","id":"date-time-components","chapter":"2 Wrangling","heading":"2.5.4 Date-time components","text":"Now know get date-time data R’s date-time data structures, let’s explore can . section focus accessor functions let get set individual components. next section look arithmetic works date-times.can pull individual parts date accessor functions year(), month(), mday() (day month), yday() (day year), wday() (day week), hour(), minute(), second().month() wday() can set label = TRUE return abbreviated name month day week. Set abbr = FALSE return full name.can use wday() see flights depart week weekend:’s interesting pattern look average departure delay minute within hour. looks like flights leaving minutes 20-30 50-60 much lower delays rest hour!Interestingly, look scheduled departure time don’t see strong pattern:see pattern actual departure times? Well, like much data collected humans, ’s strong bias towards flights leaving “nice” departure times. Always alert sort pattern whenever work data involves human judgement!","code":"\ndatetime <- ymd_hms(\"2016-07-08 12:34:56\")\nyear(datetime)## [1] 2016\nmonth(datetime)## [1] 7\nmday(datetime)## [1] 8\nyday(datetime)## [1] 190\nwday(datetime)## [1] 6\nmonth(datetime, label = TRUE)## [1] Jul\n## 12 Levels: Jan < Feb < Mar < Apr < May < Jun < Jul < Aug < Sep < ... < Dec\nwday(datetime, label = TRUE, abbr = FALSE)## [1] Friday\n## 7 Levels: Sunday < Monday < Tuesday < Wednesday < Thursday < ... < Saturday\nflights_dt %>% \n  mutate(wday = wday(dep_time, label = TRUE)) %>% \n  ggplot(aes(x = wday)) +\n    geom_bar()\nflights_dt %>% \n  mutate(minute = minute(dep_time)) %>% \n  group_by(minute) %>% \n  summarise(\n    avg_delay = mean(arr_delay, na.rm = TRUE),\n    n = n()) %>% \n  ggplot(aes(minute, avg_delay)) +\n    geom_line()## `summarise()` ungrouping output (override with `.groups` argument)\nsched_dep <- flights_dt %>% \n  mutate(minute = minute(sched_dep_time)) %>% \n  group_by(minute) %>% \n  summarise(\n    avg_delay = mean(arr_delay, na.rm = TRUE),\n    n = n())## `summarise()` ungrouping output (override with `.groups` argument)\nggplot(sched_dep, aes(minute, avg_delay)) +\n  geom_line()\nggplot(sched_dep, aes(minute, n)) +\n  geom_line()"},{"path":"wrangling.html","id":"setting-components","chapter":"2 Wrangling","heading":"2.5.5 Setting components","text":"can create new date-time update().values big, roll-:can use update() show distribution flights across course day every day year:Setting larger components date constant powerful technique allows explore patterns smaller components.","code":"\nupdate(datetime, year = 2020, month = 2, mday = 2, hour = 2)## [1] \"2020-02-02 02:34:56 UTC\"\nymd(\"2015-02-01\") %>% \n  update(mday = 30)## [1] \"2015-03-02\"\nymd(\"2015-02-01\") %>% \n  update(hour = 400)## [1] \"2015-02-17 16:00:00 UTC\"\nflights_dt %>% \n  mutate(dep_hour = update(dep_time, yday = 1)) %>% \n  ggplot(aes(dep_hour)) +\n    geom_freqpoly(binwidth = 300)"},{"path":"wrangling.html","id":"time-zones","chapter":"2 Wrangling","heading":"2.5.6 Time zones","text":"Time zones enormously complicated topic interaction geopolitical entities. Fortunately don’t need dig details ’re important data analysis. can see complete list possible timezones function OlsonNames(). Unless otherwise specified, lubridate always uses UTC (Coordinated Universal Time).R, time zone attribute date-time controls printing. example, three objects represent instant time:","code":"\n(x1 <- ymd_hms(\"2015-06-01 12:00:00\", tz = \"America/New_York\"))## [1] \"2015-06-01 12:00:00 EDT\"\n(x2 <- ymd_hms(\"2015-06-01 18:00:00\", tz = \"Europe/Copenhagen\"))## [1] \"2015-06-01 18:00:00 CEST\"\n(x3 <- ymd_hms(\"2015-06-02 04:00:00\", tz = \"Pacific/Auckland\"))## [1] \"2015-06-02 04:00:00 NZST\""},{"path":"wrangling.html","id":"combining-data","chapter":"2 Wrangling","heading":"2.6 Combining Data","text":"many ways bring data together.Bind - basically smashing rocks tibbles together. can smash things together row-wise (“row binding”) column-wise (“column binding”). characterize rock-smashing? ’re often fairly crude operations, lots responsibility falling analyst making sure whole enterprise even makes sense.row binding, need consider variables two tibbles. variables exist ? type? Different approaches row binding different combinations flexibility vs rigidity around matters.column binding, onus entirely analyst make sure rows aligned. avoid column binding whenever possible. can introduce new variables , safer means, ! safer, mean: use mechanism row alignment correct definition. proper join gold standard.Join - designate variable (combination variables) key. row one data frame gets matched row another data frame key. can bring information variables secondary data frame primary data frame based key-based lookup. description incredibly oversimplified, ’s basic idea.variety row- column-wise operations fit framework, implies many different flavors join. concepts vocabulary around joins come database world. relevant functions dplyr follow convention mention join. relevant base R function merge().Let’s explore type operation examples.","code":""},{"path":"wrangling.html","id":"row-binding","chapter":"2 Wrangling","heading":"2.6.1 Row binding","text":"’s perfect row bind three (untidy!) data frames looks like using data Lord Rings trilogy.dplyr::bind_rows() works like charm row-bindable data frames. one data frames somehow missing variable? Let’s mangle one find .see dplyr::bind_rows() row bind puts NA missing values caused lack Female data Two Towers. Nonetheless, can problematic dissimilar datasets.","code":"\nfship <- tribble(\n                         ~Film,    ~Race, ~Female, ~Male,\n  \"The Fellowship Of The Ring\",    \"Elf\",    1229,   971,\n  \"The Fellowship Of The Ring\", \"Hobbit\",      14,  3644,\n  \"The Fellowship Of The Ring\",    \"Man\",       0,  1995\n)\nrking <- tribble(\n                         ~Film,    ~Race, ~Female, ~Male,\n      \"The Return Of The King\",    \"Elf\",     183,   510,\n      \"The Return Of The King\", \"Hobbit\",       2,  2673,\n      \"The Return Of The King\",    \"Man\",     268,  2459\n)\nttow <- tribble(\n                         ~Film,    ~Race, ~Female, ~Male,\n              \"The Two Towers\",    \"Elf\",     331,   513,\n              \"The Two Towers\", \"Hobbit\",       0,  2463,\n              \"The Two Towers\",    \"Man\",     401,  3589\n)\n(lotr_untidy <- bind_rows(fship, ttow, rking))## # A tibble: 9 x 4\n##   Film                       Race   Female  Male\n##   <chr>                      <chr>   <dbl> <dbl>\n## 1 The Fellowship Of The Ring Elf      1229   971\n## 2 The Fellowship Of The Ring Hobbit     14  3644\n## 3 The Fellowship Of The Ring Man         0  1995\n## 4 The Two Towers             Elf       331   513\n## 5 The Two Towers             Hobbit      0  2463\n## 6 The Two Towers             Man       401  3589\n## 7 The Return Of The King     Elf       183   510\n## 8 The Return Of The King     Hobbit      2  2673\n## 9 The Return Of The King     Man       268  2459\nttow_no_Female <- ttow %>% mutate(Female = NULL)\nbind_rows(fship, ttow_no_Female, rking)## # A tibble: 9 x 4\n##   Film                       Race   Female  Male\n##   <chr>                      <chr>   <dbl> <dbl>\n## 1 The Fellowship Of The Ring Elf      1229   971\n## 2 The Fellowship Of The Ring Hobbit     14  3644\n## 3 The Fellowship Of The Ring Man         0  1995\n## 4 The Two Towers             Elf        NA   513\n## 5 The Two Towers             Hobbit     NA  2463\n## 6 The Two Towers             Man        NA  3589\n## 7 The Return Of The King     Elf       183   510\n## 8 The Return Of The King     Hobbit      2  2673\n## 9 The Return Of The King     Man       268  2459\nrbind(fship, ttow_no_Female, rking)## Error in rbind(deparse.level, ...): numbers of columns of arguments do not match"},{"path":"wrangling.html","id":"column-binding","chapter":"2 Wrangling","heading":"2.6.2 Column binding","text":"\nFigure 2.3: Attempting bind columns correctly\nColumn binding much dangerous often “works” . ’s job make sure rows aligned ’s easy screw .data gapminder originally excavated 3 messy Excel spreadsheets: one life expectancy, population, GDP per capital. Let’s relive data wrangling joy show column bind gone wrong.create 3 separate data frames, evil row sorting, column bind. errors. result gapminder_garbage sort looks OK. Univariate summary statistics exploratory plots look OK. ’ve created complete nonsense!One last cautionary tale column binding. one requires use cbind() ’s tidyverse generally unwilling recycle combining things different length.create tibble gapminder columns. create another remainder, filtered just one country. able cbind() objects! ? 12 rows Canada divide evenly 1704 rows gapminder. Note dplyr::bind_cols() refuses column bind .data frame isn’t obviously wrong, wrong. See Canada’s population GDP per capita repeat country?Bottom line: Row bind need , inspect results re: coercion. Column bind must extremely paranoid.","code":"\nlife_exp <- gapminder %>%\n  select(country, year, lifeExp)\n\npop <- gapminder %>%\n  arrange(year) %>% \n  select(pop)\n  \ngdp_percap <- gapminder %>% \n  arrange(pop) %>% \n  select(gdpPercap)\n\n(gapminder_garbage <- bind_cols(life_exp, pop, gdp_percap))## # A tibble: 1,704 x 5\n##    country      year lifeExp      pop gdpPercap\n##    <fct>       <int>   <dbl>    <int>     <dbl>\n##  1 Afghanistan  1952    28.8  8425333      880.\n##  2 Afghanistan  1957    30.3  1282697      861.\n##  3 Afghanistan  1962    32.0  9279525     2670.\n##  4 Afghanistan  1967    34.0  4232095     1072.\n##  5 Afghanistan  1972    36.1 17876956     1385.\n##  6 Afghanistan  1977    38.4  8691212     2865.\n##  7 Afghanistan  1982    39.9  6927772     1533.\n##  8 Afghanistan  1987    40.8   120447     1738.\n##  9 Afghanistan  1992    41.7 46886859     3021.\n## 10 Afghanistan  1997    41.8  8730405     1890.\n## # … with 1,694 more rows\nsummary(gapminder$lifeExp)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##      24      48      61      59      71      83\nsummary(gapminder_garbage$lifeExp)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##      24      48      61      59      71      83\nrange(gapminder$gdpPercap)## [1]    241 113523\nrange(gapminder_garbage$gdpPercap)## [1]    241 113523\ngapminder_mostly <- gapminder %>% select(-pop, -gdpPercap)\ngapminder_leftovers_filtered <- gapminder %>% \n  filter(country == \"Canada\") %>% \n  select(pop, gdpPercap)\n\ngapminder_nonsense <- cbind(gapminder_mostly, gapminder_leftovers_filtered)\nhead(gapminder_nonsense, 14)##        country continent year lifeExp      pop gdpPercap\n## 1  Afghanistan      Asia 1952      29 14785584     11367\n## 2  Afghanistan      Asia 1957      30 17010154     12490\n## 3  Afghanistan      Asia 1962      32 18985849     13462\n## 4  Afghanistan      Asia 1967      34 20819767     16077\n## 5  Afghanistan      Asia 1972      36 22284500     18971\n## 6  Afghanistan      Asia 1977      38 23796400     22091\n## 7  Afghanistan      Asia 1982      40 25201900     22899\n## 8  Afghanistan      Asia 1987      41 26549700     26627\n## 9  Afghanistan      Asia 1992      42 28523502     26343\n## 10 Afghanistan      Asia 1997      42 30305843     28955\n## 11 Afghanistan      Asia 2002      42 31902268     33329\n## 12 Afghanistan      Asia 2007      44 33390141     36319\n## 13     Albania    Europe 1952      55 14785584     11367\n## 14     Albania    Europe 1957      59 17010154     12490"},{"path":"wrangling.html","id":"joins-in-dplyr","chapter":"2 Wrangling","heading":"2.6.3 Joins in dplyr","text":"recent release gapminder includes new data frame, country_codes, country names ISO codes. Therefore can also use practice joins.Join (.k.. merge) two tables: dplyr join cheatsheet comic characters publishers.Working two small data frames: superheroes publishers.Sorry, cheat sheet illustrate “multiple match” situations terribly well.Sub-plot: watch row variable order join results healthy reminder ’s dangerous rely analysis.","code":"\ngapminder %>% \n  select(country, continent) %>% \n  group_by(country) %>% \n  slice(1) %>% \n  left_join(country_codes)## Joining, by = \"country\"## # A tibble: 142 x 4\n## # Groups:   country [142]\n##    country     continent iso_alpha iso_num\n##    <chr>       <fct>     <chr>       <int>\n##  1 Afghanistan Asia      AFG             4\n##  2 Albania     Europe    ALB             8\n##  3 Algeria     Africa    DZA            12\n##  4 Angola      Africa    AGO            24\n##  5 Argentina   Americas  ARG            32\n##  6 Australia   Oceania   AUS            36\n##  7 Austria     Europe    AUT            40\n##  8 Bahrain     Asia      BHR            48\n##  9 Bangladesh  Asia      BGD            50\n## 10 Belgium     Europe    BEL            56\n## # … with 132 more rows\nsuperheroes <- tibble::tribble(\n       ~name, ~alignment,  ~gender,          ~publisher,\n   \"Magneto\",      \"bad\",   \"male\",            \"Marvel\",\n     \"Storm\",     \"good\", \"female\",            \"Marvel\",\n  \"Mystique\",      \"bad\", \"female\",            \"Marvel\",\n    \"Batman\",     \"good\",   \"male\",                \"DC\",\n     \"Joker\",      \"bad\",   \"male\",                \"DC\",\n  \"Catwoman\",      \"bad\", \"female\",                \"DC\",\n   \"Hellboy\",     \"good\",   \"male\", \"Dark Horse Comics\"\n  )\n\npublishers <- tibble::tribble(\n  ~publisher, ~yr_founded,\n        \"DC\",       1934L,\n    \"Marvel\",       1939L,\n     \"Image\",       1992L\n  )"},{"path":"wrangling.html","id":"inner_join","chapter":"2 Wrangling","heading":"2.6.3.1 inner_join()","text":"inner_join(x, y): Return rows x matching values y, columns x y. multiple matches x y, combination matches returned. mutating join.\nFigure 2.4: Inner join.\nlose Hellboy join , although appears x = superheroes, publisher Dark Horse Comics appear y = publishers. join result variables x = superheroes plus yr_founded, y.Now compare result using inner_join() two datasets opposite positions.way, illustrate multiple matches, think x = publishers direction. Every publisher match y = superheroes appears multiple times result, match. fact, ’re getting result inner_join(superheroes, publishers), variable order (also never rely analysis).inner_join() solve nearly problems ’ll encounter book.","code":"\n(ijsp <- inner_join(superheroes, publishers))## Joining, by = \"publisher\"## # A tibble: 6 x 5\n##   name     alignment gender publisher yr_founded\n##   <chr>    <chr>     <chr>  <chr>          <int>\n## 1 Magneto  bad       male   Marvel          1939\n## 2 Storm    good      female Marvel          1939\n## 3 Mystique bad       female Marvel          1939\n## 4 Batman   good      male   DC              1934\n## 5 Joker    bad       male   DC              1934\n## 6 Catwoman bad       female DC              1934\n(ijps <- inner_join(publishers, superheroes))## Joining, by = \"publisher\"## # A tibble: 6 x 5\n##   publisher yr_founded name     alignment gender\n##   <chr>          <int> <chr>    <chr>     <chr> \n## 1 DC              1934 Batman   good      male  \n## 2 DC              1934 Joker    bad       male  \n## 3 DC              1934 Catwoman bad       female\n## 4 Marvel          1939 Magneto  bad       male  \n## 5 Marvel          1939 Storm    good      female\n## 6 Marvel          1939 Mystique bad       female"},{"path":"wrangling.html","id":"full_join","chapter":"2 Wrangling","heading":"2.6.3.2 full_join()","text":"full_join(x, y): Return rows columns x y. matching values, returns NA one missing. mutating join.get rows x = superheroes plus new row y = publishers, containing publisher Image. get variables x = superheroes variables y = publishers. row derives solely one table carries NAs variables found table.full_join() returns rows columns x y result full_join(x = superheroes, y = publishers) match full_join(x = publishers, y = superheroes).","code":"\n(fjsp <- full_join(superheroes, publishers))## Joining, by = \"publisher\"## # A tibble: 8 x 5\n##   name     alignment gender publisher         yr_founded\n##   <chr>    <chr>     <chr>  <chr>                  <int>\n## 1 Magneto  bad       male   Marvel                  1939\n## 2 Storm    good      female Marvel                  1939\n## 3 Mystique bad       female Marvel                  1939\n## 4 Batman   good      male   DC                      1934\n## 5 Joker    bad       male   DC                      1934\n## 6 Catwoman bad       female DC                      1934\n## 7 Hellboy  good      male   Dark Horse Comics         NA\n## 8 <NA>     <NA>      <NA>   Image                   1992"},{"path":"wrangling.html","id":"left_join","chapter":"2 Wrangling","heading":"2.6.3.3 left_join()","text":"left_join(x, y): Return rows x, columns x y. multiple matches x y, combination matches returned. mutating join.basically get x = superheroes back, addition variable yr_founded, unique y = publishers. Hellboy, whose publisher appear y = publishers, NA yr_founded.Now compare result running left_join(x = publishers, y = superheroes). Unlike inner_join() full_join() order arguments significant effect resulting dataframe.get similar result inner_join() publisher Image survives join, even though superheroes Image appear y = superheroes. result, Image NAs name, alignment, gender.similar function, right_join(x, y) return rows y, columns x y. Like left_join(), mutating join.","code":"\n(ljsp <- left_join(superheroes, publishers))## Joining, by = \"publisher\"## # A tibble: 7 x 5\n##   name     alignment gender publisher         yr_founded\n##   <chr>    <chr>     <chr>  <chr>                  <int>\n## 1 Magneto  bad       male   Marvel                  1939\n## 2 Storm    good      female Marvel                  1939\n## 3 Mystique bad       female Marvel                  1939\n## 4 Batman   good      male   DC                      1934\n## 5 Joker    bad       male   DC                      1934\n## 6 Catwoman bad       female DC                      1934\n## 7 Hellboy  good      male   Dark Horse Comics         NA\n(ljps <- left_join(publishers, superheroes))## Joining, by = \"publisher\"## # A tibble: 7 x 5\n##   publisher yr_founded name     alignment gender\n##   <chr>          <int> <chr>    <chr>     <chr> \n## 1 DC              1934 Batman   good      male  \n## 2 DC              1934 Joker    bad       male  \n## 3 DC              1934 Catwoman bad       female\n## 4 Marvel          1939 Magneto  bad       male  \n## 5 Marvel          1939 Storm    good      female\n## 6 Marvel          1939 Mystique bad       female\n## 7 Image           1992 <NA>     <NA>      <NA>"},{"path":"wrangling.html","id":"semi_join","chapter":"2 Wrangling","heading":"2.6.3.4 semi_join()","text":"semi_join(x, y): Return rows x matching values y, keeping just columns x. semi join differs inner join inner join return one row x matching row y, semi join never duplicate rows x. filtering join.get similar result inner_join() join result contains variables originally found x = superheroes.Now compare result switching values arguments.Now effects switching x y roles clear. result resembles x = publishers, publisher Image lost, observations publisher == \"Image\" y = superheroes.","code":"\n(sjsp <- semi_join(superheroes, publishers))## Joining, by = \"publisher\"## # A tibble: 6 x 4\n##   name     alignment gender publisher\n##   <chr>    <chr>     <chr>  <chr>    \n## 1 Magneto  bad       male   Marvel   \n## 2 Storm    good      female Marvel   \n## 3 Mystique bad       female Marvel   \n## 4 Batman   good      male   DC       \n## 5 Joker    bad       male   DC       \n## 6 Catwoman bad       female DC\n(sjps <- semi_join(x = publishers, y = superheroes))## Joining, by = \"publisher\"## # A tibble: 2 x 2\n##   publisher yr_founded\n##   <chr>          <int>\n## 1 DC              1934\n## 2 Marvel          1939"},{"path":"wrangling.html","id":"anti_joinsuperheroes-publishers","chapter":"2 Wrangling","heading":"2.6.3.5 anti_join(superheroes, publishers)","text":"anti_join(x, y): Return rows x matching values y, keeping just columns x. filtering join.keep Hellboy now (get yr_founded).Now switch arguments compare result.keep publisher Image now (variables found x = publishers).","code":"\n(ajsp <- anti_join(superheroes, publishers))## Joining, by = \"publisher\"## # A tibble: 1 x 4\n##   name    alignment gender publisher        \n##   <chr>   <chr>     <chr>  <chr>            \n## 1 Hellboy good      male   Dark Horse Comics\n(ajps <- anti_join(publishers, superheroes))## Joining, by = \"publisher\"## # A tibble: 1 x 2\n##   publisher yr_founded\n##   <chr>          <int>\n## 1 Image           1992"},{"path":"wrangling.html","id":"join-data-frames-with-key-variables","chapter":"2 Wrangling","heading":"2.6.4 Join data frames with “key” variables","text":"“Joining” “merging” two different datasets tricky stuff. Let’s go examples reviewing basic concepts. flights data frame, variable carrier lists carrier code different flights. corresponding airline names \"UA\" \"AA\" might somewhat easy guess (United American Airlines), airlines codes \"VX\", \"HA\", \"B6\"? information provided separate data frame airlines.see airports, carrier carrier code, name full name airline company. Using table, can see \"VX\", \"HA\", \"B6\" correspond Virgin America, Hawaiian Airlines, JetBlue, respectively. However, wouldn’t nice information single data frame instead two separate data frames? can “joining” flights airlines data frames.Note values variable carrier flights data frame match values variable carrier airlines data frame. case, can use variable carrier key variable match rows two data frames. Key variables almost always identification variables uniquely identify observational units. ensures rows data frames appropriately matched join. (???) created following diagram help us understand different data frames nycflights13 package linked various key variables:\nFigure 2.5: Relationships among nycflights tables\n","code":"\nView(airlines)"},{"path":"wrangling.html","id":"matching-key-variable-names","chapter":"2 Wrangling","heading":"2.6.4.1 Matching “key” variable names","text":"flights airlines data frames, key variable want join/merge/match rows name: carrier. Let’s use inner_join() function join two data frames, rows matched variable carrier, compare resulting data frames:Observe flights flights_joined data frames identical except flights_joined additional variable name. values name correspond airline companies’ names indicated airlines data frame.Say instead interested destinations domestic flights departing NYC 2013, ask questions like: “cities airports ?”, “\"ORD\" Orlando?”, “\"FLL\"?”.airports data frame contains airport codes airport:However, look airports flights data frames, ’ll find airport codes variables different names. airports airport code faa, whereas flights airport codes origin dest.order join two data frames airport code, inner_join() operation use = c(\"dest\" = \"faa\") argument modified code syntax allowing us join two data frames key variable different name:Let’s construct chain pipe operators %>% computes number flights NYC destination, also includes information destination airport:case didn’t know, \"ORD\" airport code Chicago O’Hare airport \"FLL\" main airport Fort Lauderdale, Florida, can seen airport_name variable.","code":"\nflights_joined <- flights %>% \n  inner_join(airlines, by = \"carrier\")\nView(flights)\nView(flights_joined)\nView(airports)\nflights_with_airport_names <- flights %>% \n  inner_join(airports, by = c(\"dest\" = \"faa\"))\nView(flights_with_airport_names)\nnamed_dests <- flights %>%\n  group_by(dest) %>%\n  summarize(num_flights = n(),\n            .groups = \"drop\") %>%\n  arrange(desc(num_flights)) %>%\n  inner_join(airports, by = c(\"dest\" = \"faa\")) %>%\n  rename(airport_name = name)\nnamed_dests## # A tibble: 101 x 9\n##    dest  num_flights airport_name          lat    lon   alt    tz dst   tzone   \n##    <chr>       <int> <chr>               <dbl>  <dbl> <dbl> <dbl> <chr> <chr>   \n##  1 ORD         17283 Chicago Ohare Intl   42.0  -87.9   668    -6 A     America…\n##  2 ATL         17215 Hartsfield Jackson…  33.6  -84.4  1026    -5 A     America…\n##  3 LAX         16174 Los Angeles Intl     33.9 -118.    126    -8 A     America…\n##  4 BOS         15508 General Edward Law…  42.4  -71.0    19    -5 A     America…\n##  5 MCO         14082 Orlando Intl         28.4  -81.3    96    -5 A     America…\n##  6 CLT         14064 Charlotte Douglas …  35.2  -80.9   748    -5 A     America…\n##  7 SFO         13331 San Francisco Intl   37.6 -122.     13    -8 A     America…\n##  8 FLL         12055 Fort Lauderdale Ho…  26.1  -80.2     9    -5 A     America…\n##  9 MIA         11728 Miami Intl           25.8  -80.3     8    -5 A     America…\n## 10 DCA          9705 Ronald Reagan Wash…  38.9  -77.0    15    -5 A     America…\n## # … with 91 more rows"},{"path":"wrangling.html","id":"multiple-key-variables","chapter":"2 Wrangling","heading":"2.6.4.2 Multiple “key” variables","text":"Say instead want join two data frames multiple key variables. example, see order join flights weather data frames, need one key variable: year, month, day, hour, origin. combination 5 variables act uniquely identify observational unit weather data frame: hourly weather recordings 3 NYC airports.achieve specifying vector key variables join using c() function. Recall c() short “combine” “concatenate.”","code":"\nflights_weather_joined <- flights %>%\n  inner_join(weather, by = c(\"year\", \"month\", \"day\", \"hour\", \"origin\"))\nView(flights_weather_joined)"},{"path":"wrangling.html","id":"tidy-data","chapter":"2 Wrangling","heading":"2.7 “Tidy” data","text":"Now, explore topic “tidy” data, manner data formatting particularly suited creation graphics manipulation dataframe. see data stored “tidy” format just everyday definition term “tidy” might suggest: data “neatly organized.” Instead, define term “tidy” ’s used data scientists use R, outlining set rules data saved.Knowledge type data formatting necessary treatment data visualization Chapter 1 previous data wrangling topics. data used already “tidy” format. chapter, ’ll now see format essential using tools covered now. Furthermore, also useful subsequent chapters book cover regression statistical inference.Let’s switch gears learn concept “tidy” data format motivating example fivethirtyeight package. fivethirtyeight package provides access datasets used many articles published data journalism website, FiveThirtyEight.com.Let’s focus attention drinks data frame look first 5 rows:reading help file running ?drinks, ’ll see drinks data frame containing results survey average number servings beer, spirits, wine consumed 193 countries. data originally reported FiveThirtyEight.com Mona Chalabi’s article: “Dear Mona Followup: People Drink Beer, Wine Spirits?”.Let’s apply data wrangling verbs drinks data frame:filter() drinks data frame consider 4 countries: United States, China, Italy, Saudi Arabia, thenselect() columns except total_litres_of_pure_alcohol using - sign, thenrename() variables beer_servings, spirit_servings, wine_servings beer, spirit, wine, respectively.save resulting data frame drinks_smaller:Let’s now ask question: \"Using drinks_smaller data frame, create side--side barplot .Let’s break graphic:categorical variable country four levels (China, Italy, Saudi Arabia, USA) mapped x-position bars.numerical variable servings mapped y-position bars (height bars).categorical variable type three levels (beer, spirit, wine) mapped fill color bars.Observe, however, drinks_smaller three separate variables beer, spirit, wine. order use ggplot() function recreate barplot need single variable type three possible values: beer, spirit, wine. map type variable fill aesthetic plot. words, recreate barplot, data frame look like :Observe drinks_smaller drinks_smaller_tidy rectangular shape contain 12 numerical values (3 alcohol types 4 countries), formatted differently. drinks_smaller formatted ’s known “wide” format, whereas drinks_smaller_tidy formatted ’s known “long/narrow” format.context data science R, long/narrow format also known “tidy” format. order use ggplot2 dplyr packages data visualization data wrangling, input data frames must “tidy” format. Thus, non-“tidy” data must converted “tidy” format first. convert non-“tidy” data frames like drinks_smaller “tidy” data frames like drinks_smaller_tidy, let’s define “tidy” data.","code":"## # A tibble: 5 x 5\n##   country    beer_servings spirit_servings wine_servings total_litres_of_pure_a…\n##   <chr>              <int>           <int>         <int>                   <dbl>\n## 1 Afghanist…             0               0             0                     0  \n## 2 Albania               89             132            54                     4.9\n## 3 Algeria               25               0            14                     0.7\n## 4 Andorra              245             138           312                    12.4\n## 5 Angola               217              57            45                     5.9\ndrinks_smaller <- drinks %>%\n  filter(country %in% c(\"USA\", \"China\", \"Italy\", \"Saudi Arabia\")) %>%\n  select(-total_litres_of_pure_alcohol) %>%\n  rename(beer = beer_servings, spirit = spirit_servings, wine = wine_servings)\ndrinks_smaller## # A tibble: 4 x 4\n##   country       beer spirit  wine\n##   <chr>        <int>  <int> <int>\n## 1 China           79    192     8\n## 2 Italy           85     42   237\n## 3 Saudi Arabia     0      5     0\n## 4 USA            249    158    84\ndrinks_smaller_tidy <- drinks_smaller %>% \n  pivot_longer(cols = -country, names_to = \"type\", values_to = \"servings\")\n\ndrinks_smaller_tidy_plot <- ggplot(drinks_smaller_tidy, \n                                   aes(x = country, y = servings, fill = type)) + geom_col(position = \"dodge\") + \n                              labs(x = \"country\", y = \"servings\")\ndrinks_smaller_tidy## # A tibble: 12 x 3\n##    country      type   servings\n##    <chr>        <chr>     <int>\n##  1 China        beer         79\n##  2 China        spirit      192\n##  3 China        wine          8\n##  4 Italy        beer         85\n##  5 Italy        spirit       42\n##  6 Italy        wine        237\n##  7 Saudi Arabia beer          0\n##  8 Saudi Arabia spirit        5\n##  9 Saudi Arabia wine          0\n## 10 USA          beer        249\n## 11 USA          spirit      158\n## 12 USA          wine         84"},{"path":"wrangling.html","id":"definition-of-tidy-data","chapter":"2 Wrangling","heading":"2.7.1 Definition of “tidy” data","text":"mean data “tidy”? “tidy” clear English meaning “organized,” word “tidy” data science using R means data follows standardized format. follow Hadley Wickham’s definition “tidy” data:dataset collection values, usually either numbers (quantitative) strings AKA text data (qualitative/categorical). Values organised two ways. Every value belongs variable observation. variable contains values measure underlying attribute (like height, temperature, duration) across units. observation contains values measured unit (like person, day, city) across attributes.“Tidy” data standard way mapping meaning dataset structure. dataset messy tidy depending rows, columns tables matched observations, variables types. tidy data:variable forms column.observation forms row.type observational unit forms table.","code":""},{"path":"wrangling.html","id":"converting-to-tidy-data","chapter":"2 Wrangling","heading":"2.7.2 Converting to “tidy” data","text":"book far, ’ve seen data frames already “tidy” format. Furthermore, rest book, ’ll mostly see data frames already “tidy” format well. always case however datasets world. original data frame wide (non-“tidy”) format like use ggplot2 dplyr packages, first convert “tidy” format. , recommend using pivot_longer() function tidyr package (???).Going back drinks_smaller data frame earlier:convert “tidy” format using pivot_longer() function tidyr package follows:set arguments pivot_longer() follows:names_to corresponds name variable new “tidy”/long data frame contain column names original data. Observe set names_to = \"type\". resulting drinks_smaller_tidy, column type contains three types alcohol beer, spirit, wine. Since type variable name doesn’t appear drinks_smaller, use quotation marks around . ’ll receive error just use names_to = type .values_to name variable new “tidy” data frame contain values original data. Observe set values_to = \"servings\" since numeric values beer, wine, spirit columns drinks_smaller data corresponds value servings. resulting drinks_smaller_tidy, column servings contains 4 \\(\\times\\) 3 = 12 numerical values. Note servings doesn’t appear variable drinks_smaller needs quotation marks around values_to argument.third argument cols columns drinks_smaller data frame either want don’t want “tidy.” Observe set -country indicating don’t want “tidy” country variable drinks_smaller rather beer, spirit, wine. Since country column appears drinks_smaller don’t put quotation marks around .third argument cols little nuanced, let’s consider code ’s written slightly differently produces output:Note third argument now specifies columns want “tidy” c(beer, spirit, wine), instead columns don’t want “tidy” using -country. use c() function create vector columns drinks_smaller ’d like “tidy.” Note since three columns appear one another drinks_smaller data frame, also following cols argument:drinks_smaller_tidy “tidy” formatted data frame, can now produce barplot saw previously using geom_col(). Recall previous chapter use geom_col() geom_bar(), since like map “pre-counted” servings variable y-aesthetic bars.\nFigure 2.6: Comparing alcohol consumption 4 countries using geom_col().\nConverting “wide” format data “tidy” format often confuses new R users. way learn get comfortable pivot_longer() function practice, practice, practice using different datasets. example, run ?pivot_longer look examples bottom help file.however want convert “tidy” data frame “wide” format, need use pivot_wider() function instead. Run ?pivot_wider look examples bottom help file examples.can also view examples pivot_longer() pivot_wider() tidyverse.org webpage. ’s nice example check different functions available data tidying case study using data World Health Organization webpage. Furthermore, week R4DS Online Learning Community posts dataset weekly #TidyTuesday event might serve nice place find data explore transform.","code":"\ndrinks_smaller## # A tibble: 4 x 4\n##   country       beer spirit  wine\n##   <chr>        <int>  <int> <int>\n## 1 China           79    192     8\n## 2 Italy           85     42   237\n## 3 Saudi Arabia     0      5     0\n## 4 USA            249    158    84\ndrinks_smaller_tidy <- drinks_smaller %>% \n  pivot_longer(names_to = \"type\", \n               values_to = \"servings\", \n               cols = -country)\ndrinks_smaller_tidy## # A tibble: 12 x 3\n##    country      type   servings\n##    <chr>        <chr>     <int>\n##  1 China        beer         79\n##  2 China        spirit      192\n##  3 China        wine          8\n##  4 Italy        beer         85\n##  5 Italy        spirit       42\n##  6 Italy        wine        237\n##  7 Saudi Arabia beer          0\n##  8 Saudi Arabia spirit        5\n##  9 Saudi Arabia wine          0\n## 10 USA          beer        249\n## 11 USA          spirit      158\n## 12 USA          wine         84\ndrinks_smaller %>% \n  pivot_longer(names_to = \"type\", \n               values_to = \"servings\", \n               cols = c(beer, spirit, wine))\ndrinks_smaller %>% \n  pivot_longer(names_to = \"type\", \n               values_to = \"servings\", \n               cols = beer:wine)\nggplot(drinks_smaller_tidy, aes(x = country, y = servings, fill = type)) +\n  geom_col(position = \"dodge\")"},{"path":"wrangling.html","id":"other-commands","chapter":"2 Wrangling","heading":"2.8 Other Commands","text":"commands prove useful rest book.","code":""},{"path":"wrangling.html","id":"na-values","chapter":"2 Wrangling","heading":"2.8.1 NA Values","text":"importing datasets already extensively wrangled, may observations dataframe blank. called missing values, often marked NA. presence NA values dataframe can problematic. Recall previous chapter without setting na.rm = TRUE, following code gives different results.Suppose wanted simply remove missing values gain column. can filter remove missing values using helper function .na(). .na() boolean function takes observation dataframe returns TRUE observation missing value FALSE otherwise. case, use !.na(), ! operator means “”. Thus, can filter observations missing values.can also remove missing values dataset instead merely filtering using drop_na() function. flights dataset contains 336,776 rows. whenAs see , 9,430 rows flights dataset contain missing values gain column. using drop_na(), get:Note 336,776 - 9,430 = 327346, drop_na() seems check . careful drop_na(), however, may removing rows valuable data columns.Suppose want remove missing values instead replace number. can use replace_na() helper function mutate(). replace missing value gain column value 0.must careful , though. Replacing missing values affect statistical result, mean standard deviation. computer mean:Comparing previous mean variable see computed value different.many additional ways manipulate missing values, three functions cover ways need work observations data.","code":"\nflights %>% \n  mutate(gain = arr_delay - dep_delay) %>% \n  summarize(mean = mean(gain))## # A tibble: 1 x 1\n##    mean\n##   <dbl>\n## 1    NA\nflights %>% \n  mutate(gain = arr_delay - dep_delay) %>% \n  summarize(mean = mean(gain, na.rm = TRUE))## # A tibble: 1 x 1\n##    mean\n##   <dbl>\n## 1 -5.66\nflights %>%\n  mutate(gain = arr_delay - dep_delay) %>%\n  filter(!is.na(gain)) %>%\n  summarize(mean = mean(gain))## # A tibble: 1 x 1\n##    mean\n##   <dbl>\n## 1 -5.66\nflights %>%\n  mutate(gain = arr_delay - dep_delay) %>%\n  filter(is.na(gain))## # A tibble: 9,430 x 22\n##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n##    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n##  1  2013     1     1     1525           1530        -5     1934           1805\n##  2  2013     1     1     1528           1459        29     2002           1647\n##  3  2013     1     1     1740           1745        -5     2158           2020\n##  4  2013     1     1     1807           1738        29     2251           2103\n##  5  2013     1     1     1939           1840        59       29           2151\n##  6  2013     1     1     1952           1930        22     2358           2207\n##  7  2013     1     1     2016           1930        46       NA           2220\n##  8  2013     1     1       NA           1630        NA       NA           1815\n##  9  2013     1     1       NA           1935        NA       NA           2240\n## 10  2013     1     1       NA           1500        NA       NA           1825\n## # … with 9,420 more rows, and 14 more variables: arr_delay <dbl>,\n## #   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n## #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>,\n## #   gain <dbl>, hours <dbl>, gain_per_hour <dbl>\nflights %>%\n  mutate(gain = arr_delay - dep_delay) %>%\n  drop_na(gain)## # A tibble: 327,346 x 22\n##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n##    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n##  1  2013     1     1      517            515         2      830            819\n##  2  2013     1     1      533            529         4      850            830\n##  3  2013     1     1      542            540         2      923            850\n##  4  2013     1     1      544            545        -1     1004           1022\n##  5  2013     1     1      554            600        -6      812            837\n##  6  2013     1     1      554            558        -4      740            728\n##  7  2013     1     1      555            600        -5      913            854\n##  8  2013     1     1      557            600        -3      709            723\n##  9  2013     1     1      557            600        -3      838            846\n## 10  2013     1     1      558            600        -2      753            745\n## # … with 327,336 more rows, and 14 more variables: arr_delay <dbl>,\n## #   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n## #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>,\n## #   gain <dbl>, hours <dbl>, gain_per_hour <dbl>\nflights %>%\n  mutate(gain = arr_delay - dep_delay) %>%\n  mutate(gain = replace_na(data = gain, replace = 0))## # A tibble: 336,776 x 22\n##     year month   day dep_time sched_dep_time dep_delay arr_time sched_arr_time\n##    <int> <int> <int>    <int>          <int>     <dbl>    <int>          <int>\n##  1  2013     1     1      517            515         2      830            819\n##  2  2013     1     1      533            529         4      850            830\n##  3  2013     1     1      542            540         2      923            850\n##  4  2013     1     1      544            545        -1     1004           1022\n##  5  2013     1     1      554            600        -6      812            837\n##  6  2013     1     1      554            558        -4      740            728\n##  7  2013     1     1      555            600        -5      913            854\n##  8  2013     1     1      557            600        -3      709            723\n##  9  2013     1     1      557            600        -3      838            846\n## 10  2013     1     1      558            600        -2      753            745\n## # … with 336,766 more rows, and 14 more variables: arr_delay <dbl>,\n## #   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>, dest <chr>,\n## #   air_time <dbl>, distance <dbl>, hour <dbl>, minute <dbl>, time_hour <dttm>,\n## #   gain <dbl>, hours <dbl>, gain_per_hour <dbl>\nflights %>%\n  mutate(gain = arr_delay - dep_delay) %>%\n  mutate(gain = replace_na(data = gain, replace = 0)) %>%\n  summarize(mean = mean(gain))## # A tibble: 1 x 1\n##    mean\n##   <dbl>\n## 1 -5.50"},{"path":"wrangling.html","id":"clean_names","chapter":"2 Wrangling","heading":"2.8.2 clean_names()","text":"Another useful function clean_names() function, included janitor package. function allows standardize column names dataset. can particularly useful reading dataset web. Look flights dataset, .can see column names lowercase, space words represented underscore character. default result clean_names(), running clean_names(flights) effect.Suppose, instead, wanted change column names camel case, word boundaries demarcated upper case letter.Nonetheless, likely ever required use clean_names() default snake case.","code":"\nglimpse(flights)## Rows: 336,776\n## Columns: 22\n## $ year           <int> 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, 2013, …\n## $ month          <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n## $ day            <int> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n## $ dep_time       <int> 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558,…\n## $ sched_dep_time <int> 515, 529, 540, 545, 600, 558, 600, 600, 600, 600, 600,…\n## $ dep_delay      <dbl> 2, 4, 2, -1, -6, -4, -5, -3, -3, -2, -2, -2, -2, -2, -…\n## $ arr_time       <int> 830, 850, 923, 1004, 812, 740, 913, 709, 838, 753, 849…\n## $ sched_arr_time <int> 819, 830, 850, 1022, 837, 728, 854, 723, 846, 745, 851…\n## $ arr_delay      <dbl> 11, 20, 33, -18, -25, 12, 19, -14, -8, 8, -2, -3, 7, -…\n## $ carrier        <chr> \"UA\", \"UA\", \"AA\", \"B6\", \"DL\", \"UA\", \"B6\", \"EV\", \"B6\", …\n## $ flight         <int> 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, …\n## $ tailnum        <chr> \"N14228\", \"N24211\", \"N619AA\", \"N804JB\", \"N668DN\", \"N39…\n## $ origin         <chr> \"EWR\", \"LGA\", \"JFK\", \"JFK\", \"LGA\", \"EWR\", \"EWR\", \"LGA\"…\n## $ dest           <chr> \"IAH\", \"IAH\", \"MIA\", \"BQN\", \"ATL\", \"ORD\", \"FLL\", \"IAD\"…\n## $ air_time       <dbl> 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, …\n## $ distance       <dbl> 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733,…\n## $ hour           <dbl> 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, …\n## $ minute         <dbl> 15, 29, 40, 45, 0, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 59, …\n## $ time_hour      <dttm> 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 …\n## $ gain           <dbl> -9, -16, -31, 17, 19, -16, -24, 11, 5, -10, 0, 1, -9, …\n## $ hours          <dbl> 3.78, 3.78, 2.67, 3.05, 1.93, 2.50, 2.63, 0.88, 2.33, …\n## $ gain_per_hour  <dbl> -2.38, -4.23, -11.62, 5.57, 9.83, -6.40, -9.11, 12.45,…\nflights %>% clean_names(\"small_camel\")## # A tibble: 336,776 x 22\n##     year month   day depTime schedDepTime depDelay arrTime schedArrTime arrDelay\n##    <int> <int> <int>   <int>        <int>    <dbl>   <int>        <int>    <dbl>\n##  1  2013     1     1     517          515        2     830          819       11\n##  2  2013     1     1     533          529        4     850          830       20\n##  3  2013     1     1     542          540        2     923          850       33\n##  4  2013     1     1     544          545       -1    1004         1022      -18\n##  5  2013     1     1     554          600       -6     812          837      -25\n##  6  2013     1     1     554          558       -4     740          728       12\n##  7  2013     1     1     555          600       -5     913          854       19\n##  8  2013     1     1     557          600       -3     709          723      -14\n##  9  2013     1     1     557          600       -3     838          846       -8\n## 10  2013     1     1     558          600       -2     753          745        8\n## # … with 336,766 more rows, and 13 more variables: carrier <chr>, flight <int>,\n## #   tailnum <chr>, origin <chr>, dest <chr>, airTime <dbl>, distance <dbl>,\n## #   hour <dbl>, minute <dbl>, timeHour <dttm>, gain <dbl>, hours <dbl>,\n## #   gainPerHour <dbl>"},{"path":"wrangling.html","id":"skim","chapter":"2 Wrangling","heading":"2.8.3 skim()","text":"skim() function skimr package useful summary function offers overview dataframe. offers users abilities see potential trends outliers variables dataframe. function creates report dataframe according variable type. ’ll run skim flights dataset.Table 2.1: Data summaryVariable type: characterVariable type: numericVariable type: POSIXctTake quick look section containing numeric variables. particular interest rightmost column offers insight potential distribution data, something discussed later depth .","code":"\nskim(flights)"},{"path":"wrangling.html","id":"distribution","chapter":"2 Wrangling","heading":"2.9 Distribution","text":"distribution? distribution variable shows frequently different values variable occur. Looking visualization distribution can show values centered, show values vary, give information typical value might fall. can also alert presence outliers.examine distributions greater depth, let’s first explore sample() function. sample() takes sample size vector either replacement without replacement. might seem abstract, consider six-sided dice represented vector.Suppose wanted simulate rolling dice . can use sample() function achieve .Now, suppose wanted roll dice 10 times. One arguments sample() function replace. must specify certain value can rolled . case, replace TRUE FALSE.replace TRUE. words, rolling 1 first roll preclude rolling one later roll.final argument sample() function prob argument. takes vector (length initial vector x) contains probabilities “landing ” one elements x. Suppose probability rolling 1 0.5, probability rolling value 0.1. Note, probabilities sum 1.Now, let’s return discussion distributions.","code":"\ndice <- c(1, 2, 3, 4, 5, 6)\nsample(x = dice, size = 1)## [1] 4\nsample(x = dice, size = 10, replace = TRUE)##  [1] 1 5 3 6 4 3 2 3 5 1\nprobs = c(0.5, 0.1, 0.1, 0.1, 0.1, 0.1)\n\nsample(x = dice, size = 10, replace = TRUE, prob = probs)##  [1] 4 4 1 1 2 1 1 3 5 1"},{"path":"wrangling.html","id":"runif","chapter":"2 Wrangling","heading":"2.9.1 runif()","text":"Consider Uniform distribution. case every outcome chance occurring. Uniform distribution might encounter everyday rolling fair dice. example, likely roll 2 roll 6. R, function runif() (read “r-unif”) corresponds Uniform contribution. words, function generates random values (within specified range).runif() function three arguments: n, min, max. Note R, runif() returns continuous uniform distribution, discrete one. means tried simulate die-rolling example, get decimal values.Let’s press die-rolling example now cautioned difference discrete continuous uniform distributions. three arguments runif(): n, min, max. n number observations, n = 1 since rolling die . default value min 0 default value max 1. die-rolling example, two values min = 1 max = 6, respectively. Let’s plug arguments function see get.Nice! just made first uniform distribution. , note output contains decimal numbers.","code":"\nrunif(n = 1,min = 1,max = 6)## [1] 5.3"},{"path":"wrangling.html","id":"rbinom","chapter":"2 Wrangling","heading":"2.9.2 rbinom()","text":"Now consider Binomial distribution, case probability boolean variable (instance success failure) calculated repeated, independent trials. One common example probability flipping coin landing heads. R, function rbinom() simulates distribution. function takes three arguments, n, size, prob. n number observations, size number trials, prob probability success trial. Suppose wanted flip fair coin one time, let landing hands represent success. Let n=1 size = 1, want flip coin . , since coin fair coin, let prob = 0.5.can see pretty even distribution Heads (1s) Tails (0s). even larger sample size result even spread Heads Tails values.Suppose instead wanted simulate unfair cin, probability landing Heads 0.75 instead 0.25.","code":"\nrbinom(n = 1 , size = 1, prob = 0.5)## [1] 0\ncoin_flip <- tibble(heads = rbinom(n = 100, size = 1, prob = 0.5))\n\nggplot(data = coin_flip, aes(x = heads)) +\n  geom_bar() +\n  labs(title = \"Flipping a Fair Coin 100 Times\") +\n  xlab(label = \"Flips\") +\n  ylab(label = \"Count\")\ncoin_flip_2 <- tibble(heads = rbinom(n = 100, size = 1, prob = 0.75))\n\nggplot(data = coin_flip_2, aes(x = heads)) +\n  geom_bar() +\n  labs(title = \"Flipping a Fair Coin 100 Times\") +\n  xlab(label = \"Flips\") +\n  ylab(label = \"Count\")"},{"path":"wrangling.html","id":"normal","chapter":"2 Wrangling","heading":"2.9.3 Normal distribution","text":"Let’s next discuss one particular kind distribution: normal distributions. bell-shaped distributions defined two values: (1) mean \\(\\mu\\) (“mu”) locates center distribution (2) standard deviation \\(\\sigma\\) (“sigma”) determines variation distribution. figure , plot three normal distributions :solid normal curve mean \\(\\mu = 5\\) & standard deviation \\(\\sigma = 2\\).dotted normal curve mean \\(\\mu = 5\\) & standard deviation \\(\\sigma = 5\\).dashed normal curve mean \\(\\mu = 15\\) & standard deviation \\(\\sigma = 2\\).\nFigure 2.7: Three normal distributions.\nNotice solid dotted line normal curves center due common mean \\(\\mu\\) = 5. However, dotted line normal curve wider due larger standard deviation \\(\\sigma\\) = 5. hand, solid dashed line normal curves variation due common standard deviation \\(\\sigma\\) = 2. However, centered different locations.mean \\(\\mu\\) = 0 standard deviation \\(\\sigma\\) = 1, normal distribution special name. ’s called standard normal distribution \\(z\\)-curve.Furthermore, variable follows normal curve, three rules thumb can use:68% values lie within \\(\\pm\\) 1 standard deviation mean.95% values lie within \\(\\pm\\) 1.96 \\(\\approx\\) 2 standard deviations mean.99.7% values lie within \\(\\pm\\) 3 standard deviations mean.Let’s illustrate standard normal curve. dashed lines -3, -1.96, -1, 0, 1, 1.96, 3. 7 lines cut x-axis 8 segments. areas normal curve 8 segments marked add 100%. example:middle two segments represent interval -1 1. shaded area interval represents 34% + 34% = 68% area curve. words, 68% values.middle four segments represent interval -1.96 1.96. shaded area interval represents 13.5% + 34% + 34% + 13.5% = 95% area curve. words, 95% values.middle six segments represent interval -3 3. shaded area interval represents 2.35% + 13.5% + 34% + 34% + 13.5% + 2.35% = 99.7% area curve. words, 99.7% values.\nFigure 2.8: Rules thumb areas normal curves.\n","code":""},{"path":"wrangling.html","id":"rnorm","chapter":"2 Wrangling","heading":"2.9.4 rnorm()","text":"function rnorm() can read “r-norm”. corresponds Normal distribution.rnorm() three arguments: n, mean, sd. n corresponds number observations, mean corresponds average whole, sd corresponds size standard deviation mean. go depth future chapters statistical mechanics behind distributions, now, let’s focus creating Normal distribution.run following:get 10 observations centered around default mean 0 default sd 1. create histogram values?Now ’s looking lot similar (although imperfect)! just discovered, observations normal distribution , closer looks symmetrical bell curve.Now, let’s compare normal distributions varying means standard deviations, can set using mean sd arguments included function.Allaire, JJ, Yihui Xie, Jonathan McPherson, Javier Luraschi, Kevin Ushey, Aron Atkins, Hadley Wickham, Joe Cheng, Winston Chang, Richard Iannone. 2020. Rmarkdown: Dynamic Documents R. https://github.com/rstudio/rmarkdown.R Core Team. 2020. R: Language Environment Statistical Computing. Vienna, Austria: R Foundation Statistical Computing. https://www.R-project.org/.Xie, Yihui. 2014. “Knitr: Comprehensive Tool Reproducible Research R.” Implementing Reproducible Computational Research, edited Victoria Stodden, Friedrich Leisch, Roger D. Peng. Chapman; Hall/CRC. http://www.crcpress.com/product/isbn/9781466561595.———. 2015a. Dynamic Documents R Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. http://yihui.name/knitr/.———. 2015b. Dynamic Documents R Knitr. 2nd ed. Boca Raton, Florida: Chapman; Hall/CRC. https://yihui.org/knitr/.———. 2016. Bookdown: Authoring Books Technical Documents R Markdown. Boca Raton, Florida: Chapman; Hall/CRC. https://github.com/rstudio/bookdown.———. 2020a. Bookdown: Authoring Books Technical Documents R Markdown. https://github.com/rstudio/bookdown.———. 2020b. Knitr: General-Purpose Package Dynamic Report Generation R. https://yihui.org/knitr/.Xie, Yihui, J. J. Allaire, Garrett Grolemund. 2018. R Markdown: Definitive Guide. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown.Xie, Yihui, Christophe Dervieux, Emily Riederer. 2020. R Markdown Cookbook. Boca Raton, Florida: Chapman; Hall/CRC. https://bookdown.org/yihui/rmarkdown-cookbook.","code":"\nrnorm(10)##  [1] -0.84  1.38 -1.26  0.07  1.71 -0.60 -0.47 -0.64 -0.29  0.14\ndistrib <- tibble(value = rnorm(10))\n\nggplot(distrib, aes(x = value)) + \n  geom_histogram(bins = 10)\ndistrib_2 <- tibble(value = rnorm(100))\n\nggplot(distrib_2, aes(x = value)) +\n  geom_histogram(bins = 10)\ndistrib_3 <- tibble(value = rnorm(1000))\n\nggplot(distrib_2, aes(x = value)) +\n  geom_histogram(bins = 10)\nnormal_distrib <- tibble(rnorm_5_1 = rnorm(n = 1000, mean = 5, sd = 1), \n                        rnorm_0_3 = rnorm(n = 1000, mean = 0, sd = 3),\n                        rnorm_0_1 = rnorm(n = 1000, mean = 0, sd = 1)) %>%\n  pivot_longer(cols = everything(), \n               names_to = \"distribution\", \n               values_to = \"samples\")\n\nggplot(normal_distrib, aes(x = samples, fill = distribution)) +\n  geom_density(alpha = 0.5) +\n  labs(title = \"Comparison of Normal Distributions with Differing Mean and Standard Deviation Values\", \n       fill = \"Distribution\") +\n  xlab(\"X\") + \n  ylab(\"Density\")"}]
