---
title: "Prediction Game"
author: "David Kane"
date: "12/23/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(primer.data)
```




### `no_NA_sampler()`

Assume that we want to sample 10 observations for `height` from the `nhanes` tibble from the **primer.data** package. That is easy to do with the built in function `sample()`.

```{r}
sample(nhanes$height, size = 10)
```

One problem with this approach is that it will sample missing values of `height`. We can avoid that by manipulating the vector inside of the call to `sample()`.

```{r}
sample(nhanes$height[! is.na(nhanes$height)], size = 10)
```

That works, but, first, it is ugly code. And, second, it is hard to extend when we have more constraints. For example, assume we only want to sample from individuals who have no missing values for any variables, not just `height`. To do that, we really ought to make a custom function. Call that function `no_NA_sampler()`.

The first step in function creation is to write code in a normal pipe which does what you want the function to do. In this case, that code would look like:

```{r}
nhanes %>% 
  drop_na() %>%
  sample_n(10) %>% 
  pull(height)
```

We start with `nhanes`, remove any row with a missing value for any variable, sample 10 rows at random and then pull out `height`. To turn this into a function, we just need to copy/paste this pipe within the body of our function definition:

```{r}
no_NA_sampler <- function(){
  nhanes %>% 
    drop_na() %>%
    sample_n(10) %>% 
    pull(height)
}

no_NA_sampler()
```

Voila! A function just executes the code within its body. The first step in function creation is not to write the function. It is to write the code which you want the function to execute.

The first version, however, "hard codes" a lot of options which we might want to change. What if we want to sample 5 values of height or 500? In that case, we could hard code a new number in place of "10". Better would be to add an argument so that we can pass in whatever value we want.


```{r}
no_NA_sampler <- function(n){
  nhanes %>% 
    drop_na() %>%
    sample_n(n) %>% 
    pull(height)
}

no_NA_sampler(n = 2)
no_NA_sampler(n = 25)
```

What if we want to sample from a different variable than `height` or from a different tibble than `nhanes`? Again, the trick is to turn hard coded values into arguments.

```{r}
no_NA_sampler <- function(tbl, var, n){
  tbl %>% 
    drop_na() %>%
    sample_n(n) %>% 
    pull({{var}})
}

no_NA_sampler(nhanes, height, n = 2)
no_NA_sampler(trains, age, n = 5)
```

The tricky part of using variable names as arguments is that R does not know how to interpret something like `age` when it is passed in as an argument. The double curly braces tell R, in essence, that `var` is a variable which is in the tibble which will be passed, in the pipe, to `pull()`. 

<!-- DK: I realize that the above is a lousy explanation. Feel free to change it completely. -->

Now that we have the function doing what we want, we should add some comments and some error checking.

```{r}
no_NA_sampler <- function(tbl, var, n){
  
  # Function for grabbing `n` samples from a variable `var` which lives in a
  # tibble `tbl`. 
  
  # I could not figure out how to check to see if `var` actually lives in tibble
  # in my error checking. Also, I don't like that I need to use is_double() as
  # the check on `n` even though I want `n` to be an integer.
  
  stopifnot(is_tibble(tbl))
  stopifnot(is_double(n))

  tbl %>% 
    drop_na() %>%
    
    # What happens if n is "too large"? That is, I need to think harder about a)
    # whether or not I am sampling with or without replacement and b) which I
    # should be doing.
    
    sample_n(size = n) %>% 
    pull({{var}})
}
```

### Prediction Game

Let's play a prediction game. Consider the `kenya` tibble from **primer.data**.

```{r}
kenya
```

The game is that we will pick a random value of `rv13`, which is the number of people who live in the vicinity of a polling station. You guess a number. I guess a number. The winner of the Prediction Game is the person whose guess is closest to the random value selected. Example:

```{r}
your_guess <- 500
my_guess <- 600

sampled_value <- no_NA_sampler(kenya, rv13, n = 1) 

your_error <- abs(your_guess - sampled_value)
my_error <- abs(my_guess - sampled_value)

if(your_error < my_error) cat("You win!")
if(your_error > my_error) cat("I win!")
```


Run this code in your R Console to try it out. It works! It is also sloppy and disorganized. *But the first step in writing good code is to write bad code*.

We don't want to play the Prediction Game just once. We want to do it thousands of times. Copy/pasting this code a thousand times would be stupid. Instead, we need a function. Just place the working code within a function definition, and Voila!

```{r}
prediction_game <- function(){
  your_guess <- 500
  my_guess <- 600
  
  sampled_value <- no_NA_sampler(kenya, rv13, n = 1) 
  
  your_error <- abs(your_guess - sampled_value)
  my_error <- abs(my_guess - sampled_value)
  
  if(your_error < my_error) cat("You win!")
  if(your_error > my_error) cat("I win!")
}
```

Other than the function definition itself, there are no changes. Yet, by creating a function, we can now easily run this multiple times.


```{r}
replicate(3, prediction_game())
```

The problem with this version is that we want `prediction_game()` to *return* a message about the winner. Right now, it returns nothing. It just prints the winner. Let's change that, and also allow for guesses to be passed in as an argument, along with the tibble and variable. We can leave `n` hard coded as 1 since, by definition, the Prediction Game is an attempt to guess one number, at least for now.

<!-- DK: Add some code comments, especially {{var}} -->

```{r}
prediction_game <- function(guesses, tbl, var){
  stopifnot(all(is_double(guesses)))
  stopifnot(length(guesses) == 2)
  
  your_guess <- guesses[1]
  my_guess <- guesses[2]
  
  sampled_value <- no_NA_sampler(tbl, {{var}}, n = 1) 
  
  your_error <- abs(your_guess - sampled_value)
  my_error <- abs(my_guess - sampled_value)
  
  if(your_error < my_error){ 
    return(paste("Guess", your_guess, "wins!"))
  }
  if(your_error > my_error){ 
    return(paste("Guess", my_guess, "wins!"))
  }
  if(your_error == my_error){ 
    return("A tie!")
  }

}
```

```{r}
replicate(5, prediction_game(guesses = c(500, 600), kenya, rv13))
```


In general, we will want to store the results in a tibble, which makes later analysis and plotting easier.

```{r}
tibble(ID = 1:3) %>% 
  mutate(result = map_chr(ID, ~ 
                            prediction_game(guesses = c(500, 600),
                                            kenya, 
                                            rv13)))
```

Who wins the game the most if we play 1,000 times?

```{r, echo = FALSE}
set.seed(9)
```


```{r}
tibble(ID = 1:1000) %>% 
  mutate(result = map_chr(ID, ~ 
                            prediction_game(guesses = c(500, 600),
                                            kenya, 
                                            rv13))) %>% 
  ggplot(aes(result)) +
    geom_bar()
```

It is hardly surprising that 500 wins more often than 600 since the mean of `rv13` is `r mean(kenya$rv13)`. The mean seems like a pretty good guess. But it is not the best guess.

```{r}
tibble(ID = 1:1000) %>% 
  mutate(result = map_chr(ID, 
                          ~ prediction_game(c(442, 539),
                                            kenya,
                                            rv13))) %>% 
  ggplot(aes(result)) +
    geom_bar()
```

The mean is not a bad prediction. But the best prediction is (surprisingly?) the median, which is `r median(kenya$rv13)`.

#### Playing within a tibble

In other cases, it is more convenient to play portions of the Prediction Game within a tibble. Imagine that we are trying to guess the biggest value out of 10 random samples. 


```{r}
tibble(ID = 1:3, guess_1 = 800, guess_2 = 900) %>% 
  mutate(result = map(ID, ~ no_NA_sampler(kenya, rv13, 10)))
```

We can now manipulate the `result` column and then see which prediction did better.

```{r}
tibble(ID = 1:3, guess_1 = 800, guess_2 = 900) %>% 
  mutate(result = map(ID, ~ no_NA_sampler(kenya, rv13, 10))) %>% 
  mutate(biggest = map_dbl(result, ~ max(.))) %>% 
  mutate(error_1 = abs(guess_1 - biggest)) %>% 
  mutate(error_2 = abs(guess_2 - biggest)) %>% 
  mutate(winner = case_when(error_1 < error_2 ~ "Guess one wins!",
                            error_1 > error_2 ~ "Guess two wins!",
                            TRUE ~ "A tie!"))
```

Run the test 1,000 times.

```{r}
tibble(ID = 1:1000, guess_1 = 800, guess_2 = 900) %>% 
  mutate(result = map(ID, ~ no_NA_sampler(kenya, rv13, 10))) %>% 
  mutate(biggest = map_dbl(result, ~ max(.))) %>% 
  mutate(error_1 = abs(guess_1 - biggest)) %>% 
  mutate(error_2 = abs(guess_2 - biggest)) %>% 
  mutate(winner = case_when(error_1 < error_2 ~ "Guess one wins!",
                            error_1 > error_2 ~ "Guess two wins!",
                            TRUE ~ "A tie!")) %>% 
  ggplot(aes(winner)) +
    geom_bar()
```

Empirically, we see than 900 is a much better guess than 800.

#### Measures of the center of a distribution

Let's play a new game. Pretend that we don't have access to the entire `kenya` data set. Instead, someone is going to draw 25 values of `rv13` at random. Our job is to calculate the `mean()` and `median()` of each of those sames and then to explore which measure is more "stable."

```{r}
tibble(ID = 1:3) %>% 
  mutate(samp = map(ID, ~ no_NA_sampler(kenya, rv13, 25))) %>% 
  mutate(median_rv13 = map_dbl(samp, ~ median(.))) %>% 
  mutate(mean_rv13 = map_dbl(samp, ~ mean(.)))         
```

As usual with right-skewed distributions, the median is smaller than the mean. Let's do this 1,000 times and look at the distrubution of these estimates.

```{r, cache = TRUE}
tibble(ID = 1:1000) %>% 
  mutate(samp = map(ID, ~ no_NA_sampler(kenya, rv13, 25))) %>% 
  mutate(median_rv13 = map_dbl(samp, ~ median(.))) %>% 
  mutate(mean_rv13 = map_dbl(samp, ~ mean(.))) %>% 
  pivot_longer(cols = median_rv13:mean_rv13,
               names_to = "measure",
               values_to = "estimate") %>% 
  ggplot(aes(estimate, fill = measure)) +
    geom_histogram(alpha = 0.5, 
                   bins = 100, 
                   position = "identity") +
    labs(title = "Distribution of Measures of the Center",
         subtitle = "The median is a more stable measure than the mean",
         x = "Estimate",
         y = "Count") + 
    scale_x_continuous(labels = scales::number_format())
```


<!-- DK: Not even sure if this shows what we want! But finishing off with a chart like this is probably a good idea. -->
