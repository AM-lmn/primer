# Functions {#functions}




<!-- tibble(ID = 1:10) %>%  -->
<!--   mutate(height = map_dbl(ID, ~ my_sampler(nhanes, "height"))) %>%  -->
<!--   mutate(height_list = map(ID, ~ my_sampler(nhanes, "height", n = 10))) %>%  -->
<!--   mutate(avg_height = map_dbl(height_list, ~ mean(.))) -->
  
<!-- Plot histograms of average height with different n's. Can also do with standard deviation. -->

<!-- Lesson: Larger N means more stable estimates. -->

<!-- Perhaps there are three main parts to the chapter. The first is lists, list-columns, map functions and custom functions. We can cover all that with fairly simple examples. (Don't use N argument yet. Just solve the no NA problem.) Second, as discussed below, is explorations of measures of center and variability for distributions. (Means we need to extend my_sampler with n argument.) We can explore those things with our new tools. The third section plays the Guessing Game. Show them mean, median, sd, and mad.-->


<!-- Key concept to focus on is the idea of a distribution and draws therefrom. This connects to chapter 2, where we introduced distributions and to chapter 5, where we explain probability distributions. In particular, we should show various ways to measure center and variability. These are cool and important concepts. Is "center" the mean or the median or the trimmed mean or . . . Is "variability" the standard deviation, the mean absolute deviation, the standard deviation of the median absolute deviation or . . . There is nothing explicitly "statistical" here. We are just trying to connect English words to specific formulas. We might show the distributions for which these measures give the same answers and then some (mainly skewed) for which they don't. How to explore these concepts in the context of function writing? Perhaps by writing functions like my_mean() and my_median()? Or maybe focus on a function which calculates MAD SD? Then use list-columns to compare this function to other choices? -->

<!-- Lesson: If you have a really skewed distribution, then median is a more stable measure than mean, and MAD (median absolute difference -- which means absolute difference from the median) is a more stable measure than standard deviation. Results depends too much on who ended up in the sample, like Bill Gates. -->

<!-- Related: Teach random draws. We introduce random variables at the end of chapter 2. Do more with them here. For example, with a data set, calculated a mean and sd. Then do 1,000 draws from that. Then, plot the densities of the raw data and the simulated data on top of one another. -->

<!-- Standard errors, qua standard errors, are a tricky thing to teach. But what if, instead of teaching them as standard errors, we just introduce the formula as a simple way to approximate something which, when multiplied by 2, and then added/subtracted from the mean, gives you a pretty useful 95% confidence interval. Then we could do the same for MAD SD, and show how that works better for skewed variables! Here, "works better" means that, if you do it 1,000 times, it works better on average. No! Too much! -->

<!-- The main use case is the "Guessing Game." Imagine that you are I are using the kenya data set and the distance, pop_density or rv13 variables. (All of which are quite skewed. We might also experiment with the poverty variable, which is less skewed. But skewed variables make this more interesting.) -->

<!-- In the Guessing Game, you guess a number and I guess a number. The goal is to get closest to a random draw from all the values of distance (or whatever). We do this 1,000 times. Whoever gets closer more often, wins the Guessing Game.  -->

<!-- This is a useful exercise for several reasons. First, coding it up is a good practice for writing a function. Indeed, we might re-write the whole chapter to focus on this example. Second, once we have a function, which runs one iteration of the Game --- maybe it takes the data set (or maybe a vector of values?), my guess and your guess, and then returns the winner --- we can use list columns and map_functions to run it a thousand times. This is all more fun and more interesting that stupid max-minus-min functions. -->

<!-- Third, the Guessing Game gets at key statistical issues. There is a lot of meat there, all things that we will revisit many times. Some things to highlight, many of which can be put into the Guessing Game. -->

<!-- 1) Guess a formula rather than a number. Presumably, you and I get to see (all of?) the data before playing the game. In the simplest version, we look at the data and give you a number. (The mean and median both do well in this game, obviously.) But, in a more advanced form of the game, we might be allowed to provide a function. The goal of inference is to come up with a function which wins the prediction game.) -->

<!-- 2) Change the objective function. The simplest form of the Guessing Game just counts each contest separately. A more advanced for would give you a penalty which varies depending on how wrong you are. (This, obviously, is one way to think about minimizing the squared residuals.) This is very fun because there are many different penalty functions, each of which may lead to a different function winning the Guessing Game. -->

<!-- 3) The chapter climaxes with the following cool result: If you are minimizing the sum (or average) of the squared residuals, guessing the mean wins the Guessing Game. However, if you are minimizing the sum (or average) of the absolute values of the residuals, you should guess the median. -->

<!-- 4) Another form of the Guessing Game is like a casino. One person (the Casino) gives a 50% confidence interval. The other person gets to pick either inside or outside. Then there is a draw. The Casino wins if the second person can't consistently win. -->

<!-- Key question: Do we explain standard error here? Could be easy! Calculate the mean. Calculate the sd. Divide and scale by the square root of n. Voila! But, still, I think No. But we should explain everything short of standard error.  -->

<!-- group_nest() might be a useful function.  -->

<!-- Might also show how to add lots of plots to a tibble and then pick out the ones that show cool stuff. If you run 1,000 experiments, show the plots of the 5 extreme ones. -->




## Introduction

A function is a piece of code that is packaged in a way that makes it easy to reuse. Functions make it easy for you to `filter()`, `arrange()`, `select()`, and create a `tibble()`, as you have seen in Chapters \@ref(visualization) and \@ref(wrangling). Functions also allow you to transform variables and perform mathematical calculations. We use functions like `rnorm()` and `runif()` to generate random draws from a distribution.

Note that every time we discuss a function, we include the parentheses. This is because you call a function by including its parentheses and any necessary arguments within those parentheses. This is a correct call of `rnorm()`:

```{r}
rnorm(n = 1)
```

If you run the function name without its parentheses, R will return the code that makes up the function. 

```{r}
rnorm
```

Functions can do all sorts of things. `sample()` takes a vector of values and returns a number of values randonly selected from that vector. You can specify the number of random values with the argument `size`. This call is the equivalent of rolling a die.

```{r}
sample(x = 1:6, size = 1)
```

Functions can also take in other functions as arguments. For example, `replicate()` takes an expression and repeats it `n` times. What if we replicated the rolling of a die ten times?

```{r}
replicate(10, sample(1:6, 1))
```

An especially useful type of function is the family of `map_*` functions. `map_*` functions come from the **purrr** package, which is automatically loaded with `library(tidyverse)`. These functions apply the same function to every row in a tibble.

```{r, message = FALSE}
library(tidyverse)
```

Let's create a tibble with one variable `x` which takes on three values: 3, 7, and 2.

```{r}
tibble(x = c(3, 7, 2))
```

It is easy to use mutate to create a new variable, `sq_root`, which is the square root of each value of x.

```{r}
tibble(x = c(3, 7, 2)) %>% 
  mutate(sq_root = sqrt((x)))
```

map_* functions provide another approach.

```{r}
tibble(x = c(3, 7, 2)) %>% 
  mutate(sq_root = map_dbl(x, ~ sqrt(.)))
```

`map_dbl()` (pronounced "map-double") took the function `sqrt()` and applied it to each element of `x`. There are two tricky parts to the use of map_* functions. First, you need to put the tilde symbol --- the "~" --- before the call to the function. Second, you need to include a period --- the "." --- in the spot where the variable goes.

A `map_*` function takes two required arguments. First is the object over which you want to iterate. This will generally be a column in the tibble you are working in. Second is the function which you want to run for each row in the tibble.

We called these `map_*` functions (plural) before.  If you know the expected output of your function, you can specify that kind of vector:

- `map()`: list  
- `map_lgl()`: logical
- `map_int()`: integer
- `map_dbl()`: double (numeric)
- `map_chr()`: character
- `map_df()`: data frame

Since our example produces numeric output, we use `map_dbl()` instead of `map()`.

What's the difference between using `mutate()` and `map_*` functions? `map_*` functions are useful because of their ability to apply functions to every single element of a list, which `mutate()` cannot handle.


## List-columns and map functions

Recall that a list is different from an atomic vector. In atomic vectors, each element of the vector has one value.  Lists, however, can contain vectors, and even more complex objects, as elements.

```{r}
x <- list(c(3, 7, 2))
x
```

The above object, x, contains a numeric vector as an element. How do we extract the first element of the list?

```{r}
x[[1]][1]
```

Recall the example from Chapter \@ref(wrangling) that  lists are like a pepper jar which contains more pepper packets. Don't forget the square brackets!


There are a number of built-in R functions that output lists. For example, the ***ggplot***s you have been making store all of the plot information in lists.

Any function that returns multiple values can be used to create a list output by wrapping those values with `list()`.


```{r}
x <- rnorm(10)

range(x)

tibble(col_1 = list(range(x))) 
```

Notice this is a 1x1 tibble with one observation, which is a list of one element. Voila! You have just created a *list-column**.

*If a function returns multiple values as a vector, like `range()` does, you must use `list()` as a wrapper if you want to create a list-column.*

A list column is a column of your data which is a [list](https://adv-r.hadley.nz/vectors-chap.html#lists) rather than an atomic vector.  Like with lists, you can pipe in `str()` to read the column more easily.

```{r message=FALSE}
tibble(col_1 = list(range(x))) %>%
  str()
```


Let's practice with the `nhanes` dataset. How could we add a column to the dataset that included the quantiles of the `height` variable for each `gender`?

First, we load the necessary **primer.data** library.

```{r}
library(primer.data)
```

Then, select the relevant variables, and group by `gender`. We are grouping because we are curious as to how `height` is distributed in between `gender`. We drop any rows with missing data.

```{r}
nhanes %>%
  select(gender, height) %>%
  drop_na() %>% 
  group_by(gender)
```

Next, we will create a list-column by wrapping `quantile()` with `list()`. `quantile()` naturally produces a numeric vector of the quantiles of `height`, and wrapping with `list()` will capture this numeric vector as a list.

```{r}
tmp <- nhanes %>%
  select(gender, height) %>%
  drop_na() %>% 
  group_by(gender) %>% 
  mutate(height_quantiles = map(height, ~ quantile))

tmp
```

Take a look at the values for `height_quantiles`:

```{r}
str(tmp)
```

Men are taller than women, except at the very bottom of the highet distribution, which includes children.

We can use `map_*` functions to both create a list-column and then, much more importantly, work with that list-column afterwards. Example:


```{r}
tibble(ID = 1:3) %>% 
  mutate(draws = map(ID, ~ rnorm(10))) %>% 
  mutate(max = map_dbl(draws, ~ max(.))) %>% 
  mutate(range = map(draws, ~ range(.)))
```

This flexibility is only possible via the use of list-columns and  `map_*` functions.


Until now, we have practiced using `map_*` functions witht built-in R functions. Next, we will show you how to write your very own functions!

## Custom Functions

### Anonymous functions with `map_*` functions

We can create functions that do operations "on the fly" without bothering to give them a name. These nameless functions are called [anonymous functions.](https://coolbutuseless.github.io/2019/03/13/anonymous-functions-in-r-part-1/)

You can use anonymous functions in conjunction with the `map_*` family of functions. They're commonly used to conduct mathematical operations repeatedly.

You can call an anonymous function using a `~` operator and then using a `.` to represent the current element.

```{r}
tibble(old = c(3, 7, 2)) %>% 
  mutate(new = map_dbl(old, ~ (. + 1)))
```

Note that the parentheses are not necessary. As long as everything after the `~` works as R code, the anonymous function should work, each time replace the `.` with the value of the relevant value of the `.x` variable --- which is `old` in this case --- with its value in that row.

```{r}
tibble(old = c(3, 7, 2)) %>% 
  mutate(new = map_dbl(old, ~ . + 1))
```


### Creating your own functions

There are plenty of built-in functions in R, such as the ones mentioned above. You can also create your own custom functions, which may look something like this:

```{r}
add_one_and_one <- function(){
  1 + 1
}

add_one_and_one()
```

You just created a function! This function will return `1 + 1` whenever called. 

What if we wanted to leave some mystery in the function? That is to say, we want to add the number 6 to a value `x`, that the user provides for us. 

```{r}
add_six_to_something <- function(x){
  x + 6
}

add_six_to_something(x = 1)
```

Congratulations! You have incorporated your first **formal argument**. Formal arguments in functions are additional parameters that allow the user to customize the use of your function. Instead of adding `1 + 1` over and over again, your function takes in a number `x` that the user defines and adds 6. Now let's drive it home and make a function with *two* formal arguments.

```{r}
add_x_to_y <- function(x, y) {
  x + y
}

add_x_to_y(1, 2)
add_x_to_y(4, 3)
```



### Skateboard >> perfectly formed rear-view mirror

This image --- widely attributed to the Spotify development team --- conveys an important point.

```{r echo = FALSE, out.width = "60%", fig.align='center', fig.cap = "From [Your ultimate guide to Minimum Viable Product (+great examples)](https://blog.fastmonkeys.com/2014/06/18/minimum-viable-product-your-ultimate-guide-to-mvp-great-examples/)"}
knitr::include_graphics("03-functions/images/mvp.jpg")
```

Build that skateboard before you build the car or some fancy car part. A limited-but-functioning thing is very useful. It also keeps spirits high.

This is related to the valuable Telescope Rule:

> It is faster to make a four-inch mirror and then a six-inch mirror than it is to make a six-inch mirror.





<!-- DK: Useful points to include, maybe.

### Argument names: freedom and conventions -->

<!-- Understand the importance of argument names. We can name my arguments almost anything we like. Proof: -->

<!-- ```{r} -->
<!-- multiple_sampler <- function(bob_ross) { -->
<!--   nhanes %>%  -->
<!--     select(height) %>%  -->
<!--     sample_n(bob_ross) %>%  -->
<!--     slice() -->
<!-- } -->

<!-- multiple_sampler(bob_ross = 3) -->
<!-- ``` -->

<!-- While we *can* name our argument after a famous painter, it's usually a bad idea. Take all opportunities to make things more self-explanatory via meaningful names. -->

<!-- If you are going to pass the arguments of your function as arguments of a built-in function, consider copying the argument names. Unless you have a good reason to do your own thing (some argument names are bad!), be consistent with the existing function. Again, the reason is to reduce your cognitive load.  -->

<!-- We took this detour so you could see there is no *structural* relationship between our argument (`n`) and that of `sample()` (which also includes `n`). The similarity or equivalence of the names __accomplishes nothing__ as far as R is concerned; it is solely for the benefit of humans reading, writing, and using the code. Which is very important! -->


  


<!-- Maybe useful?

### What a function returns -->

<!-- By default, a function returns the result of the last line of the body. We are just letting that happen with the line `sum(sample(1:6, n, replace = TRUE))`. However, there is an explicit function for this: `return()`. We could just as easily make this the last line of my function's body: -->

<!-- ```{r echo = FALSE} -->
<!-- add_dice <- function(n = 2) { -->
<!--   stopifnot(is.numeric(n)) -->
<!--   stopifnot(n >= 0) -->
<!--   sum(sample(1:6, n, replace = TRUE)) -->
<!-- } -->
<!-- ``` -->

<!-- ```{r eval=FALSE} -->
<!-- return(sum(sample(1:6, n, replace = TRUE))) -->
<!-- ``` -->

<!-- You absolutely must use `return()` if you want to return early based on some condition, i.e. before execution gets to the last line of the body. Otherwise, you can decide your own conventions about when you use `return()` and when you don't. -->





## Summary

<!-- Add summaries for all major sections of the chapter. This is just for the function section and needs more clarification. -->

<!-- MF: Should the summary include enough information that a student could get away with not reading the chapter? Or should it only be a tool of review for students who have read the chapter? -->

### Lists and list-columns

The introduction of the chapter was centered on a discussion of lists and list-columns. Key points from this section include:

- A list is different from an atomic vector. Atomic vectors are familiar to us: each element of the vector has one value, and thus if an atomic vector is a column in your dataset, each observation gets a single value.  Lists, however, can contain vectors as elements.
- There are various ways to create lists. We can directly input values inside `list()`, or wrap the values in `c()` first to create a vector element.
- Any function that returns multiple values can be used to create a list output. To turn the output into a list, simply wrap the line of code with `list()`.
- We can take a list column and, by applying an anonymous function to it with `map()`, create another list column. This is similar to taking a tibble and piping it into a `dplyr` function (such as `mutate()`) which gives you a new tibble that you can work with.
- You can also use `map_*` functions to take a list column as an input and return an atomic vector -- a column with a single value per observation -- as an output. 

### Functions

This chapter, we focused on functions. 

In particular, when building a function, you want to remember these key lessons:
- Optimize usefulness by adding more formal arguments when needed. A function that only gives an option for `n` may not be as helpful as a function that allows us to enter options for a dataset, variable, and n value. 
- As there is no *structural* relationship between our argument names (`n`) and that of `sample()` (which also includes `n`), ensure that argument names are sensible. This helps not only your readers, but also you. In short: using "bob_ross" to denote the number of samples you want... is a bad idea. 
- Make sure we account for possible values of NA in our functions. This can be accomplished by placing something like `drop_na()` as another line of code within the function's body, or by adding an `na.rm =` argument to our function. We might even enforce our preferred default -- but at least we're giving the user a way to control the behavior around `NA`s.
- By default, a function returns the result of the last line of the body.


